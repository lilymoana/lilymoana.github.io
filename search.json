[{"title":"共识算法的比较：Casper vs Tendermint","url":"/ConsensusCompare.html","content":"\n  CTFG更注重可用性，Tendermint更注重一致性，CFFG介于两者之间。 <Excerpt in index | Homepage Digest>\n\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n\n![](/asset/ConsensusCompare_head.jpeg)\n\n\n## 权益证明的漫漫长路\n权益证明的定义可以查看[理解权益证明](https://blog.cosmos.network/understanding-the-basics-of-a-proof-of-stake-security-model-de3b3e160710)。\n\n1982年，拜占庭将军问题首次被Lamport，Shostak和Pease提出。Cosmos的Ethan Buchman这样描述它：”这是一个在可妥协的通信网络中实现分布式协议的问题，也就是在不可靠的环境中建立一个可靠的系统的问题“。从1982年到1999年，都没有人能够创造一个可以解决拜占庭将军问题系统。长久以来，拜占庭将军问题与计算都是无关的，因为在那个时候，互联网从基于云的中央计算演变而来，所需要解决的只是容错问题。\n\n所以，故障容错算法得到普及，例如1998年发明的Paxos算法和2013年发明的Raft算法被广泛的应用。而1999年发明的实用拜占庭容错（PBFT）却没有被学术界之外采用。直到2008年，中本聪将网络规模级别的分布式拜占庭容错(BFT)算法设计到区块链方案中，才使拜占庭容错得到推广。当这种原型出现之后，系统研究界的人都开始围绕将学术界“奇物”应用到真实世界而去构思各种想法。\n\n在2011年，[BitcoinTalk论坛](https://bitcointalk.org/index.php?topic=27787.0)对一个叫做权益证明(PoS)的概念组织了一场讨论。最初的PoS协议例如点点币，实现结果的并不理想。第一个真正提出将BFT研究应用到PoS公有区块链环境中是Jae Kwon，他在2014年创造了Tendermint。\n\n在当时，PoS研究做出了很大的假设：假设系统中的一系列对等节点都是静态的，并且在长时间内都是稳定的。在区块链环境中完全是不现实的。 Jae Kwon的重大突破是使Tendermint能够使用区块，哈希链接，动态验证器集合和循环的领导者选举来将BFT研究适应复制状态机（区块链）的领域。\n\n在Tendermint环境中，出现了大量的共识算法（Honeybadger, Ouroboros, Tezos, Casper），它们都包含了BTF研究的元素以及在区块链上其他模块观察的元素。\n\n为权益证明做的所有研究都指向一个重要问题：在不耗尽物质稀缺资源的情况下，我们可以达到工作量证明（PoW）的安全级别吗？这个问题可以转化为：PoS的投票权以链上货币计价而不是计算力计价。区块链的POS共识问题比可扩展性更被广泛讨论，运行PoW挖矿的高开销成本以及环境外部性方面存在的问题都刺激了大量资源涌入PoS安全研究。\n\n本文主要探讨了在加密货币中使用了权益证明的三个主要PoS协议的特性：由Vlad Zamfir带领研究的Casper the Friendly Ghost(CTFG)和由Vitalik Buterin带领研究Casper the Friendly Finality Gadget(CFFG)以及Jae Kwon带领研究的[Tendermint](https://github.com/tendermint/tendermint.github.io/blob/5c111743a03d2c6ed2e0b14bd3091cac8974c8da/docs/tendermint_v02.pdf)。\n\n## 权益证明的陷阱\n\n### 无利害关系\n起初，有多种不同的说法来描述权益证明的一般陷阱，无利害关系就在这时被提出。Jae Kwon 2014年5月以“错误选择谬论”的不幸名字[第一次提到这个问题](https://github.com/tendermint/tendermint.github.io/blob/5c111743a03d2c6ed2e0b14bd3091cac8974c8da/docs/tendermint_v02.pdf)。在2014年7月Vitalik把比特币开发者所描述的确切定义的问题普及推广为“无利害关系”。问题呈现出此情况：验证者通过在给定高度为多个有冲突的区块投票可以有效的破坏安全性而不用付出任何代价。\n\n简单的PoS实现对于这些攻击而言是非常脆弱的。灾难性的是，因为没有任何的激励来鼓励大家永远集中在一个独一的链上，并且每一次激励都要一次性在多个相互冲突的链条上进行重复签名，所以为了获得更多的区块奖励，在经济上最优的策略就变成了尽可能的在多个分杈上进行投票。下面这张图就展示了：\n![在简单的PoS设计中竞争链上的期待投票数高于单一链上期待的投票数](/asset/ConsensusCompare1.png)\n\n在工作量证明中，对于在多个链上进行挖矿的矿工“惩罚”是他们必须分开他们的计算力（非常稀缺的资源）。在现代非简并的PoS设计中，这种成本必须嵌入到协议里面以此模仿物理PoW挖矿的限制。\n\n Vitalik Buterin在2014年1月引入的“slasher”概念或协议内惩罚可以减轻这个攻击。Jae Kwon在同一年[进一步推算了此方法](https://tendermint.com/static/docs/tendermint.pdf)，这是实现Tendermint共识协议的第一个迭代进展。苛刻以及允许这种惩罚的条件，对于所有的非简并BFT协议都是有帮助的，甚至在本文中出现的三种共识都采用了。\n\n### 远程攻击\n远程攻击来源于用户不得不撤回保证金的权利。这就产生了一个基本问题，因为这意味着攻击者可以从任意长度的距离建立一个分杈而不用担心被削减。一旦保证金被解除绑定，激励不从某个高度区块前进行长距离投票就被取消了。换句话说，当超过2/3的验证者解除了绑定，那么他们就可以恶意的创造包含之前验证者集的第二条链，这可能导致任意的交易。\n\n对于权益证明协议这是相当致命的，因为安全模型必然是“主观”的。当参与网络要求大量的社会信息，那么这个安全模型就会被称为是“主观的”。一个新节点加入网络之后，对于当前网络的状态可能会得出不同的结论，因为他们的决策是基于主观信息的，即社会声誉。在相反面，工作量证明的安全模型必然是“客观的”，因为当前网络状态总是工作量最多的那个状态，新节点对于网络状态的结论总是相同的，因为他们的决策是基于客观信息。\n\nPoS的远程攻击在[弱主观性](https://blog.ethereum.org/2014/11/25/proof-stake-learned-love-weak-subjectivity/)模型下进行了纠正，这要求接入到网络中的后续新节点：\n- *当前必须是被绑定的*。只相信*当前*有保证金的验证节点\n- 解除绑定保证金必须要经过一个\"解冻\"时期。解除绑定之后，虚拟币为引起的数周到数月的同步猜想需要时间进行\"解冻\"（即延迟的消息）。\n- 禁止在N个块之前恢复，其中N是保证金的长度。 这个规则使任何长程分杈无效。\n- 可选择的将验证者集存放在PoW的链上\n![](/asset/ConsensusCompare2.png)\n\nCasper（s）和Tendermint采用一种简单的锁定机制（“Tendermint”中俗称“冻结”）来锁定股权一段时间（几周到几个月后“解冻”），以防止任何恶意联合验证者 违反安全。在CFFG算法中，一个分杈选择规则永远只能修改最终块之后的块阻止了远程攻击。通过使用时间戳，在CFFG中的长距离分叉试图修改比最终块还要更早的块的时候会被协议直接忽略掉。\n\n## 卡特尔形式\n第三，最后的障碍是面临任意价值的任何经济形式都将面对一个真正的寡头垄断问题，就算本土加密货币也不例外。\n\n*“加密货币令人难以置信的集中，挖矿算力也是一样。寡头垄断竞争是很多现实市场的常态。少数相对富有的验证者之间的协调比多数相对贫穷验证者之间的协调要容易的多。在我们这种情况下，卡特尔形式是完全被预料到的。”*\n——Vlad Zamfir，[*Casper的历史第4章节*](https://medium.com/@Vlad_Zamfir/the-history-of-casper-chapter-4-3855638b5f0e)\n\nTendermint依靠额外协议管理方法来与寡头垄断验证者进行对抗。虽然在审查制度方面没有任何协议措施，但依靠带外社会信息解决卡特尔形成，其中的基本原理是：用户最终将不可避免地注意到卡特尔的形成，社会上也会对此到处八卦，然后放弃或者投票重新组织受到攻击的区块链。\n\n到目前为止，Vlad的Casper协议是唯一一个明确使用共识内审查激励来打击卡特尔形式一种模式。\n\n## 概述\n有很多不同的方式来实现权益证明的算法，但是权益证明设计的两个主要原理是基于链的PoS和基于拜占庭容错(BFT)的PoS。Tendermint是基于拜占庭容错的PoS设计，CTFG是基于链的PoS设计，而CFFG则混合了两者。\n\n计算机科学中的[CAP理论](https://en.wikipedia.org/wiki/CAP_theorem)返回在分布式数据系统中提供超过2/3担保的不可能性：可用性、一致性、分区容错。基于链的PoS算法倾向于选择可用性高的而不选择一致性高的，因为可用性高意味着所有的交易都能被处理，不过要以牺牲整个网络中一致性状态复制为代价。基于BFT的却相反，会倾向于选择高一致性。\n\n### 基于BTF的权益证明\n拜占庭容错共识算法源于30多年的丰富研究。Tendermint（2014）是Castro和Liskov在1999年引入的实用拜占庭容错(PBFT)算法的第一个PoS的改编版。基于BFT的PoS协议伪随机的安排一个验证者在多轮投票的过程中提出一个区块。但是，提交和最终化区块取决于大多数——所有验证者中2/3的验证者在提交的区块中签名。在区块最终化之前可能需要进行几轮(译者注：这种多轮投票和现实世界的波尔卡舞蹈类似， 这也是polkadot 名字的由来)签名。BFT系统只能容错1/3的失败，其中失败包括故障或是恶意的攻击。\n\n### Tendermint核心\nTendermint主要包含两个主要的技术：区块链共识引擎和通用的应用接口。共识引擎被称为Tendermint核心模块，确保相同的交易在每个机器中都按照相同的顺序被记录下来。应用接口被称为应用区块链接口(ABCI)，让交易可以被任何编程语言编写的程序处理。\n\n在核心模块中，Tendermint基于循环投票机制进行工作，这也是共识协议的原理。一个回合被分成3个处理步骤：验证者提出一个块、发送提交意图、签名后提交一个新区块。这种机制为原子广播提供了一个安全的状态复制机，增加了一个责任层——安全故障可以完全归结于Tendermint。\n\nTendermint共识算法从验证者集开始。验证者们都维护了一份区块链的全拷贝，并且可以用公钥来识别验证者的身份。在每个新的块高度他们轮流的提出一个区块。每轮投票都只有一个验证者可以提出块，并且要用验证者相应的私钥对此进行签名，这样的话如果有错误发生就可以找到为此负责的验证者。然后剩下的验证者就需要对每个提议都进行投票，投票都需要用自己的私钥进行签名。这些组成一个回合。不过可能因为网络的异步需要好几个回合才能提交一个新块。\n![](/asset/ConsensusCompare3.jpeg)\n\n验证者提交块的时候由于几种原因可能会失败：当前的提议可能下线了，或者网络可能遇到了延迟。Tendermint允许验证者可以被跳过（就是轮到一个验证者出块的时候但是此验证者没出块）。验证者在移到下一轮投票之前等待一小段时间来接收提议者（此轮出块的验证者）提出的整个区块。这种对超时的依赖让Tendermint成为一个弱同步协议，而不是一个异步协议。不过，剩下的协议是异步的，并且验证者只有在接收到了超过2/3的验证者集消息时才会进行处理事物。正是因为这样，所以Tendermint需要大多数的验证者可以100%正常运行，如果1/3或更多的验证者离线或脱机，网路就会停止运行了。\n\n假设少于1/3的验证者是拜占庭，Tendermint保证安全永远不会被破坏——也就是，验证者（2/3以上）永远不会在同一个高度提交冲突的区块。因此，基于Temdermint的区块链永远不会分叉。\n\n目前为止，Tendermint的设计决策确实是把安全性和不可改变性地位放在了灵活性之上。在现实世界上有相当高的可能性是，系统真的会停止运行，参与者将会需要在协议外组织在某种软件上更新后重启系统。\n\n在数字加密货币社区中只有少数人理解 Casper以及为什么它很有价值的时候，Tendermint就为Casper研究奠定了基础。这个洞察力就是：如果一个链的本身是高度容错的，那么你就可以依赖链来对于谁来生产区块做出一个好的决定，但是如果链的本身就是不可靠的，那么你就陷入了鸡和鸡蛋的问题中去了，这也是之前所有其他共识算法的灭顶之灾。\n\n这个设计决策被认为不如可用性优先的协议例如以太坊和比特币。比特币中的权衡是：如果它的网络被分裂了，比特币在各种攻击的情况下就失去了它的安全保证。这其实就是一个不可修改理论，也就是你的置信区间是100%的时候，那么你跟随的就是一条正确的链，你会使用这条链来选择谁来生产下个区块，但是一旦你转移到一条不安全的链上之后，并没有一条明确的路径让你回到正确的链上。\n\n#### Tendermint的明确属性\n- 可证明的活跃性\n- 安全阈值：1/3的验证者\n- 公有/私有链相容\n- 即时的最终确定性：1-3秒，取决于验证者数量\n- 一致性优先\n- 在弱同步性网络的共识安全\n\n## 基于链的权益证明\n基于链的权益证明模仿了工作量证明共识算法，在此权益证明中协议让伪随机选择出来的验证者产生一个新块，新块是哈希连接（包含上个块的哈希值）到前一个最长链的父区块上。基于链的PoS非常依赖同步的网络，通常优先考虑可用性而非一致性。Casper(s)对于倾向于活跃性而非安全性环境而言，它就是Tendermint核心思想的一个改编。\n\n### CFFG\nCTFG是一个明确的PoS构造，但是CFFG是一个覆盖在已存在的以太坊PoW提议机制上的PoS——融合了PoW和PoS两者，由Vitalik Buterin带领实现。\n\n比特币和以太坊的PoW共识协议都不会做“最终”决定，并且区块可能会潜在的被重新组织到一些过去区块高度。当区块没有机会再被修改的时候才能称为“最终确定”的。因为工作量证明没有提供这样的修改保证，所以它被认为是共识不安全的。相反，当我们持续加长链的时候区块的最终确定性概率也越来越高。为了为以太坊区块链增加想要的最终确定性和51%的攻击阻力，CFFG实现的逻辑就完美的提供了这种效果。\n\nCFFG将通过多个步骤推出，以保守的方式将以太坊的PoW安全模式逐渐过渡到PoS安全模式。Casper的第一个迭代将会是实现这里讨论的混合PoW/PoS协议，Casper的最后一个迭代很有可能吸取CFFG和CTFG的教训，朝着一个完整的PoS协议发展。\n\nCFFG是基于链的PoS和基于BFT的PoS的之间的混合体，因为它吸取了两者的思想。它的模块化覆盖设计让现在的PoW链的更新变得更加容易，因为它对于将系统升级到完全不同的共识模式而言是一种更保守的方法。\n\nCasper的应用逻辑存在于智能合约的内部。要想在Casper中成为验证者，必须要有ETH并且要将ETH存储到Casper智能合约中作为杠杆的权益。在Casper第一次迭代中区块提议的机制会被保留：它依然使用Nakamoto PoW共识，矿工可以创建区块。不过为了最终化区块，Casper的PoS覆盖掌握控制权，并且拥有自己的验证者在PoW矿工之后进行投票。\n\nCasper的PoS共识最重要的一个部分就是检查点(checkpoints)。Casper在50区块增量的时候评估最终确定性就称之为检查点，每50个块片段就称之为周期(epoch)。通过验证者在每个周期发送投票消息时触发这个处理过程。\n\n在一个周期前最终化检查点需要2个周期才能完成，也就是需要两轮投票。例如，当超过2/3的验证者（也就是大多数）给一个检查点c投票了，那么就说这个检查点已经被\"审判\"了。下一个周期，当大多数人给检查点c投票了，会发生两件事情：c变成了被审判的并且c已经最终化了。c这个周期也就代表着最后一个最终化的周期(LFE)。\n\n回顾一下，一个区块最终化需要两个条件：\n\n- 大多数(超过2/3)验证者在周期1的时候给区块1进行了投票，因此审判了区块1\n- 大多数(超过2/3)验证者在周期2的时候给区块2进行了投票，区块2是区块1的子区块，因此在周期2的时候最终化了区块1\n\n在理想执行中，一个区块的最终化是按照下面的步骤的：\n> 区块1的2/3投票→审判区块1→2/3投票区块2→最终化区块1\n- 其中区块2是区块1的子区块\n![](/asset/ConsensusCompare4.png)\n\n当一个检查点被最终化之后验证者就会得到报酬。不过，如果有两个最终化的检查点在相同高度上分杈时，那么就破坏了安全性，这个时候就达到了消减的条件，最少1/3的保证金将会被消减掉。当安全性被破坏的时候可以将错误归因的证据当作交易广播给PoW的矿工。然后PoW就将这个证据交易组成一个区块来进行挖矿，提交了这个证据的验证者会得到查找者的费用。当此事发生的时候，签署了在冲突区块的有罪验证者将会在两条链上被消减掉。\n\n现在如果一个矿工进行蛮力攻击，那么会发生什么？现在Casper的最终化区块链可以防止PoW的攻击者，就算是51%或者更多的计算力重写最新检查点之外的历史也会被阻止。因此，Casper协议提供了安全。不像CTFG，因为CFFG就是不同提议机制上的一层覆盖，Casper不能确保活跃性，因为活跃性是取决于提议机制的。\n\n验证者是被激励着集合在权威链上的，因为如果他们持续在不同的链上进行投票将会受到惩罚。[slasher 2.0](https://docs.google.com/document/d/13_FSQ1Koq8uLvqTaSvZdb6OT2SpUZZq53vFiiDQj4qM/edit?usp=sharing)的形成让验证者不仅仅会为双重投票而受罚也要为在*不正确*的链上进行投票而受到惩罚。不过这也造成了一个“泄气”的窘境，因为验证者担心如果出现一个分杈而自己不确定到底哪个才是权威的，然后投错票之后被消减所以选择退出投票。\n\n#### CFFG的明确属性\n- 最终化：超过20分钟最终化。每隔50块（一个周期）就最终化一次区块，防止PoW挖矿暴利攻击\n- 共识安全性\n- 可证明的活跃性\n- 优先可用性\n\n### CTFG\nCTFG是Vlad Zamfir的正确构造(CBC)共识协议专用于对抗寡头垄断的真实世界的环境。CTFG是工作量证明中[GHOS](https://eprint.iacr.org/2013/881.pdf)或GHOST协议的PoS改编版，用于其分杈选择规则。CTFG背后的指导设计原则是基于加密经济学的，使用旨在实现评估安全的正规方法。与前面详细说明的CFFG混合协议不同，CTFG是纯粹的权益证明的概念。\n\n*“Casper刚刚开始的时候只是简单的‘友好的幽灵’，它对于PoS而言是GHOST的改编，完善的激励让卡特尔‘友善地’变成‘非卡特尔’的验证者。”*\n\n——Vlad Zamfir，[*Casper的历史第5章*](https://medium.com/@Vlad_Zamfir/the-history-of-casper-chapter-5-8652959cef58)\n\n与工作量证明类似，CTFG会为一致性和可用性进行权衡。特别，在区块没有被最终化的时候，随着在链中的深度越深的它们就会越安全。CTFG与CFFG有一点相似，链头部的处理总是比区块最终化的处理要快很多。\n\nCasper的PoS提议机制与Tendermint提议机制最大的区别是相比较伪随机选择领导者，前者的验证者可以基于自己见到的块提出块。\n\nCasper提供的一个独特功能是参数化安全阈值。与比特币中使用6个确认来确定一个经济最终状态类似，CTFG中的“评估安全”提供了一个验证者可以有一个与其他验证者不同的安全阈值功能。Casper的设计目标是在网络维持PoS低开销的时候能够允许验证者选择自己的容错阈值。\n\nCasper对Tendermint的核心优势在于网络随时可以容纳一定数量的验证者。因为Tendermint中的区块在创建的时候需要最终化，所以区块的确认时间应该短一点。为了达到短区块时间，Tendermint PoS能够容纳的验证者数量就需要有个限制。由于CTFG和CFFG到在区块创建的时候都不需要安全性，所以以太坊网络相对于cosmos容纳100个验证者来说，可以容纳验证者的数量会更加的多一点。\n\n#### CTFG的明确属性\n- 可用性。Casper的节点在它们达成共识之前可以块分杈\n- 异步安全性\n- 生存。Casper的决策可以在部分同步中存活，但是不能在异步中存活\n- 卡特尔阻力。Casper的整个前提是建立在抵制寡头垄断攻击者基础之上，因此不会有任何勾结的验证者可以超越协议\n- 安全性。取决于每个验证者的评估安全阈值\n\n## 未来的工作\n公链在产品上运行是一个比较新生的技术。在这个范例中到目前为止显示出不会腐败的唯一安全模型就是工作量证明。权益证明的设计空间还非常的大，而且工程学上权衡的理解也远远不够，因为权益证明是一个研究前沿也没有足够的数据。不用多说，要达到一个最佳的PoS共识算法，我们还有很多未来工作需要完成。\n\nTendermint的一个改进可能是新的提出机制，或者将Tendermint的多轮投票过程压缩成一轮投票。\n\n第二个未来工作的领域可能是利用更高级的加密技术让区块头的签名更小一点。因为我们是通过Cosmos来建立一个“区块链的互联网”，所以将轻客户端证明从一条链上移到另一条链上就是我们的核心工作。从这个观点来看的话，使用更加高级的密码学将区块头的大小减少三十倍或者更多是非常有利的。目前，100验证者，Tendermint的区块头接近4KB，它们都是验证者的签名。我们可以使用高级的加密技术让100个签名从3.2KB减少到64字节。\n\n还有一些优化p2p层的方法，这样我们就可以显著减少点对点需要最终化块的流量。在未来的工作中，不仅仅是压缩区块头中的数据量，还会减少发送到对端的数据量。这样的话，在Cosmos网络初始100个验证者的阈值之上，Tendermint还可以增加更大的验证者集。\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n翻译校对：[郭光华](https://gguoss.github.io/)\n原文地址：[Consensus Compare: Casper vs. Tendermint](https://blog.cosmos.network/consensus-compare-casper-vs-tendermint-6df154ad56ae)\n\n\n\n\n\n\n\n\n\n \n\n","tags":["Consensus"],"categories":["translation"]},{"title":"深入了解以太坊虚拟机","url":"/evm_part1.html","content":"** **  <Excerpt in index | Homepage Digest>\n\n深入了解以太坊虚拟机是一个系列的文章，一共5篇！ 本文是第1篇，主要介绍的是以太坊虚拟机汇编代码基础。后续的4篇译文链接在本文的结尾处。\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n![](http://upload-images.jianshu.io/upload_images/8388873-16fc12cd8a9b1992.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nSolidity提供了很多高级语言的抽象概念，但是这些特性让人很难明白在运行程序的时候到底发生了什么。我阅读了Solidity的文档，但依旧存在着几个基本的问题没有弄明白。\n\n*string, bytes32, byte[], bytes之间的区别是什么？*\n- 该在什么地方使用哪个类型？\n- 将 string 转换成bytes时会怎么样？可以转换成byte[]吗？\n- 它们的存储成本是多少？\n\n*EVM是如何存储映射( mappings)的？*\n- 为什么不能删除一个映射？\n- 可以有映射的映射吗？(可以，但是怎样映射？)\n- 为什么存在存储映射，但是却没有内存映射？\n\n*编译的合约在EVM看来是什么样子的？*\n- 合约是如何创建的？\n- 到底什么是构造器？\n- 什么是 fallback 函数？\n\n我觉得学习在以太坊虚拟机(EVM)上运行的类似Solidity 高级语言是一种很好的投资，有几个原因：\n1. *Solidity不是最后一种语言*。更好的EVM语言正在到来。（拜托？）\n2. *EVM是一个数据库引擎*。要理解智能合约是如何以任意EVM语言来工作的，就必须要明白数据是如何被组织的，被存储的，以及如何被操作的。\n3. *知道如何成为贡献者。*以太坊的工具链还处于早期，理解EVM可以帮助你实现一个超棒的工具给自己和其他人使用。\n4. *智力的挑战。*EVM可以让你有个很好的理由在密码学、数据结构、编程语言设计的交集之间进行翱翔。\n\n在这个系列的文章中，我会拆开一个简单的Solidity合约，来让大家明白它是如何以EVM字节码(bytecode)来运行的。\n\n我希望能够学习以及会书写的文章大纲：\n- EVM字节码的基础认识\n- 不同类型(映射，数组)是如何表示的\n- 当一个新合约创建之后会发生什么\n- 当一个方法被调用时会发生什么\n- ABI如何桥接不同的EVM语言\n\n我的最终目标是整体的理解一个编译的Solidity合约。让我们从阅读一些基本的EVM字节码开始。\n\n[EVM指令集](https://gist.github.com/hayeah/bd37a123c02fecffbe629bf98a8391df)将是一个比较有帮助的参考。\n\n## 一个简单的合约\n我们的第一个合约有一个构造器和一个状态变量：\n```\n// c1.sol\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    function C() {\n      a = 1;\n    }\n}\n```\n用`solc`来编译此合约：\n```\n$ solc --bin --asm c1.sol\n======= c1.sol:C =======\nEVM assembly:\n    /* \"c1.sol\":26:94  contract C {... */\n  mstore(0x40, 0x60)\n    /* \"c1.sol\":59:92  function C() {... */\n  jumpi(tag_1, iszero(callvalue))\n  0x0\n  dup1\n  revert\ntag_1:\ntag_2:\n    /* \"c1.sol\":84:85  1 */\n  0x1\n    /* \"c1.sol\":80:81  a */\n  0x0\n    /* \"c1.sol\":80:85  a = 1 */\n  dup2\n  swap1\n  sstore\n  pop\n    /* \"c1.sol\":59:92  function C() {... */\ntag_3:\n    /* \"c1.sol\":26:94  contract C {... */\ntag_4:\n  dataSize(sub_0)\n  dup1\n  dataOffset(sub_0)\n  0x0\n  codecopy\n  0x0\n  return\nstop\nsub_0: assembly {\n        /* \"c1.sol\":26:94  contract C {... */\n      mstore(0x40, 0x60)\n    tag_1:\n      0x0\n      dup1\n      revert\nauxdata: 0xa165627a7a72305820af3193f6fd31031a0e0d2de1ad2c27352b1ce081b4f3c92b5650ca4dd542bb770029\n}\nBinary:\n60606040523415600e57600080fd5b5b60016000819055505b5b60368060266000396000f30060606040525b600080fd00a165627a7a72305820af3193f6fd31031a0e0d2de1ad2c27352b1ce081b4f3c92b5650ca4dd542bb770029\n```\n`6060604052...`这串数字就是EVM实际运行的字节码。\n\n##  一小步一小步的来\n上面一半的编译汇编是大多数Solidity程序中都会存在的样板语句。我们稍后再来看这些。现在，我们来看看合约中独特的部分，简单的存储变量赋值：\n```\na = 1\n```\n代表这个赋值的字节码是`6001600081905550`。我们把它拆成一行一条指令：\n```\n60 01\n60 00\n81\n90\n55\n50\n```\nEVM本质上就是一个循环，从上到下的执行每一条命令。让我们用相应的字节码来注释汇编代码(缩进到标签`tag_2`下)，来更好的看看他们之间的关联：\n```\ntag_2:\n  // 60 01\n  0x1\n  // 60 00\n  0x0\n  // 81\n  dup2\n  // 90\n  swap1\n  // 55\n  sstore\n  // 50\n  pop\n```\n注意`0x1`在汇编代码中实际上是`push(0x1)`的速记。这条指令将数值1压入栈中。\n\n只是盯着它依然很难明白到底发生了什么，不过不用担心，一行一行的模拟EVM是比较简单的。\n\n## 模拟EVM\nEVM是个堆栈机器。指令可能会使用栈上的数值作为参数，也会将值作为结果压入栈中。让我们来思考一下`add`操作。\n\n假设栈上有两个值：\n```\n[1 2]\n```\n当EVM看见了`add`，它会将栈顶的2项相加，然后将答案压入栈中，结果是：\n```\n[3]\n```\n接下来，我们用`[]`符号来标识栈：\n```\n// 空栈\nstack: []\n// 有3个数据的栈，栈顶项为3，栈底项为1\nstack: [3 2 1]\n```\n用`{}`符号来标识合约存储器：\n```\n// 空存储\nstore: {}\n// 数值0x1被保存在0x0的位置上\nstore: { 0x0 => 0x1 }\n```\n现在让我们来看看真正的字节码。我们将会像EVM那样来模拟`6001600081905550`字节序列，并打印出每条指令的机器状态：\n```\n// 60 01:将1压入栈中\n0x1\n  stack: [0x1]\n// 60 00: 将0压入栈中\n0x0\n  stack: [0x0 0x1]\n// 81: 复制栈中的第二项\ndup2\n  stack: [0x1 0x0 0x1]\n// 90: 交换栈顶的两项数据\nswap1\n  stack: [0x0 0x1 0x1]\n// 55: 将数值0x01存储在0x0的位置上\n// 这个操作会消耗栈顶两项数据\nsstore\n  stack: [0x1]\n  store: { 0x0 => 0x1 }\n// 50: pop (丢弃栈顶数据)\npop\n  stack: []\n  store: { 0x0 => 0x1 }\n```\n最后，栈就为空栈，而存储器里面有一项数据。\n\n值得注意的是Solidity已经决定将状态变量`uint256 a`保存在`0x0`的位置上。其他语言完全可以选择将状态变量存储在其他的任何位置上。\n\n`6001600081905550`字节序列在本质上用EVM的操作伪代码来表示就是：\n```\n// a = 1\nsstore(0x0, 0x1)\n```\n仔细观察，你就会发现`dup2`，`swap1`，`pop`都是多余的，汇编代码可以更简单一些：\n```\n0x1\n0x0\nsstore\n```\n你可以模拟上面的3条指令，然后会发现他们的机器状态结果都是一样的：\n```\nstack: []\nstore: { 0x0 => 0x1 }\n```\n\n## 两个存储变量\n让我们再额外的增加一个相同类型的存储变量：\n```\n// c2.sol\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    uint256 b;\n    function C() {\n      a = 1;\n      b = 2;\n    }\n}\n```\n编译之后，主要来看`tag_2`：\n```\n$ solc --bin --asm c2.sol\n//前面的代码忽略了\ntag_2:\n    /* \"c2.sol\":99:100  1 */\n  0x1\n    /* \"c2.sol\":95:96  a */\n  0x0\n    /* \"c2.sol\":95:100  a = 1 */\n  dup2\n  swap1\n  sstore\n  pop\n    /* \"c2.sol\":112:113  2 */\n  0x2\n    /* \"c2.sol\":108:109  b */\n  0x1\n    /* \"c2.sol\":108:113  b = 2 */\n  dup2\n  swap1\n  sstore\n  pop\n```\n汇编的伪代码：\n```\n// a = 1\nsstore(0x0, 0x1)\n// b = 2\nsstore(0x1, 0x2)\n```\n我们可以看到两个存储变量的存储位置是依次排列的，`a`在`0x0`的位置而`b`在`0x1`的位置。\n\n## 存储打包\n每个存储槽都可以存储32个字节。如果一个变量只需要16个字节但是使用全部的32个字节会很浪费。Solidity为了高效存储，提供了一个优化方案：如果可以的话，就将两个小一点的数据类型进行打包然后存储在一个存储槽中。\n\n我们将`a`和`b`修改成16字节的变量：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint128 a;\n    uint128 b;\n    function C() {\n      a = 1;\n      b = 2;\n    }\n}\n```\n编译此合约：\n```\n$ solc --bin --asm c3.sol\n```\n产生的汇编代码现在更加的复杂一些：\n```\ntag_2:\n  // a = 1\n  0x1\n  0x0\n  dup1\n  0x100\n  exp\n  dup2\n  sload\n  dup2\n  0xffffffffffffffffffffffffffffffff\n  mul\n  not\n  and\n  swap1\n  dup4\n  0xffffffffffffffffffffffffffffffff\n  and\n  mul\n  or\n  swap1\n  sstore\n  pop\n  // b = 2\n  0x2\n  0x0\n  0x10\n  0x100\n  exp\n  dup2\n  sload\n  dup2\n  0xffffffffffffffffffffffffffffffff\n  mul\n  not\n  and\n  swap1\n  dup4\n  0xffffffffffffffffffffffffffffffff\n  and\n  mul\n  or\n  swap1\n  sstore\n  pop\n```\n上面的汇编代码将这两个变量打包放在一个存储位置(`0x0`)上，就像这样：\n```\n[         b         ][         a         ]\n[16 bytes / 128 bits][16 bytes / 128 bits]\n```\n进行打包的原因是因为目前最昂贵的操作就是存储的使用：\n- `sstore`指令第一次写入一个新位置需要花费20000 gas\n- `sstore`指令后续写入一个已存在的位置需要花费5000 gas\n- `sload`指令的成本是500 gas\n- 大多数的指令成本是3~10 gas\n\n通过使用相同的存储位置，Solidity为存储第二个变量支付5000 gas，而不是20000 gas，节约了15000 gas。\n\n## 更多优化\n应该可以将两个128位的数打包成一个数放入内存中，然后使用一个'sstore'指令进行存储操作，而不是使用两个单独的`sstore`命令来存储变量`a`和`b`，这样就额外的又省了5000 gas。\n\n你可以通过添加`optimize`选项来让Solidity实现上面的优化：\n```\n$ solc --bin --asm --optimize c3.sol\n```\n这样产生的汇编代码只有一个`sload`指令和一个`sstore`指令:\n```\ntag_2:\n    /* \"c3.sol\":95:96  a */\n  0x0\n    /* \"c3.sol\":95:100  a = 1 */\n  dup1\n  sload\n    /* \"c3.sol\":108:113  b = 2 */\n  0x200000000000000000000000000000000\n  not(sub(exp(0x2, 0x80), 0x1))\n    /* \"c3.sol\":95:100  a = 1 */\n  swap1\n  swap2\n  and\n    /* \"c3.sol\":99:100  1 */\n  0x1\n    /* \"c3.sol\":95:100  a = 1 */\n  or\n  sub(exp(0x2, 0x80), 0x1)\n    /* \"c3.sol\":108:113  b = 2 */\n  and\n  or\n  swap1\n  sstore\n```\n字节码是：\n```\n600080547002000000000000000000000000000000006001608060020a03199091166001176001608060020a0316179055\n```\n将字节码解析成一行一指令：\n```\n// push 0x0\n60 00\n// dup1\n80\n// sload\n54\n// push17 将下面17个字节作为一个32个字的数值压入栈中\n70 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n/* not(sub(exp(0x2, 0x80), 0x1)) */\n// push 0x1\n60 01\n// push 0x80 (32)\n60 80\n// push 0x80 (2)\n60 02\n// exp\n0a\n// sub\n03\n// not\n19\n// swap1\n90\n// swap2\n91\n// and\n16\n// push 0x1\n60 01\n// or\n17\n/* sub(exp(0x2, 0x80), 0x1) */\n// push 0x1\n60 01\n// push 0x80\n60 80\n// push 0x02\n60 02\n// exp\n0a\n// sub\n03\n// and\n16\n// or\n17\n// swap1\n90\n// sstore\n55\n```\n上面的汇编代码中使用了4个神奇的数值：\n- 0x1(16字节)，使用低16字节\n```\n// 在字节码中表示为0x01\n16:32 0x00000000000000000000000000000000\n00:16 0x00000000000000000000000000000001\n```\n- 0x2(16字节)，使用高16字节\n```\n//在字节码中表示为0x200000000000000000000000000000000 \n16:32 0x00000000000000000000000000000002\n00:16 0x00000000000000000000000000000000\n```\n- not(sub(exp(0x2, 0x80), 0x1))\n```\n// 高16字节的掩码\n16:32 0x00000000000000000000000000000000 \n00:16 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\n```\n- sub(exp(0x2, 0x80), 0x1)\n```\n// 低16字节的掩码\n16:32 0x00000000000000000000000000000000 \n00:16 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\n```\n代码将这些数值进行了一些位的转换来达到想要的结果：\n```\n16:32 0x00000000000000000000000000000002 \n00:16 0x00000000000000000000000000000001\n```\n最后，该32字节的数值被保存在了`0x0`的位置上。\n\n## Gas 的使用\n> 60008054700**200000000000000000000000000000000**6001608060020a03199091166001176001608060020a0316179055\n\n注意`0x200000000000000000000000000000000`被嵌入到了字节码中。但是编译器也可能选择使用`exp(0x2, 0x81)`指令来计算数值，这会导致更短的字节码序列。\n\n但结果是`0x200000000000000000000000000000000`比`exp(0x2, 0x81)`更便宜。让我们看看与gas费用相关的信息：\n- 一笔交易的每个零字节的数据或代码费用为 4 gas\n- 一笔交易的每个非零字节的数据或代码的费用为 68 gas\n\n来计算下两个表示方式所花费的gas成本：\n- `0x200000000000000000000000000000000`字节码包含了很多的0，更加的便宜。\n(1 * 68) + (32 * 4) = 196\n\n- `608160020a`字节码更短，但是没有0。\n5 * 68 = 340\n\n更长的字节码序列有很多的0，所以实际上更加的便宜！\n\n## 总结\nEVM的编译器实际上不会为字节码的大小、速度或内存高效性进行优化。相反，它会为gas的使用进行优化，这间接鼓励了计算的排序，让以太坊区块链可以更高效一点。\n\n我们也看到了EVM一些奇特的地方：\n- EVM是一个256位的机器。以32字节来处理数据是最自然的\n- 持久存储是相当昂贵的\n- Solidity编译器会为了减少gas的使用而做出相应的优化选择\n\nGas成本的设置有一点武断，也许未来会改变。当成本改变的时候，编译器也会做出不同的优化选择。\n\n本系列文章其他部分译文链接：\n- [固定长度数据类型的表示方法(第2部分)](http://www.jianshu.com/p/9df8d15418ed)\n- [动态数据类型的表示方法(第3部分)](http://www.jianshu.com/p/af5721c79505)\n- [ABI编码外部方法调用的方式(第4部分)](http://www.jianshu.com/p/d0e8e825d41b)\n- [一个新合约被创建后会发生什么(第5部分)](http://www.jianshu.com/p/d9137e87c9d3)\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[Diving Into The Ethereum VM Part One](https://medium.com/@hayeah/diving-into-the-ethereum-vm-6e8d5d2f3c30)\n","tags":["ethereum"],"categories":["translation"]},{"title":"深入了解以太坊虚拟机第2部分——固定长度数据类型的表示方法","url":"/evm_part2.html","content":"** **  <Excerpt in index | Homepage Digest>\n\n深入了解以太坊虚拟机是一个系列的文章，本文是第2篇，本系列其他部分的译文链接在文章结尾处\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n![Micron MT4C1024](/asset/evmp2_head.jpeg)\n\n在本系列的第一篇文章中，我们已经看到了一个简单的Solidity合约的汇编代码：\n```\ncontract C {\n    uint256 a;\n    function C() {\n      a = 1;\n    }\n}\n```\n该合约归结于`sstore`指令的调用：\n```\n// a = 1\nsstore(0x0, 0x1)\n```\n- EVM将`0x1`数值存储在`0x0`的位置上\n- 每个存储槽可以存储正好32字节(或256位)\n> 如果你觉得这看起来很陌生，我建议你阅读本系列的第一篇文章：[EVM汇编代码的介绍](http://www.jianshu.com/p/1969f3761208)\n\n在本文中我们将会开始研究Solidity如何使用32字节的块来表示更加复杂的数据类型如结构体和数组。我们也将会看到存储是如何被优化的，以及优化是如何失败的。\n\n在典型编程语言中理解数据类型在底层是如何表示的没有太大的作用。但是在Solidity(或其他的EVM语言)中，这个知识点是非常重要的，因为存储的访问是非常昂贵的：\n- `sstore`指令成本是20000 gas，或比基本的算术指令要贵~5000x\n- `sload`指令成本是5000 gas，或比基本的算术指令要贵~1600x\n\n这里说的成本，就是真正的金钱，而不仅仅是毫秒级别的性能。运行和使用合约的成本基本上是由`sstore`指令和`sload`指令来主导的！\n\n## Parsecs磁带上的Parsecs\n\n![图林机器，来源：http://raganwald.com/](/asset/evmp2_parsecs.jpeg)\n\n构建一个通用计算机器需要两个基本要素：\n- 一种循环的方式，无论是跳转还是递归\n- 无限量的内存\n\n\nEVM的汇编代码有跳转，EVM的存储器提供无限的内存。这对于一切就已经足够了，包括模拟一个运行以太坊的世界，这个世界本身就是一个模拟运行以太坊的世界.........\n\n![进入Microverse电池](/asset/evmp2_ microverse.gif)\n\nEVM的存储器对于合约来说就像一个无限的自动收报机磁带，磁带上的每个槽都能存储32个字节，就像这样：\n```\n[32 bytes][32 bytes][32 bytes]...\n```\n我们将会看到数据是如何在无限的磁带中生存的。\n> 磁带的长度是2²⁵⁶，或者每个合约~10⁷⁷存储槽。可观测的宇宙粒子数是10⁸⁰。大概1000个合约就可以容纳所有的质子、中子和电子。不要相信营销炒作，因为它比无穷大要短的多。\n\n## 空磁带\n存储器初始的时候是空白的，默认是0。拥有无限的磁带不需要任何的成本。\n\n以一个简单的合约来演示一下0值的行为：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    uint256 b;\n    uint256 c;\n    uint256 d;\n    uint256 e;\n    uint256 f;\n    function C() {\n      f = 0xc0fefe;\n    }\n}\n```\n存储器中的布局很简单。\n- 变量`a`在`0x0`的位置上\n- 变量`b`在`0x1`的位置上\n- 以此类推.........\n\n关键问题是：如果我们只使用`f`，我们需要为`a`，`b`，`c`，`d`，`e`支付多少成本？\n\n编译一下再看：\n```\n$ solc --bin --asm --optimize c-many-variables.sol\n```\n汇编代码：\n```\n// sstore(0x5, 0xc0fefe)\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n```\n所以一个存储变量的声明不需要任何成本，因为没有初始化的必要。Solidity为存储变量保留了位置，但是只有当你存储数据进去的时候才需要进行付费。\n\n这样的话，我们只需要为存储`0x5`进行付费。\n\n如果我们手动编写汇编代码的话，我们可以选择任意的存储位置，而用不着\"扩展\"存储器：\n```\n// 编写一个任意的存储位置\nsstore(0xc0fefe, 0x42)\n```\n## 读取零\n你不仅可以写在存储器的任意位置，你还可以立刻读取任意的位置。从一个未初始化的位置读取只会返回`0x0`。\n\n让我们看看一个合约从一个未初始化的位置`a`读取数据：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    function C() {\n      a = a + 1;\n    }\n}\n```\n编译：\n```\n$ solc --bin --asm --optimize c-zero-value.sol\n```\n汇编代码：\n```\ntag_2:\n  // sload(0x0) returning 0x0\n  0x0\n  dup1\n  sload\n  // a + 1; where a == 0\n  0x1\n  add\n  // sstore(0x0, a + 1)\n  swap1\n  sstore\n```\n注意生成从一个未初始化的位置`sload`的代码是无效的。\n\n然而，我们可以比Solidity编译器聪明。既然我们知道`tag_2`是构造器，而且`a`从未被写入过数据，那么我们可以用`0x0`替换掉`sload`，以此节省5000 gas。\n\n## 结构体的表示\n来看一下我们的第一个复杂数据类型，一个拥有6个域的结构体：\n```\npragma solidity ^0.4.11;\ncontract C {\n    struct Tuple {\n      uint256 a;\n      uint256 b;\n      uint256 c;\n      uint256 d;\n      uint256 e;\n      uint256 f;\n    }\n    Tuple t;\n    function C() {\n      t.f = 0xC0FEFE;\n    }\n}\n```\n存储器中的布局和状态变量是一样的：\n- `t.a`域在`0x0`的位置上\n- `t.b`域在`0x1`的位置上\n- 以此类推.........\n\n就像之前一样，我们可以直接写入`t.f`而不用为初始化付费。\n\n编译一下：\n```\n$ solc --bin --asm --optimize c-struct-fields.sol\n```\n然后我们看见一模一样的汇编代码：\n```\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n```\n### 固定长度数组\n让我们来声明一个定长数组：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint256[6] numbers;\n    function C() {\n      numbers[5] = 0xC0FEFE;\n    }\n}\n```\n因为编译器知道这里到底有几个`uint256`(32字节)类型的数值，所以它可以很容易让数组里面的元素依次存储起来，就像它存储变量和结构体一样。\n\n在这个合约中，我们再次存储到`0x5`的位置上。\n\n编译：\n```\n$ solc --bin --asm --optimize c-static-array.sol\n```\n汇编代码：\n```\ntag_2:\n  0xc0fefe\n  0x0\n  0x5\ntag_4:\n  add\n  0x0\ntag_5:\n  pop\n  sstore\n```\n这个稍微长一点，但是如果你仔细一点，你会看见它们其实是一样的。我们手动的来优化一下：\n```\ntag_2:\n  0xc0fefe\n  // 0+5. 替换为0x5\n  0x0\n  0x5\n  add\n  // 压入栈中然后立刻出栈。没有作用，只是移除\n  0x0\n  pop\n  sstore\n```\n移除掉标记和伪指令之后，我们再次得到相同的字节码序列：\n```\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n```\n## 数组边界检查\n我们看到了定长数组、结构体和状态变量在存储器中的布局是一样的，但是产生的汇编代码是不同的。这是因为Solidity为数组的访问产生了边界检查代码。\n\n让我们再次编译数组合约，这次去掉优化的选项：\n```\n$ solc --bin --asm c-static-array.sol\n```\n汇编代码在下面已经注释了，并且打印出每条指令的机器状态：\n```\ntag_2:\n  0xc0fefe\n    [0xc0fefe]\n  0x5\n    [0x5 0xc0fefe]\n  dup1\n  /* 数组边界检查代码 */\n  // 5 < 6\n  0x6\n    [0x6 0x5 0xc0fefe]\n  dup2\n    [0x5 0x6 0x5 0xc0fefe]\n  lt\n    [0x1 0x5 0xc0fefe]\n  // bound_check_ok = 1 (TRUE)\n  // if(bound_check_ok) { goto tag5 } else { invalid }\n  tag_5\n    [tag_5 0x1 0x5 0xc0fefe]\n  jumpi\n    // 测试条件为真，跳转到 tag_5.\n    //  `jumpi` 从栈中消耗两项数据\n    [0x5 0xc0fefe]\n  invalid\n// 数据访问有效，继续执行\n// stack: [0x5 0xc0fefe]\ntag_5:\n  sstore\n    []\n    storage: { 0x5 => 0xc0fefe }\n```\n我们现在已经看见了边界检查代码。我们也看见了编译器可以对这类东西进行一些优化，但是不是非常完美。\n\n在本文的后面我们将会看到数组的边界检查是如何干扰编译器优化的，比起存储变量和结构体，定长数组的效率更低。\n\n## 打包行为\n存储是非常昂贵的（呀呀呀，这句话我已经说了无数次了）。一个关键的优化就是尽可能的将数据打包成一个32字节数值。\n\n考虑一个有4个存储变量的合约，每个变量都是64位，全部加起来就是256位（32字节）：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint64 a;\n    uint64 b;\n    uint64 c;\n    uint64 d;\n    function C() {\n      a = 0xaaaa;\n      b = 0xbbbb;\n      c = 0xcccc;\n      d = 0xdddd;\n    }\n}\n```\n我们期望（希望）编译器使用一个`sstore`指令将这些数据存放到同一个存储槽中。\n\n编译：\n```\n$ solc --bin --asm --optimize c-many-variables--packing.sol\n```\n汇编代码：\n```\ntag_2:\n    /* \"c-many-variables--packing.sol\":121:122  a */\n  0x0\n    /* \"c-many-variables--packing.sol\":121:131  a = 0xaaaa */\n  dup1\n  sload\n    /* \"c-many-variables--packing.sol\":125:131  0xaaaa */\n  0xaaaa\n  not(0xffffffffffffffff)\n    /* \"c-many-variables--packing.sol\":121:131  a = 0xaaaa */\n  swap1\n  swap2\n  and\n  or\n  not(sub(exp(0x2, 0x80), exp(0x2, 0x40)))\n    /* \"c-many-variables--packing.sol\":139:149  b = 0xbbbb */\n  and\n  0xbbbb0000000000000000\n  or\n  not(sub(exp(0x2, 0xc0), exp(0x2, 0x80)))\n    /* \"c-many-variables--packing.sol\":157:167  c = 0xcccc */\n  and\n  0xcccc00000000000000000000000000000000\n  or\n  sub(exp(0x2, 0xc0), 0x1)\n    /* \"c-many-variables--packing.sol\":175:185  d = 0xdddd */\n  and\n  0xdddd000000000000000000000000000000000000000000000000\n  or\n  swap1\n  sstore\n```\n这里还是有很多的位转移我没能弄明白，但是无所谓。最关键事情是这里只有一个`sstore`指令。\n\n这样优化就成功！\n\n## 干扰优化器\n优化器并不能一直工作的这么好。让我们来干扰一下优化器。唯一的改变就是使用协助函数来设置存储变量：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint64 a;\n    uint64 b;\n    uint64 c;\n    uint64 d;\n    function C() {\n      setAB();\n      setCD();\n    }\n    function setAB() internal {\n      a = 0xaaaa;\n      b = 0xbbbb;\n    }\n    function setCD() internal {\n      c = 0xcccc;\n      d = 0xdddd;\n    }\n}\n```\n编译：\n```\n$ solc --bin --asm --optimize c-many-variables--packing-helpers.sol\n```\n输出的汇编代码太多了，我们忽略了大多数的细节，只关注结构体：\n```\n// 构造器函数\ntag_2:\n  // ...\n  // 通过跳到tag_5来调用setAB()\n  jump\ntag_4:\n  // ...\n  //通过跳到tag_7来调用setCD() \n  jump\n// setAB()函数\ntag_5:\n  // 进行位转移和设置a，b\n  // ...\n  sstore\ntag_9:\n  jump  // 返回到调用setAB()的地方\n//setCD()函数\ntag_7:\n  // 进行位转移和设置c，d\n  // ...\n  sstore\ntag_10:\n  jump  // 返回到调用setCD()的地方\n```\n现在这里有两个`sstore`指令而不是一个。Solidity编译器可以优化一个标签内的东西，但是无法优化跨标签的。\n\n调用函数会让你消耗更多的成本，不是因为函数调用昂贵（他们只是一个跳转指令），而是因为`sstore`指令的优化可能会失败。\n\n为了解决这个问题，Solidity编译器应该学会如何內联函数，本质上就是不用调用函数也能得到相同的代码：\n```\na = 0xaaaa;\nb = 0xbbbb;\nc = 0xcccc;\nd = 0xdddd;\n```\n> 如果我们仔细阅读输出的完整汇编代码，我们会看见`setAB()`和`setCD()`函数的汇编代码被包含了两次，不仅使代码变得臃肿了，并且还需要花费额外的gas来部署合约。在学习合约的生命周期时我们再来谈谈这个问题。\n\n## 为什么优化器会被干扰？\n因为优化器不会跨标签进行优化。思考一下\"1+1\"，在同一个标签下，它会被优化成`0x2`:\n```\n// 优化成功！\ntag_0:\n  0x1\n  0x1\n  add\n  ...\n```\n但是如果指令被标签分开的话就不会被优化了：\n```\n// 优化失败！\ntag_0:\n  0x1\n  0x1\ntag_1:\n  add\n  ...\n```\n在0.4.13版本中上面的行为都是真实的。也许未来会改变。\n\n## 再次干扰优化器\n让我们看看优化器失败的另一种方式，打包适用于定长数组吗？思考一下：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint64[4] numbers;\n    function C() {\n      numbers[0] = 0x0;\n      numbers[1] = 0x1111;\n      numbers[2] = 0x2222;\n      numbers[3] = 0x3333;\n    }\n}\n```\n再一次，这里有4个64位的数值我们希望能打包成一个32位的数值，只使用一个`sstore`指令。\n\n编译的汇编代码太长了，我们就数数`sstore`和`sload`指令的条数：\n```\n$ solc --bin --asm --optimize c-static-array--packing.sol | grep -E '(sstore|sload)'\n  sload\n  sstore\n  sload\n  sstore\n  sload\n  sstore\n  sload\n  sstore\n```\n哦，不！即使定长数组与等效的结构体和存储变量的存储布局是一样的，优化也失败了。现在需要4对`sload`和`sstore`指令。\n\n快速的看一下汇编代码，可以发现每个数组的访问都有一个边界检查代码，它们在不同的标签下被组织起来。优化无法跨标签，所以优化失败。\n\n不过有个小安慰。其他额外的3个`sstore`指令比第一个要便宜：\n- `sstore`指令第一次写入一个新位置需要花费 20000 gas\n- `sstore`指令后续写入一个已存在的位置需要花费 5000 gas\n\n所以这个特殊的优化失败会花费我们35000 gas而不是20000 gas，多了额外的75%。\n\n## 总结\n如果Solidity编译器能弄清楚存储变量的大小，它就会将这些变量依次的放入存储器中。如果可能的话，编译器会将数据紧密的打包成32字节的块。\n\n总结一下目前我们见到的打包行为：\n- 存储变量：打包\n- 结构体：打包\n- 定长数组：不打包。在理论上应该是打包的\n\n因为存储器访问的成本较高，所以你应该将存储变量作为自己的数据库模式。当写一个合约时，做一个小实验是比较有用的，检测汇编代码看看编译器是否进行了正确的优化。\n\n我们可以肯定Solidity编译器在未来肯定会改良。对于现在而言，很不幸，我们不能盲目的相信它的优化器。\n\n它需要你真正的理解存储变量。\n\n本系列文章其他部分译文链接：\n- [EVM汇编代码的介绍(第1部分)](http://www.jianshu.com/p/1969f3761208)\n- [动态数据类型的表示方法(第3部分)](http://www.jianshu.com/p/af5721c79505)\n- [ABI编码外部方法调用的方式(第4部分)](http://www.jianshu.com/p/d0e8e825d41b)\n- [一个新合约被创建后会发生什么(第5部分)](http://www.jianshu.com/p/d9137e87c9d3)\n\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[Diving Into The Ethereum VM Part  Two](https://medium.com/@hayeah/diving-into-the-ethereum-vm-part-2-storage-layout-bc5349cb11b7)","tags":["ethereum"],"categories":["translation"]},{"title":"深入了解以太坊虚拟机第3部分——动态数据类型的表示方法","url":"/evm_part3.html","content":"** **  <Excerpt in index | Homepage Digest>\n\n深入了解以太坊虚拟机是一个系列的文章，本文是第3篇，本系列其他部分的译文链接在文章结尾处\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n![](/asset/evmp3_head.jpeg) \n\nSolidity提供了在其他编程语言常见的数据类型。除了简单的值类型比如数字和结构体，还有一些其他数据类型，随着数据的增加可以进行动态扩展的动态类型。动态类型的3大类：\n- 映射(Mappings)：`mapping(bytes32 => uint256)`， `mapping(address => string)`等等\n- 数组(Arrays)：`[]uint256`，`[]byte`等等\n- 字节数组(Byte arrays)：只有两种类型：`string`，`bytes`\n\n在本系列的第二篇文章中我们看见了固定大小的简单类型在内存中的表示方式。\n- 基本数值：`uint256`，`byte`等等\n- 定长数组：`[10]uint8`，`[32]byte`，`bytes32`\n- 组合了上面类型的结构体\n\n固定大小的存储变量都是尽可能的打包成32字节的块然后依次存放在存储器中的。（如果这看起来很陌生，请阅读本系列的第二篇文章： [固定长度数据类型的表示方法](http://www.jianshu.com/p/9df8d15418ed)\n\n在本文中我们将会研究Solidity是如何支持更加复杂的数据结构的。在表面上看可能Solidity中的数组和映射比较熟悉，但是从它们的实现方式来看在本质上却有着不同的性能特征。\n\n我们会从映射开始，这是三者当中最简单的。数组和字节数组其实就是拥有更加高级特征的映射。\n\n## 映射\n让我们存储一个数值在`uint256 => uint256`映射中：\n```\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 => uint256) items;\n    function C() {\n      items[0xC0FEFE] = 0x42;\n    }\n}\n```\n编译：\n```\nsolc --bin --asm --optimize c-mapping.sol\n```\n汇编代码：\n```\ntag_2:\n  // 不做任何事情，应该会被优化掉\n  0xc0fefe\n  0x0\n  swap1\n  dup2\n  mstore\n  0x20\n  mstore\n  // 将0x42 存储在地址0x798...187c上\n  0x42\n 0x79826054ee948a209ff4a6c9064d7398508d2c1909a392f899d301c6d232187c\n  sstore\n```\n我们可以将EVM想成一个键-值( key-value)数据库，不过每个key都限制为32字节。与其直接使用key`0xC0FEFE`，不如使用key的哈希值`0x798...187c`，并且`0x42`存储在这里。哈希函数使用的是`keccak256`(SHA256)函数。\n\n在这个例子中我们没有看见`keccak256`指令本身，因为优化器已经提前计算了结果并內联到了字节码中。在没什么作用的`mstore`指令中，我们依然可以看到计算的痕迹。\n\n## 计算地址\n使用一些Python代码来把`0xC0FEFE`哈希成`0x798...187c`。如果你想要跟着做下去，你需要安装Python 3.6，或者安装[pysha3](https://pypi.python.org/pypi/pysha3) 来获得`keccak_256`哈希函数。\n\n定义两个协助函数：\n```\nimport binascii\nimport sha3\n#将数值转换成32字节数组\ndef bytes32(i):\n    return binascii.unhexlify('%064x' % i)\n# 计算32字节数组的 keccak256 哈希值\ndef keccak256(x):\n    return sha3.keccak_256(x).hexdigest()\n```\n将数值转换成32个字节：\n```\n>>> bytes32(1)\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01'\n>>> bytes32(0xC0FEFE)\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\xfe\\xfe'\n```\n使用`+`操作符，将两个字节数组连接起来：\n```\n>>> bytes32(1) + bytes32(2)\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02'\n```\n计算一些字节的 keccak256 哈希值：\n```\n>>> keccak256(bytes(1))\n'bc36789e7a1e281436464229828f817d6612f7b477d66591ff96a9e064bcc98a'\n```\n现在我们可以计算`0x798...187c`了。\n\n存储变量`items`的位置是`0x0`（因为它是第一个存储变量）。连接key`0xc0fefe`和`items`的位置来获取地址：\n```\n# key = 0xC0FEFE, position = 0\n>>> keccak256(bytes32(0xC0FEFE) + bytes32(0))\n'79826054ee948a209ff4a6c9064d7398508d2c1909a392f899d301c6d232187c'\n```\n为key计算存储地址的公式是：\n```\nkeccak256(bytes32(key) + bytes32(position))\n```\n## 两个映射\n我们先把公式放在这里，后面数值存储时需要计算会用到该公式。\n\n假设我们的合约有两个映射：\n```\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 => uint256) itemsA;\n    mapping(uint256 => uint256) itemsB;\n    function C() {\n      itemsA[0xAAAA] = 0xAAAA;\n      itemsB[0xBBBB] = 0xBBBB;\n    }\n}\n```\n- `itemsA`的位置是`0`，key为`0xAAAA`：\n```\n# key = 0xAAAA, position = 0\n>>> keccak256(bytes32(0xAAAA) + bytes32(0))\n'839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3'\n```\n- `itemsB`的位置为`1`，key为`0xBBBB`：\n```\n# key = 0xBBBB, position = 1\n>>> keccak256(bytes32(0xBBBB) + bytes32(1))\n'34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395'\n```\n用编译器来验证一下这些计算：\n```\n$ solc --bin --asm --optimize  c-mapping-2.sol\n```\n汇编代码：\n```\ntag_2:\n  // ... 忽略可能会被优化掉的内存操作\n  0xaaaa\n  0x839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3\n  sstore\n  0xbbbb\n  0x34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395\n  sstore\n```\n跟期望的结果一样。\n\n## 汇编代码中的KECCAK256\n编译器可以提前计算key的地址是因为相关的值是常量。如果key使用的是变量，那么哈希就必须要在汇编代码中完成。现在我们无效化优化器，来看看在汇编代码中哈希是如何完成的。\n\n事实证明很容易就能让优化器无效，只要引入一个间接的虚变量`i`：\n```\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 => uint256) items;\n    //这个变量会造成常量的优化失败\n    uint256 i = 0xC0FEFE;\n    function C() {\n      items[i] = 0x42;\n    }\n}\n```\n变量`items`的位置依然是`0x0`，所以我们应该期待地址与之前是一样的。\n\n加上优化选项进行编译，但是这次不会提前计算哈希值：\n```\n$ solc --bin --asm --optimize  c-mapping--no-constant-folding.sol\n```\n注释的汇编代码：\n```\ntag_2:\n  // 加载`i` 到栈中\n  sload(0x1)\n    [0xC0FEFE]\n  // 将key`0xC0FEFE`存放在内存中的0x0位置上，为哈希做准备\n  0x0\n    [0x0 0xC0FEFE]\n  swap1\n    [0xC0FEFE 0x0]\n  dup2\n    [0x0 0xC0FEFE 0x0]\n  mstore\n    [0x0]\n    memory: {\n      0x00 => 0xC0FEFE\n    }\n  // 将位置 `0x0` 存储在内存中的 0x20 (32)位置上，为哈希做准备\n  0x20 // 32\n    [0x20 0x0]\n  dup2\n    [0x0 0x20 0x0]\n  swap1\n    [0x20 0x0 0x0]\n  mstore\n    [0x0]\n    memory: {\n      0x00 => 0xC0FEFE\n      0x20 => 0x0\n    }\n // 从第0个字节开始，哈希在内存中接下来的0x40(64)个字节\n  0x40 // 64\n    [0x40 0x0]\n  swap1\n    [0x0 0x40]\n  keccak256\n    [0x798...187c]\n  // 将0x42 存储在计算的地址上\n  0x42\n    [0x42 0x798...187c]\n  swap1\n    [0x798...187c 0x42]\n  sstore\n    store: {\n      0x798...187c => 0x42\n    }\n```\n`mstore`指令写入32个字节到内存中。内存操作便宜很多，只需要3 gas就可以读取和写入。前半部分的汇编代码就是通过将key和位置加载到相邻的内存块中来进行“连接”的：\n```\n 0                   31  32                 63\n[    key (32 bytes)    ][ position (32 bytes) ]\n```\n然后`keccak256`指令哈希内存中的数据。成本取决于被哈希的数据有多少：\n- 每个SHA3操作需要支付 30 gas\n- 每个32字节的字需要支付 6 gas\n\n对于一个`uint256`类型key，gas的成本是42：`30 + 6 * 2`。\n\n## 映射大数值\n每个存储槽只能存储32字节。如果我们尝试存储一个更大一点的结构体会怎么样？\n```\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 => Tuple) tuples;\n    struct Tuple {\n      uint256 a;\n      uint256 b;\n      uint256 c;\n    }\n    function C() {\n      tuples[0x1].a = 0x1A;\n      tuples[0x1].b = 0x1B;\n      tuples[0x1].c = 0x1C;\n    }\n}\n```\n编译，你会看见3个`sstore`指令：\n```\ntag_2:\n  //忽略未优化的代码\n  0x1a\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7d\n  sstore\n  0x1b\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7e\n  sstore\n  0x1c\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7f\n  sstore\n```\n注意计算的地址除了最后一个数字其他都是一样的。`Tulp`结构体成员是依次排列的(..7d, ..7e, ..7f)。\n\n## 映射不会打包\n考虑到映射的设计方式，每项需要的最小存储空间是32字节，即使你实际只需要存储1个字节：\n```\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 => uint8) items;\n    function C() {\n      items[0xA] = 0xAA;\n      items[0xB] = 0xBB;\n    }\n}\n```\n如果一个数值大于32字节，那么你需要的存储空间会以32字节依次增加。\n\n## 动态数组是映射的升级\n在典型语言中，数组只是连续存储在内存中一系列相同类型的元素。假设你有一个包含100个`uint8`类型的元素数组，那么这就会占用100个字节的内存。这种模式的话，将整个数组加载到CPU的缓存中然后循环遍历每个元素会便宜一点。\n\n对于大多数语言而言，数组比映射都会便宜一些。不过在Solidity中，数组是更加昂贵的映射。数组里面的元素会按照顺序排列在存储器中：\n```\n0x290d...e563\n0x290d...e564\n0x290d...e565\n0x290d...e566\n```\n但是请记住，对于这些存储槽的每次访问实际上就像数据库中的key-value的查找一样。访问一个数组的元素跟访问一个映射的元素是没什么区别的。\n\n思考一下`[]uint256`类型，它本质上与`mapping(uint256 => uint256)`是一样的，只不过后者多了一点特征，让它看起去就像数组一样。\n- `length`表示一共有多少个元素\n- 边界检查。当读取或写入时索引值大于`length`就会报错\n- 比映射更加复杂的存储打包行为\n- 当数组变小时，自动清除未使用的存储槽\n- `bytes`和`string`的特殊优化让短数组(小于32字节)存储更加高效\n\n## 简单数组\n看一下保存3个元素的数组：\n```\n// c-darray.sol\npragma solidity ^0.4.11;\ncontract C {\n    uint256[] chunks;\n    function C() {\n      chunks.push(0xAA);\n      chunks.push(0xBB);\n      chunks.push(0xCC);\n    }\n}\n```\n数组访问的汇编代码难以追踪，使用[Remix](https://remix.ethereum.org/)调试器来运行合约：\n![](/asset/evmp3_remix.jpeg)\n\n模拟的最后，我们可以看到有4个存储槽被使用了：\n```\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0x0000000000000000000000000000000000000000000000000000000000000003\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000aa\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e564\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000bb\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e565\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000cc\n```\n`chunks`变量的位置是`0x0`，用来存储数组的长度（`0x3`），哈希变量的位置来找到存储数组数据的地址：\n```\n# position = 0\n>>> keccak256(bytes32(0))\n'290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563'\n```\n在这个地址上数组的每个元素依次排列（`0x29..63`，`0x29..64`，`0x29..65`）。\n\n## 动态数据打包\n所有重要的打包行为是什么样的？数组与映射比较，数组的一个优势就是打包。拥有4个元素的`uint128[]`数组元素刚刚好需要2个存储槽（再加1个存储槽用来存储长度）。\n\n思考一下：\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint128[] s;\n    function C() {\n        s.length = 4;\n        s[0] = 0xAA;\n        s[1] = 0xBB;\n        s[2] = 0xCC;\n        s[3] = 0xDD;\n    }\n}\n```\n在Remix中运行这个代码，存储器的最后看起来像这样：\n```\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0x0000000000000000000000000000000000000000000000000000000000000004\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563\nvalue: 0x000000000000000000000000000000bb000000000000000000000000000000aa\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e564\nvalue: 0x000000000000000000000000000000dd000000000000000000000000000000cc\n```\n只有三个存储槽被使用了，跟预料的一样。长度再次存储在存储变量的`0x0`位置上。4个元素被打包放入两个独立的存储槽中。该数组的开始地址是变量位置的哈希值：\n```\n# position = 0\n>>> keccak256(bytes32(0))\n'290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563'\n```\n现在的地址是每两个数组元素增加一次，看起来很好！\n\n但是汇编代码本身优化的并不好。因为使用了两个存储槽，所以我们会希望优化器使用两个`sstore`指令来完成任务。不幸的是，由于边界检查(和一些其他因素)，所以没有办法将`sstore`指令优化掉。\n\n使用4个`sstore`指令才能完成任务：\n```\n/* \"c-bytes--sstore-optimize-fail.sol\":105:116  s[0] = 0xAA */\nsstore\n/* \"c-bytes--sstore-optimize-fail.sol\":126:137  s[1] = 0xBB */\nsstore\n/* \"c-bytes--sstore-optimize-fail.sol\":147:158  s[2] = 0xCC */\nsstore\n/* \"c-bytes--sstore-optimize-fail.sol\":168:179  s[3] = 0xDD */\nsstore\n```\n### 字节数组和字符串\n`bytes`和`string`是为字节和字符进行优化的特殊数组类型。如果数组的长度小于31字节，只需要1个存储槽来存储整个数组。长一点的字节数组跟正常数组的表示方式差不多。\n\n看看短一点的字节数组：\n```\n// c-bytes--long.sol\npragma solidity ^0.4.11;\ncontract C {\n    bytes s;\n    function C() {\n        s.push(0xAA);\n        s.push(0xBB);\n        s.push(0xCC);\n    }\n}\n```\n因为数组只有3个字节（小于31字节），所以它只占用1个存储槽。在Remix中运行，存储看起来如下：\n```\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0xaabbcc0000000000000000000000000000000000000000000000000000000006\n```\n数据`0xaabbcc...`从左到右的进行存储。后面的0是空数据。最后的`0x06`字节是数组的编码长度。公式是`长度=编码长度/2`，在这个例子中实际长度是`6/2=3`。\n\n`string`与`bytes`的原理一模一样。\n\n## 长字节数组\n如果数据的长度大于31字节，字节数组就跟`[]byte`一样。来看一下长度为128字节的字节数组：\n```\n// c-bytes--long.sol\npragma solidity ^0.4.11;\ncontract C {\n    bytes s;\n    function C() {\n        s.length = 32 * 4;\n        s[31] = 0x1;\n        s[63] = 0x2;\n        s[95] = 0x3;\n        s[127] = 0x4;\n    }\n}\n```\n在Remix中运行，可以看见使用了4个存储槽：\n```\n0x0000...0000\n0x0000...0101\n0x290d...e563\n0x0000...0001\n0x290d...e564\n0x0000...0002\n0x290d...e565\n0x0000...0003\n0x290d...e566\n0x0000...0004\n```\n`0x0`的存储槽不再用来存储数据，整个存储槽现在存储编码的数组长度。要获得实际长度，使用`长度=（编码长度-1）/2`公式。在这个例子中长度是`（0x101 - 1）/2=128`。实际的字节被保存在`0x290d...e563`，并且存储槽是连续的。\n\n字节数组的汇编代码相当多。除了正常的边界检查和数组恢复大小等，它还需要对长度进行编码/解码，以及注意长字节数组和短字节数组之间的转换。\n\n>为什么要编码长度？因为编码之后，可以很容易的测试出来字节数组是长还是短。注意对于长数组而言编码长度总是奇数，而短数组的编码长度总是偶数。汇编代码只需要查看一下最后一位是否为0，为0就是偶数（短数组），非0就是奇数（长数组）。\n\n## 总结\n查看Solidity编译器的内部工作，可以看见熟悉的数据结构例如映射和数组与传统编程语言完全不同。\n\n概括：\n- 数组跟映射一样，非高效\n- 比映射的汇编代码更加复杂\n- 小类型(`byte`，`uint8`，`string`)时存储比映射高效\n- 汇编代码优化的不是很好。即使是打包，每个任务都会有一个`sstore`指令\n\nEVM的存储器就是一个键值数据库，跟git很像。如果你改变了任一东西，根节点的校验和也会改变。如果两个根节点拥有相同的校验和，存储的数据就能保证是一样的。\n\n为了体会Solidity和EVM的奇特，可以想象一下在git仓库里数组里面的每个元素都是它自己的文件。当你改变数组里一个元素的值，实际上就相当于创建了一个提交。当你迭代一个数组时，你不能一次性的加载整个数组，你必须要到仓库中进行查找并分别找到每个文件。\n\n不仅仅这样，每个文件都限制到32字节！因为我们需要将数据结构都分割成32字节的块，Solidity编译器的所有逻辑和优化都是很负责的，全部在汇编的时候完成。\n\n不过32字节的限制是完全任意的。支持键值存储的可以使用key来存储任意类型的数值。也许未来我们添加新的EVM指令使用key来存储任意的字节数组。\n\n不过现在，EVM存储器就是一个伪装成32字节数组的键值数据库。\n\n>可以看看[ArrayUtils::resizeDynamicArray](https://github.com/ethereum/solidity/blob/3b07c4d38e40c52ee8a4d16e56e2afa1a0f27905/libsolidity/codegen/ArrayUtils.cpp#L624) 来了解一下当恢复数组大小时编译器的动作。正常情况下数据结构都会作为语言的标准库来完成的，但是在Solidity中嵌入到了编译器里面。\n\n本系列文章其他部分译文链接：\n- [EVM汇编代码的介绍(第1部分)](http://www.jianshu.com/p/1969f3761208)\n- [固定长度数据类型的表示方法(第2部分)](http://www.jianshu.com/p/9df8d15418ed)\n- [ABI编码外部方法调用的方式(第4部分)](http://www.jianshu.com/p/d0e8e825d41b)\n- [一个新合约被创建后会发生什么(第5部分)](http://www.jianshu.com/p/d9137e87c9d3)\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[Diving Into The Ethereum VM Part  Three](https://medium.com/@hayeah/diving-into-the-ethereum-vm-the-hidden-costs-of-arrays-28e119f04a9b)\n","tags":["ethereum"],"categories":["translation"]},{"title":"深入了解以太坊虚拟机第4部分——ABI编码外部方法调用的方式","url":"/evm_part4.html","content":"** **  <Excerpt in index | Homepage Digest>\n\n深入了解以太坊虚拟机是一个系列的文章，本文是第4篇，本系列其他部分的译文链接在文章结尾处\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n![](/asset/evmp4_head.jpeg) \n\n在本系列的上一篇文章中我们看到了Solidity是如何在EVM存储器中表示复杂数据结构的。但是如果无法交互，数据就是没有意义的。智能合约就是数据和外界的中间体。\n\n在这篇文章中我们将会看到Solidity和EVM可以让外部程序来调用合约的方法并改变它的状态。\n\n“外部程序”不限于DApp/JavaScript。任何可以使用HTTP RPC与以太坊节点通信的程序，都可以通过创建一个交易与部署在区块链上的任何合约进行交互。\n\n创建一个交易就像发送一个HTTP请求。Web的服务器会接收你的HTTP请求，然后改变数据库。交易会被网络接收，底层的区块链会扩展到包含改变的状态。\n\n交易对于智能合约就像HTTP请求对于Web服务器。\n\n如果对EVM汇编和Solidity数据表示陌生，请阅读该系列的前几篇文章：\n本系列文章其他部分译文链接：\n- [EVM汇编代码的介绍(第1部分)](http://www.jianshu.com/p/1969f3761208)\n- [固定长度数据类型的表示方法(第2部分)](http://www.jianshu.com/p/9df8d15418ed)\n- [动态数据类型的表示方法(第3部分)](http://www.jianshu.com/p/af5721c79505)\n\n## 合约交易\n让我们来看一下将状态变量设置在`0x1`位置上的交易。我们想要交互的合约有一个对变量`a`的设置者和获取者：\n```\npragma solidity ^0.4.11;\ncontract C {\n  uint256 a;\n  function setA(uint256 _a) {\n    a = _a;\n  }\n  function getA() returns(uint256) {\n    return a;\n  }\n}\n```\n这个合约部署在Rinkeby测试网上。可以随意使用Etherscan，并搜索地址 [0x62650ae5…](https://rinkeby.etherscan.io/address/0x62650ae5c5777d1660cc17fcd4f48f6a66b9a4c2#code)进行查看。\n\n我创建了一个可以调用`setA(1)`的交易，可以在地址[0x7db471e5...](https://rinkeby.etherscan.io/tx/0x7db471e5792bbf38dc784a5b983ee6a7bbe3f1db85dd4daede9ee88ed88057a5)上查看该交易。\n![](/asset/evmp4_transation.jpeg)\n\n交易的输出数据是：\n```\n0xee919d500000000000000000000000000000000000000000000000000000000000000001\n```\n\n对于EVM而言，这只是36字节的元数据。它对元数据不会进行处理，会直接将元数据作为`calldata`传递给智能合约。如果智能合约是个Solidity程序，那么它会将这些输入字节解释为方法调用，并为`setA(1)`执行适当的汇编代码。\n\n输入数据可以分成两个子部分：\n```\n# 方法选择器(4字节)\n0xee919d5\n#第一个参数(32字节)\n00000000000000000000000000000000000000000000000000000000000000001\n```\n前面的4个字节是方法选择器，剩下的输入数据是方法的参数，32个字节的块。在这个例子中，只有一个参数，值是`0x1`。\n\n方法选择器是方法签名的 kecccak256 哈希值。在这个例子中方法的签名是`setA(uint256)`，也就是方法名称和参数的类型。\n\n让我们用Python来计算方法选择器。首先，哈希方法签名：\n```\n# 安装pyethereum [https://github.com/ethereum/pyethereum/#installation](https://github.com/ethereum/pyethereum/#installation)> from ethereum.utils import sha3> sha3(\"setA(uint256)\").hex()'ee919d50445cd9f463621849366a537968fe1ce096894b0d0c001528383d4769'\n```\n然后获取哈希值的前4字节：\n```\n> sha3(\"setA(uint256)\")[0:4].hex()\n'ee919d50'\n```\n## 应用二进制接口（ABI）\n对于EVM而言，交易的输入数据(`calldata`)只是一个字节序列。EVM内部不支持调用方法。\n\n智能合约可以选择通过以结构化的方式处理输入数据来模拟方法调用，就像前面所说的那样。\n\n如果EVM上的所有语言都同意相同的方式解释输入数据，那么它们就可以很容易进行交互。 [合约应用二进制接口](https://github.com/ethereum/wiki/wiki/Ethereum-Contract-ABI#formal-specification-of-the-encoding)（ABI）指定了一个通用的编码模式。\n\n我们已经看到了ABI是如何编码一个简单的方法调用，例如`SetA(1)`。在后面章节中我们将会看到方法调用和更复杂的参数是如何编码的。\n\n## 调用一个获取者\n如果你调用的方法改变了状态，那么整个网络必须要同意。这就需要有交易，并消耗gas。\n\n一个获取者如`getA()`不会改变任何东西。我们可以将方法调用发送到本地的以太坊节点，而不用请求整个网络来执行计算。一个`eth_call`RPC请求可以允许你在本地模拟交易。这对于只读方法或gas使用评估比较有帮助。\n\n一个`eth_call`就像一个缓存的HTTP GET请求。\n- 它不改变全球的共识状态\n- 本地区块链(\"缓存\")可能会有点稍微过时\n\n制作一个`eth_call`来调用 `getA`方法，通过返回值来获取状态`a`。首先，计算方法选择器：\n```\n>>> sha3(\"getA()\")[0:4].hex()\n'd46300fd'\n```\n由于没有参数，输入数据就只有方法选择器了。我们可以发送一个`eth_call`请求给任意的以太坊节点。对于这个例子，我们依然将请求发送给 infura.io的公共以太坊节点：\n```\n$ curl -X POST \\-H \"Content-Type: application/json\" \\\"[https://rinkeby.infura.io/YOUR_INFURA_TOKEN](https://rinkeby.infura.io/YOUR_INFURA_TOKEN)\" \\--data '{\"jsonrpc\": \"2.0\",\"id\": 1,\"method\": \"eth_call\",\"params\": [{\"to\": \"0x62650ae5c5777d1660cc17fcd4f48f6a66b9a4c2\",\"data\": \"0xd46300fd\"},\"latest\"]}'\n```\nEVM执行了计算并将元字节作为结果返回：\n```\n{\n\"jsonrpc\":\"2.0\",\n\"id\":1,\n        \"result\":\"0x0000000000000000000000000000000000000000000000000000000000000001\"\n}\n```\n根据ABI，该字节应该会解释为`0x1`数值。\n\n## 外部方法调用的汇编\n现在来看看编译的合约是如何处理源输入数据的，并以此来制作一个方法调用。思考一个定义了`setA(uint256)`的合约：\n```\npragma solidity ^0.4.11;\ncontract C {\n  uint256 a;\n  // 注意: `payable` 让汇编简单一点点\n  function setA(uint256 _a) payable {\n    a = _a;\n  }\n}\n```\n编译：\n```\nsolc --bin --asm --optimize call.sol\n```\n调用方法的汇编代码在合约内部，在`sub_0`标签下：\n```\nsub_0: assembly {\n    mstore(0x40, 0x60)\n    and(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n    0xee919d50\n    dup2\n    eq\n    tag_2\n    jumpi\n  tag_1:\n    0x0\n    dup1\n    revert\n  tag_2:\n    tag_3\n    calldataload(0x4)\n    jump(tag_4)\n  tag_3:\n    stop\n  tag_4:\n      /* \"call.sol\":95:96  a */\n    0x0\n      /* \"call.sol\":95:101  a = _a */\n    dup2\n    swap1\n    sstore\n  tag_5:\n    pop\n    jump // 跳出\nauxdata: 0xa165627a7a7230582016353b5ec133c89560dea787de20e25e96284d67a632e9df74dd981cc4db7a0a0029\n}\n```\n这里有两个样板代码与此讨论是无关的，但是仅供参考：\n- 最上面的`mstore(0x40, 0x60)`为sha3哈希保留了内存中的前64个字节。不管合约是否需要，这个都会存在的。\n- 最下面的`auxdata`用来验证发布的源码与部署的字节码是否相同的。这个是可选择的，但是嵌入到了编译器中。\n\n将剩下的汇编代码分成两个部分，这样容易分析一点：\n- 匹配选择器并跳掉方法处\n- 加载参数、执行方法，并从方法返回\n\n首先，匹配选择器的注释汇编代码：\n```\n// 加载前4个字节作为方法选择器\nand(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n//  如果选择器匹配`0xee919d50`, 跳转到 setA\n0xee919d50\ndup2\neq\ntag_2\njumpi\n// 匹配失败，返回并还原\ntag_1:\n  0x0\n  dup1\n  revert\n// setA函数\ntag_2:\n  ...\n```\n除了开始从调用数据里面加载4字节时的位转移，其他的都是非常清晰明朗的。为了清晰可见，给出了汇编逻辑的低级伪代码：\n```\nmethodSelector = calldata[0:4]\nif methodSelector == \"0xee919d50\":\n  goto tag_2 // 跳转到setA\nelse:\n  // 匹配失败，返回并还原\n  revert\n```\n实际方法调用的注释汇编代码：\n```\n// setA\ntag_2:\n  // 方法调用之后跳转的地方\n  tag_3\n  // 加载第一个参数(数值0x1).\n  calldataload(0x4)\n  // 执行方法\n  jump(tag_4)\ntag_4:\n  // sstore(0x0, 0x1)\n  0x0\n  dup2\n  swap1\n  sstore\ntag_5:\n  pop\n  //程序的结尾，将会跳转到 tag_3并停止\n  jump\ntag_3:\n  // 程序结尾\n  stop\n```\n在进入方法体之前，汇编代码做了两件事情：\n1. 保存了一个位置，方法调用之后返回此位置\n2. 从调用数据里面加载参数到栈中\n\n低级的伪代码：\n```\n// 保存位置，方法调用结束后返回此位置\n@returnTo = tag_3\ntag_2: // setA\n  // 从调用数据里面加载参数到栈中\n  @arg1 = calldata[4:4+32]\ntag_4: // a = _a\n  sstore(0x0, @arg1)\ntag_5 // 返回\n  jump(@returnTo)\ntag_3:\n  stop\n```\n将这两部分组合起来：\n```\nmethodSelector = calldata[0:4]\nif methodSelector == \"0xee919d50\":\n  goto tag_2 // goto setA\nelse:\n  // 无匹配方法。失败\n  revert\n@returnTo = tag_3\ntag_2: // setA(uint256 _a)\n  @arg1 = calldata[4:36]\ntag_4: // a = _a\n  sstore(0x0, @arg1)\ntag_5 // 返回\n  jump(@returnTo)\ntag_3:\n  stop\n```\n> 有趣的小细节：`revert`的操作码是`fd`。但是在黄皮书中你不会找到它的详细说明，或者在代码中找到它的实现。实际上，`fd`不是确实存在的！这是个无效的操作。当EVM遇到了一个无效的操作，它会放弃并且会有还原状态的副作用。\n\n## 处理多个方法\nSolidity编译器是如何为有多个方法的合约产生汇编代码的？\n```\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    uint256 b;\n    function setA(uint256 _a) {\n      a = _a;\n    }\n    function setB(uint256 _b) {\n      b = _b;\n    }\n}\n```\n简单，只要一些`if-else`分支就可以了：\n```\n// methodSelector = calldata[0:4]\nand(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n// if methodSelector == 0x9cdcf9b\n0x9cdcf9b\ndup2\neq\ntag_2 // SetB\njumpi\n// elsif methodSelector == 0xee919d50\ndup1\n0xee919d50\neq\ntag_3 // SetA\njumpi\n```\n伪代码：\n```\nmethodSelector = calldata[0:4]\nif methodSelector == \"0x9cdcf9b\":\n  goto tag_2\nelsif methodSelector == \"0xee919d50\":\n  goto tag_3\nelse:\n  // Cannot find a matching method. Fail.\n  revert\n```\n### ABI为复杂方法调用进行编码\n![不用担心零,这些零都没关系](/asset/evmp4_zero.jpeg)\n\n对于一个方法调用，交易输入数据的前4个字节总是方法选择器。跟在后面的32字节块就是方法参数。 [ABI编码规范](https://github.com/ethereum/wiki/wiki/Ethereum-Contract-ABI)显示了更加复杂的参数类型是如何被编码的，但是阅读起来非常的痛苦。\n\n另一个学习ABI编码的方式是使用 [pyethereum的ABI编码函数](https://github.com/ethereum/pyethereum/blob/4e945e2a24554ec04eccb160cff689a82eed7e0d/ethereum/abi.py) 来研究不同数据类型是如何编码的。我们会从简单的例子开始，然后建立更复杂的类型。\n\n首先，导出`encode_abi`函数：\n```\nfrom ethereum.abi import encode_abi\n```\n对于一个有3个` uint256`类型参数的方法（例如`foo(uint256 a, uint256 b, uint256 c)`），编码参数只是简单的依次对`uint256`数值进行编码：\n```\n# 第一个数组列出了参数的类型\n# 第二个数组列出了参数的值\n> encode_abi([\"uint256\", \"uint256\", \"uint256\"],[1, 2, 3]).hex()\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n```\n小于32字节的类型会被填充到32字节：\n```\n> encode_abi([\"int8\", \"uint32\", \"uint64\"],[1, 2, 3]).hex()\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n```\n对于定长数组，元素还是32字节的块（如果必要的话会填充0），依次排列：\n```\n> encode_abi(\n   [\"int8[3]\", \"int256[3]\"],\n   [[1, 2, 3], [4, 5, 6]]\n).hex()\n// int8[3]. Zero-padded to 32 bytes.\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n// int256[3].\n0000000000000000000000000000000000000000000000000000000000000004\n0000000000000000000000000000000000000000000000000000000000000005\n0000000000000000000000000000000000000000000000000000000000000006\n```\n### ABI为动态数组编码\nABI介绍了一种间接的编码动态数组的方法，遵循一个叫做[头尾编码](https://github.com/ethereum/pyethereum/blob/4e945e2a24554ec04eccb160cff689a82eed7e0d/ethereum/abi.py#L735-L741)的模式。\n\n该模式其实就是动态数组的元素被打包到交易的调用数据尾部，参数(“头”)会被引用到调用数据里，这里就是数组元素。\n\n如果我们调用的方法有3个动态数组，参数的编码就会像这样（添加注释和换行为了更加的清晰）：\n```\n> encode_abi(\n  [\"uint256[]\", \"uint256[]\", \"uint256[]\"],\n  [[0xa1, 0xa2, 0xa3], [0xb1, 0xb2, 0xb3], [0xc1, 0xc2, 0xc3]]\n).hex()\n/************* HEAD (32*3 bytes) *************/\n// 参数1: 数组数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数2：数组数据在0xe0位置\n00000000000000000000000000000000000000000000000000000000000000e0\n// 参数3： 数组数据在0x160位置 \n0000000000000000000000000000000000000000000000000000000000000160\n/************* TAIL (128**3 bytes) *************/\n//  0x60位置。参数1的数据\n// 长度后跟这元素\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000a1\n00000000000000000000000000000000000000000000000000000000000000a2\n00000000000000000000000000000000000000000000000000000000000000a3\n// 0xe0位置。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n//0x160位置。参数3的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000c1\n00000000000000000000000000000000000000000000000000000000000000c2\n00000000000000000000000000000000000000000000000000000000000000c3\n```\n\n`HEAD`部分有32字节参数，指出`TAIL`部分的位置，`TAIL`部分包含了3个动态数组的实际数据。\n\n举个例子，第一个参数是`0x60`，指出调用数据的第96个(`0x60`)字节。如果你看一下第96个字节，它是数组的开始地方。前32字节是长度，后面跟着的是3个元素。\n\n混合动态和静态参数是可能的。这里有个(`static`，`dynamic`，`static`)参数。静态参数按原样编码，而第二个动态数组的数据放到了尾部：\n```\n> encode_abi(\n  [\"uint256\", \"uint256[]\", \"uint256\"],\n  [0xaaaa, [0xb1, 0xb2, 0xb3], 0xbbbb]\n).hex()\n/************* HEAD (32*3 bytes) *************/\n// 参数1： 0xaaaa\n000000000000000000000000000000000000000000000000000000000000aaaa\n// 参数2：数组数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数3： 0xbbbb\n000000000000000000000000000000000000000000000000000000000000bbbb\n/************* TAIL (128 bytes) *************/\n// 0x60位置。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n```\n有很多的0，不过没关系。\n\n## 编码字节数组\n字符串和字节数组同样是头尾编码。唯一的区别是字节数组会被紧密的打包成一个32字节的块，就像：\n```\n> encode_abi(\n  [\"string\", \"string\", \"string\"],\n  [\"aaaa\", \"bbbb\", \"cccc\"]\n).hex()\n// 参数1： 字符串数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数2：字符串数据在0xa0位置\n00000000000000000000000000000000000000000000000000000000000000a0\n// 参数3：字符串数据在0xe0位置\n00000000000000000000000000000000000000000000000000000000000000e0\n// 0x60 (96)。 参数1的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6161616100000000000000000000000000000000000000000000000000000000\n// 0xa0 (160)。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6262626200000000000000000000000000000000000000000000000000000000\n// 0xe0 (224)。参数3的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6363636300000000000000000000000000000000000000000000000000000000\n```\n对于每个字符串/字节数组，前面的32字节是编码长度，后面跟着才是字符串/字节数组的内容。\n\n如果字符串大于32字节，那么多个32字节块就会被使用：\n```\n// 编码字符串的48字节\nethereum.abi.encode_abi(\n  [\"string\"],\n  [\"a\" * (32+16)]\n).hex()\n\n0000000000000000000000000000000000000000000000000000000000000020\n//字符串的长度为0x30 (48)\n0000000000000000000000000000000000000000000000000000000000000030\n6161616161616161616161616161616161616161616161616161616161616161\n6161616161616161616161616161616100000000000000000000000000000000\n```\n## 嵌套数组\n嵌套数组中每个嵌套有一个间接寻址。\n```\n> encode_abi(\n  [\"uint256[][]\"],\n  [[[0xa1, 0xa2, 0xa3], [0xb1, 0xb2, 0xb3], [0xc1, 0xc2, 0xc3]]]\n).hex()\n//参数1：外层数组在0x20位置上\n0000000000000000000000000000000000000000000000000000000000000020\n// 0x20。每个元素都是里层数组的位置\n0000000000000000000000000000000000000000000000000000000000000003\n0000000000000000000000000000000000000000000000000000000000000060\n00000000000000000000000000000000000000000000000000000000000000e0\n0000000000000000000000000000000000000000000000000000000000000160\n// array[0]在0x60位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000a1\n00000000000000000000000000000000000000000000000000000000000000a2\n00000000000000000000000000000000000000000000000000000000000000a3\n// array[1] 在0xe0位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n// array[2]在0x160位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000c1\n00000000000000000000000000000000000000000000000000000000000000c2\n00000000000000000000000000000000000000000000000000000000000000c3\n```\n很多的0！\n\n## Gas成本和ABI编码设计\n为什么ABI将方法选择器截断到4个字节？如果我们不使用sha256的整个32字节，会不会不幸的碰到不同方法发生冲突的情况？ 如果这个截断是为了节省成本，那么为什么在用更多的0来进行填充时，而仅仅只为了节省方法选择器中的28字节而截断呢？\n\n这种设计看起来互相矛盾......直到我们考虑到一个交易的gas成本。\n- 每笔交易需要支付 21000 gas\n- 每笔交易的0字节或代码需要支付 4 gas\n- 每笔交易的非0字节或代码需要支付 68 gas\n\n啊哈！0要便宜17倍，0填充现在看起来没有那么不合理了。\n\n方法选择器是一个加密哈希值，是个伪随机。一个随机的字符串倾向于拥有很多的非0字节，因为每个字节只有0.3%（1/255）的概率是0。\n\n- `0x1`填充到32字节成本是192 gas\n4*31 (0字节) + 68 (1个非0字节)\n- sha256可能有32个非0字节，成本大概2176 gas\n32 * 68\n- sha256截断到4字节，成本大概272 gas\n32*4\n\nABI展示了另外一个底层设计的奇特例子，通过gas成本结构进行激励。\n\n### 负整数....\n一般使用叫做 [补码](https://en.wikipedia.org/wiki/Two%27s_complement)的方式来表达负整数。`int8`类型`-1`的数值编码会都是1。`1111 1111`。\n\nABI用1来填充负整数，所以`-1`会被填充为：\n```\nffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\n```\n越大的负整数（`-1`大于`-2`）1越多，会花费相当多的gas。\n\n## 总结\n与智能合约交互，你需要发送原始字节。它会进行一些计算，可能会改变自己的状态，然后会返回给你原始字节。方法调用实际上不存在，这是ABI创造的集体假象。\n\nABI被指定为一个低级格式，但是在功能上更像一个跨语言RPC框架的序列化格式。\n\n 我们可以在DApp和Web App的架构层面之间进行类比：\n- 区块链就是一个备份数据库\n- 合约就像web服务器\n- 交易就像请求\n- ABI是数据交换格式，就像[Protocol Buffer](https://en.wikipedia.org/wiki/Protocol_Buffers)。\n\n本系列文章其他部分译文链接：\n- [EVM汇编代码的介绍(第1部分)](http://www.jianshu.com/p/1969f3761208)\n- [固定长度数据类型的表示方法(第2部分)](http://www.jianshu.com/p/9df8d15418ed)\n- [动态数据类型的表示方法(第3部分)](http://www.jianshu.com/p/af5721c79505)\n- [一个新合约被创建后会发生什么(第5部分)](http://www.jianshu.com/p/d9137e87c9d3)\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[Diving Into The Ethereum VM Part Four](https://medium.com/@hayeah/how-to-decipher-a-smart-contract-method-call-8ee980311603)\n","tags":["ethereum"],"categories":["translation"]},{"title":"深入了解以太坊虚拟机第5部分——一个新合约被创建后会发生什么","url":"/evm_part5.html","content":" **  **  <Excerpt in index | Homepage Digest>\n \n深入了解以太坊虚拟机是一个系列的文章，本文是最后一篇，前部分的译文链接在本文结尾处\n\n <!-- more -->\n<The rest of contents | Rest of all>\n\n![](/asset/evmp5_head.jpeg) \n\n在该系列文章的前部分，我们学了EVM汇编基础，也学了ABI编码是如何允许外部程序与合约进行通信的。在本文中，我们将会学习一个合约是如何从零创建的。\n\n本系列的相关文章（按照顺序）：\n- [EVM汇编代码的介绍(第1部分)](http://www.jianshu.com/p/1969f3761208)\n- [固定长度数据类型的表示方法(第2部分)](http://www.jianshu.com/p/9df8d15418ed)\n- [动态数据类型的表示方法(第3部分)](http://www.jianshu.com/p/af5721c79505)\n- [ABI编码外部方法调用的方式(第4部分)](http://www.jianshu.com/p/d0e8e825d41b)\n\n我们目前所见的EVM字节码都是比较清晰明朗的，就是EVM从上往下的执行指令，没有什么隐藏的魔法。合约创建的过程更有意思一些，它将数据和代码之间的界限模糊化。\n\n在学习合约是如何创建的时候，我们将会看到有时候数据就是代码，有时候代码就是数据。\n\n带上你最喜欢的魔术帽子🎩，我们来开始吧！\n\n## 合约出生证明\n让我们创建一个简单（完全没用）的合约：\n```\npragma solidity ^0.4.11;\ncontract C {\n}\n```\n编译它：\n```\nsolc --bin --asm c.sol\n```\n字节码是：\n```\n60606040523415600e57600080fd5b5b603680601c6000396000f30060606040525b600080fd00a165627a7a723058209747525da0f525f1132dde30c8276ec70c4786d4b08a798eda3c8314bf796cc30029\n```\n为了创建这个合约，我们需要先通过发送一个[eth_sendtransaction](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sendtransaction) RPC请求给以太坊的节点来创建一个交易。你可以使用[Remix](https://remix.ethereum.org/)或[Metamask](https://metamask.io/)来做这件事情。\n\n不管你使用什么开发工具，RPC调用的参数就差不多类似于：\n```\n{\n  \"from\": \"0xbd04d16f09506e80d1fd1fd8d0c79afa49bd9976\",\n  \"to\": null,\n  \"gas\": \"68653\", // 30400,\n  \"gasPrice\": \"1\", // 10000000000000\n  \"data\": \"0x60606040523415600e57600080fd5b603580601b6000396000f3006060604052600080fd00a165627a7a723058204bf1accefb2526a5077bcdfeaeb8020162814272245a9741cc2fddd89191af1c0029\"\n}\n```\n没有什么特殊的RPC调用或交易类型来创建一个合约。相同的交易机制也被用于其他机制：\n- 转移Ether到一个账户或合约\n- 调用一个带参数的合约方法\n\n根据你指定的参数，以太坊会以不同方式解释交易。创建一个合约，`to`地址应该为`null`（或被忽略）。\n\n我用下面这个交易创建了一个合约例子：\n[https://rinkeby.etherscan.io/tx/0x58f36e779950a23591aaad9e4c3c3ac105547f942f221471bf6ffce1d40f8401](https://rinkeby.etherscan.io/tx/0x58f36e779950a23591aaad9e4c3c3ac105547f942f221471bf6ffce1d40f8401)\n\n打开Etherscan，你应该可以看到该交易的输入数据就是Solidity编译器产生的字节码：\n![](/asset/evmp5_bytecode.jpeg)\n\n当处理该交易的时候，EVM会将输入数据作为代码执行。瞧，一个合约就被创建了。\n\n## 字节码是干什么的？\n我们可以将上面的字节码分成3个独立的块：\n```\n//部署代码\n60606040523415600e57600080fd5b5b603680601c6000396000f300\n//合约代码\n60606040525b600080fd00\n// Auxdata\na165627a7a723058209747525da0f525f1132dde30c8276ec70c4786d4b08a798eda3c8314bf796cc30029\n```\n- 创建合约时运行部署代码\n- 合约创建成功之后当它的方法被调用时，运行合约代码\n- （可选）Auxdata是源码的加密指纹，用来验证。这只是数据，永远不会被EVM执行\n\n部署代码有两个主要作用：\n1. 运行构造器函数，并设置初始化内存变量（就像合约的拥有者）\n2. 计算合约代码，并返回给EVM\n\nSolidity编译器产生的部署代码会从字节码中加载`60606040525b600080fd00`到内存中，然后将它作为合约代码返回。在这个例子中，“计算”只是读取一块数据到内存中。原则上，我们可以编程地产生合约代码。\n\n构造器到底做什么取决于语言，但是EVM语言最后会返回合约代码。\n\n## 合约创建\n那么当部署代码运行完并返回合约代码之后会发生什么？以太坊是如何从返回的合约代码中创建一个合约的？\n\n让我们一起深入的去了解一下源码，看看细节。\n\n我发现了Go-Ethereum 的实现方式是找到需要信息的最简单参考。我们得到了正确的变量名、静态类型信息和符号交叉引用。尝试超越这个，黄皮书！\n\n使用Sourcegraph（当鼠标停留在一个变量上的时候会有类型信息，非常好用）软件阅读的源码，找到的相关方法是[evm.Create](https://sourcegraph.com/github.com/ethereum/go-ethereum@e9295163aa25479e817efee4aac23eaeb7554bba/-/blob/core/vm/evm.go#L301)。让我们略读一下代码，忽略一些错误检查和过于详细的细节。从上到下：\n\n- 检测调用者是否拥有足够的余额来做转账\n```\nif !evm.CanTransfer(evm.StateDB, caller.Address(), value) {\n return nil, common.Address{}, gas, ErrInsufficientBalance\n}\n```\n- 从调用者的地址派生一个新合约的地址（通过创建者账户的 `nonce`传递）：\n```\ncontractAddr = crypto.CreateAddress(caller.Address(), nonce)\n```\n- 使用派生的合约地址来创建新合约账户（改变”世界状态“`StateDB` ）：\n```\nevm.StateDB.CreateAccount(contractAddr)\n```\n- 将初始的Ether基金从调用者转到新合约中：\n```\nevm.Transfer(evm.StateDB, caller.Address(), contractAddr, value)\n```\n- 设置输入数据为合约的部署代码，然后使用EVM来执行。`ret`变量是返回的合约代码：\n```\ncontract := NewContract(caller, AccountRef(contractAddr), value, gas)\ncontract.SetCallCode(&contractAddr, crypto.Keccak256Hash(code), code)\nret, err = run(evm, snapshot, contract, nil)\n```\n- 检查错误。或如果合约代码太长则会失败。收取用户的gas然后设置合约代码：\n```\nif err == nil && !maxCodeSizeExceeded {\n  createDataGas := uint64(len(ret)) * params.CreateDataGas\n  if contract.UseGas(createDataGas) {\n    evm.StateDB.SetCode(contractAddr, ret)\n  } else {\n    err = ErrCodeStoreOutOfGas\n  }\n}\n```\n## 部署代码的代码\n让我们来看看汇编代码的细节，看看当一个合约被创建的时候”部署代码“是如何返回”合约代码“的。我们将会再一次分析合约列子：\n```\npragma solidity ^0.4.11;\ncontract C {\n}\n```\n将该合约的字节码分成独立的块：\n```\n// 部署代码\n60606040523415600e57600080fd5b5b603680601c6000396000f300\n//合约代码\n60606040525b600080fd00\n// Auxdata\na165627a7a723058209747525da0f525f1132dde30c8276ec70c4786d4b08a798eda3c8314bf796cc30029\n```\n部署代码的汇编代码是：\n```\n// 为Solidity内部保留0x60个字节的内存\nmstore(0x40, 0x60)\n// 非支付合约。如果调用者发送ether就会归还\njumpi(tag_1, iszero(callvalue))\n0x0\ndup1\nrevert\n// 将合约代码拷贝到内存中并返回\ntag_1:\ntag_2:\n  dataSize(sub_0)\n  dup1\n  dataOffset(sub_0)\n  0x0\n  codecopy\n  0x0\n  return\nstop\n```\n为返回合约代码跟踪上面的汇编代码：\n```\n// 60 36 (PUSH 0x36)\ndataSize(sub_0)\n  stack: [0x36]\ndup1\n  stack: [0x36 0x36]\n// 60 1c == (PUSH 0x1c)\ndataOffset(sub_0)\n  stack: [0x1c 0x36 0x36]\n0x0\n  stack: [0x0 0x1c 0x36 0x36]\ncodecopy\n  // 消耗三个参数\n  // 将数据的 `length` 从`codeOffset` 拷贝到`memoryOffset`\n  // memoryOffset = 0x0\n  // codeOffset   = 0x1c\n  // length       = 0x36\n  stack: [0x36]\n0x0\n  stack: [0x0 0x36]\n  memory: [\n    0x0:0x36 => calldata[0x1c:0x36]\n  ]\nreturn\n  // 消耗两个参数\n  // 返回 `memoryOffset`中的数据`length` \n  // memoryOffset  = 0x0\n  // length        = 0x36\n  stack: []\n  memory: [\n    0x0:0x36 => calldata[0x1c:0x36]\n  ]\n```\n`dataSize(sub_0)`和`dataOffset(sub_0)`实际上不是真正的指令。它们实际上是PUSH指令，将常量压入栈中。两个`0x1C `(28) 和`0x36` (54) 常量指定一个字节码子字符串作为代码合约返回。\n\n部署代码的汇编代码大致对应于下面的Python3 代码：\n```\nmemory = []\ncalldata = bytes.fromhex(\"60606040523415600e57600080fd5b5b603680601c6000396000f30060606040525b600080fd00a165627a7a72305820b5090d937cf89f134d30e54dba87af4247461dd3390acf19d4010d61bfdd983a0029\")\nsize = 0x36   // dataSize(sub_0)\noffset = 0x1c // dataOffset(sub_0)\n// 将调用数据的子字符串拷贝到内存\nmemory[0:size] = calldata[offset:offset+size]\n// 将内存的内容用十六进制打印出来而不返回\nprint(bytes(memory[0:size]).hex())\n```\n产生的内存内容是：\n```\n60606040525b600080fd00\na165627a7a72305820b5090d937cf89f134d30e54dba87af4247461dd3390acf19d4010d61bfdd983a0029\n```\n对应的汇编代码（加上auxdata）：\n```\n// 6060604052600080fd00\nmstore(0x40, 0x60)\ntag_1:\n  0x0\n  dup1\n  revert\nauxdata: 0xa165627a7a723058209747525da0f525f1132dde30c8276ec70c4786d4b08a798eda3c8314bf796cc30029\n```\n再次看下Etherscan，这正是部署的合约代码：\n[以太坊账户0x2c7f561F1fc5c414C48d01E480fDAAE2840B8AA2 信息\n以太坊区块链探险者，API和分析平台\nrinkeby.etherscan.io ](https://rinkeby.etherscan.io/address/0x2c7f561f1fc5c414c48d01e480fdaae2840b8aa2#code)\n![](/asset/evmp5_address.jpeg)\n\n\n## CODECOPY\n部署代码使用`codecopy`将交易的输入数据拷贝到内存。\n\n`codecopy`指令的行为和参数比其他的简单指令要复杂一点。如果我在黄皮书中查找这个指令，可能会更加的困惑一些。相反，让我们看看go-ethereum 源代码来研究一下到底怎么回事。\n\n看看[CODECOPY](https://sourcegraph.com/github.com/ethereum/go-ethereum@e9295163aa25479e817efee4aac23eaeb7554bba/-/blob/core/vm/instructions.go#L408:6)：\n```\nfunc opCodeCopy(pc *uint64, evm *EVM, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {\n var (\n  memOffset  = stack.pop()\n  codeOffset = stack.pop()\n  length     = stack.pop()\n )\n codeCopy := getDataBig(contract.Code, codeOffset, length)\n memory.Set(memOffset.Uint64(), length.Uint64(), codeCopy)\nevm.interpreter.intPool.put(memOffset, codeOffset, length)\n return nil, nil\n}\n```\n没有难懂的字母！\n\n> `evm.interpreter.intPool.put(memOffset, codeOffset, length)`这一行回收对象（大整数）后面使用。这只是一个高效的优化。\n\n## 构造器参数\n除了产生合约代码，部署代码的其他作用是运行构造器来进行设置。如果存在构造器参数，那么部署代码就需要从某地放加载参数。\n\nSolidity传递构造器参数的惯例是在调用`eth_sendtransaction`时在字节码末尾附加ABI编码的参数值。RPC调用将字节码和ABI编码参数放到一起作为输入数据进行传递，就像：\n```\n{\n  \"from\": \"0xbd04d16f09506e80d1fd1fd8d0c79afa49bd9976\"\n  \"data\": hexencode(compiledByteCode + encodedParams),\n}\n```\n看看有一个构造器参数的合约例子：\n```\npragma solidity ^0.4.11;\ncontract C {\n  uint256 a;\n  function C(uint256 _a) {\n    a = _a;\n  }\n}\n```\n我已经创建了这个合约，传递了`66`值。Etherscan上的交易：\n[https://rinkeby.etherscan.io/tx/0x2f409d2e186883bd3319a8291a345ddbc1c0090f0d2e182a32c9e54b5e3fdbd8](https://rinkeby.etherscan.io/tx/0x2f409d2e186883bd3319a8291a345ddbc1c0090f0d2e182a32c9e54b5e3fdbd8)\n\n输入数据是：\n```\n0x60606040523415600e57600080fd5b6040516020806073833981016040528080519060200190919050508060008190555050603580603e6000396000f3006060604052600080fd00a165627a7a7230582062a4d50871818ee0922255f5848ba4c7e4edc9b13c555984b91e7447d3bb0e7400290000000000000000000000000000000000000000000000000000000000000042\n```\n我们可以在最后面看到构造器的参数，也就是`66`，但是作为ABI编码的32位字节就是：\n```\n0000000000000000000000000000000000000000000000000000000000000042\n```\n为了处理构造器里面的参数，部署代码从`calldata`中的结尾拷贝ABI参数到内存中，然后从内存中拷贝到栈中。\n\n## 创建合约的合约\n`FooFactory`合约可以通过调用`makeNewFoo`来创建一个新的`Foo`实例：\n```\npragma solidity ^0.4.11;\ncontract Foo {\n}\ncontract FooFactory {\n  address fooInstance;\n  function makeNewFoo() {\n    fooInstance = new Foo();\n  }\n}\n```\n这个合约完整的汇编代码在[Gist](https://gist.github.com/hayeah/a94aa4e87b7b42e9003adf64806c84e4)里。编译器输出的结构更加的复杂，因为这里有两套”安装时间“和”运行时间“的字节码。就像这样组织的：\n```\nFooFactoryDeployCode\nFooFactoryContractCode\n  FooDeployCode\n  FooContractCode\n  FooAUXData\nFooFactoryAUXData\n```\n`FooFactoryContractCode`本质就是为`tag_8`中`Foo`拷贝字节码然后跳转回`tag_7`去执行`create`指令。\n\n`create`指令就像`eth_sendtransaction`RPC调用。它提供了一个在EVM里面创建新合约的方法。\n\n看一下go-ethereum 源代码里面的[opCreate](https://sourcegraph.com/github.com/ethereum/go-ethereum@e9295163aa25479e817efee4aac23eaeb7554bba/-/blob/core/vm/instructions.go#L572:6) 。这个指令调用`evm.Create`来创建合约：\n```\nres, addr, returnGas, suberr := evm.Create(contract, input, gas, value)\n```\n我们在前面就已经看见了`evm.Create`，但是这次的调用者是一个智能合约而不是人类。\n\n## AUXDATA\n如果你想要完全的理解auxdata是什么，那么可以阅读 [合约元数据](https://github.com/ethereum/solidity/blob/8fbfd62d15ae83a757301db35621e95bccace97b/docs/metadata.rst#encoding-of-the-metadata-hash-in-the-bytecode)。它的要点就是`auxdata`是一个哈希值，你可以使用它来抓取部署合约的元数据。\n\nauxdata的格式就是：\n```\n0xa1 0x65 'b' 'z' 'z' 'r' '0' 0x58 0x20 <32 bytes swarm hash> 0x00 0x29`\n```\n\n解构我们之前看到过的auxdata字节序列：\n```\na1 65\n// b z z r 0 (ASCII)\n62 7a 7a 72 30\n58 20\n// 32 bytes hash\n62a4d50871818ee0922255f5848ba4c7e4edc9b13c555984b91e7447d3bb0e74\n00 29\n```\n## 总结\n合约创建的方式和自我解压软件安装程序的工作方式比较类似。当安装程序运行时，它会配置系统环境，然后会从程序包中读取目标程序放入到系统中。\n- 在”安装时间“和”运行时间“之间有一个强制的分离。无法运行构造器两次\n- 智能合约可以使用相同的处理来创建其他的智能合约\n- 使用非Solidity语言实现会容易一点\n\n首先，我对”智能合约安装程序“的不同部分被打包到一起作为字节字符串`data`放在交易里感到很困惑：\n```\n{\n  \"data\": constructorCode + contractCode + auxdata + constructorData\n}\n```\n`data`是如何被编码的，阅读文档中的`eth_sendtransaction`无法获得明显的答案。我一直都没弄明白构造器的参数是如何传递给交易的，直到有一个朋友告诉我它们被ABI进行编码之后附加到字节码的后面，才明白是怎么回事。\n\n另一个可以使它看起来更加清晰一点的替代设计也许就是将这些作为交易独立的属性进行发送：\n```\n{\n  // For \"install time\" bytecode\n  \"constructorCode\": ...,\n  // For \"run time\" bytecode\n  \"constructorBody\": ...,\n  // For encoding arguments\n  \"data\": ...,\n}\n```\n不过进行更多的思考，我认为交易对象简单化实际上是非常强大的。对于一个交易，`data`只是一个字节字符串，而且它不涉及数据是如何被解释的语言模型。通过让交易对象简单化，语言的实现者就有一个空白的画布进行设计和实验。\n\n确实，`data`在未来甚至可以被一个不同的虚拟机进行解释。\n\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[Diving Into The Ethereum VM Part Five](https://medium.com/@hayeah/diving-into-the-ethereum-vm-part-5-the-smart-contract-creation-process-cb7b6133b855)\n","tags":["ethereum"],"categories":["translation"]},{"title":"以太坊的工作原理","url":"/ethereum_theory.html","content":"**  **  <Excerpt in index | Homepage Digest>\n这篇文章主要讲解以太坊的基本原理，对技术感兴趣的朋友可以看看。\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n\n翻译作者: [许莉](https://lilymoana.github.io/)\n原文地址：[How does Ethereum work, anyway?](https://medium.com/@preethikasireddy/how-does-ethereum-work-anyway-22d1df506369) \n\n## 简介\n不管你们知不知道以太坊（Ethereum blockchain）是什么，但是你们大概都听说过以太坊。最近在新闻里出现过很多次，包括一些专业杂志的封面，但是如果你们对以太坊到底是什么没有一个基本的了解的话，看这些文章就会感觉跟看天书一样。 所以，什么是以太坊？本质上，就是一个保存数字交易永久记录的公共数据库。重要的是，这个数据库不需要任何中央权威机构来维持和保护它。相反的它以一个“无信任”的交易系统来运行—一个个体在不需要信任任何第三方或对方的情况下进行点对点交易的架构。\n\n依然感到很困惑？这就是这篇文章存在的理由。我的目标是在技术层面来解释以太坊的工作原理，但是不会出现很复杂的数学问题或看起来很可怕的公式。即使你不是一个程序员，我希望你看完之后最起码对技术有个更好的认识。如果有些部分技术性太强不好理解，这是非常正常的，真的没有必要完全理解每一个小细节。我建议只要宏观的理解一下事物就行了。\n\n这篇文章中的很多议点都是以太坊黄皮书中讨论过的概念的细分。我添加了我自己的解释和图表使理解以太坊更加简单一点。那些足够勇敢的人可以挑战一下技术，去阅读一下以太坊的黄皮书。\n\n好了， 让我们开始吧！\n\n## 区块链定义\n区块链就是一个**具有共享状态的密码性安全交易的单机(cryptographically secure transactional singleton machine with shared-state)**。[1]这有点长，是吧？让我们将它分开来看：\n- **“密码性安全(Cryptographically secure)”**是指用一个很难被解开的复杂数学机制算法来保证数字货币生产的安全性。将它想象成类似于防火墙的这种。它们使得欺骗系统近乎是一个不可能的事情（比如：构造一笔假的交易，消除一笔交易等等）。\n- **“交易的单机(Transactional singleton machine)”**是指只有一个权威的机器实例为系统中产生的交易负责任。换句话说，只有一个全球真相是大家所相信的。\n- **“具有共享状态(With shared-state)”**是指在这台机器上存储的状态是共享的，对每个人都是开放的。\n\n以太坊实现了区块链的这个范例。\n\n## 以太坊模型说明\n以太坊的本质就是一个**基于交易的状态机(transaction-based state machine)**。在计算机科学中，一个 *状态机* 是指可以读取一系列的输入，然后根据这些输入，会转换成一个新的状态出来的东西。\n<img src=\"/asset/eth_statemachine.png\"   width = \"800\" height = \"230\" alt=\"\" align=center />\n\n根据以太坊的状态机，我们从**创世纪状态(genesis state)**开始。这差不多类似于一片空白的石板，在网络中还没有任何交易的产生状态。当交易被执行后，这个创世纪状态就会转变成最终状态。在任何时刻，这个最终状态都代表着以太坊当前的状态。\n<img src=\"/asset/eth_statetransition.png\"   width = \"800\" height = \"200\" alt=\"\" align=center />\n\n以太坊的状态有百万个交易。这些交易都被“组团”到一个区块中。一个区块包含了一系列的交易，每个区块都与它的前一个区块链接起来。\n<img src=\"/asset/eth_chain.png\"   width = \"800\" height = \"200\" alt=\"\" align=center />\n\n为了让一个状态转换成下一个状态，交易必须是有效的。**为了让一个交易被认为是有效的，它必须要经过一个验证过程，此过程也就是挖矿**。挖矿就是一组节点（即电脑）用它们的计算资源来创建一个包含有效交易的区块出来。\n\n任何在网络上宣称自己是矿工的节点都可以尝试创建和验证区块。世界各地的很多矿工都在同一时间创建和验证区块。每个矿工在提交一个区块到区块链上的时候都会提供一个数学机制的“证明”，这个证明就像一个保证：如果这个证明存在，那么这个区块一定是有效的。\n\n为了让一个区块添加到主链上，一个矿工必须要比其他矿工更快的提供出这个“证明”。通过矿工提供的一个数学机制的“证明”来证实每个区块的过程称之为**工作量证明(proof of work)**。\n\n证实了一个新区块的矿工都会被奖励一定价值的奖赏。奖赏是什么？以太坊使用一种内在数字代币—**以太币(Ether)**作为奖赏。每次矿工证明了一个新区块，那么就会产生一个新的以太币并被奖励给矿工。\n\n你也许会在想：什么能确保每个人都只在区块的同一条链上呢？我们怎么能确定不会存在一部分矿工创建一个他们自己的链呢？\n\n前面，我们定义了区块链就是一个**具有共享状态的交易单机**。使用这个定义，我们可以知道正确的当前状态是一个全球真相，所有人都必须要接受它。拥有多个状态（或多个链）会摧毁这个系统，因为它在哪个是正确状态的问题上不可能得到统一结果。如果链分叉了，你有可能在一条链上拥有10个币，一条链上拥有20个币，另一条链上拥有40个币。在这种场景下，是没有办法确定哪个链才是最”有效的“。\n\n不论什么时候只要多个路径产生了，一个”分叉“就会出现。我们通常都想避免分叉，因为它们会破坏系统，强制人们去选择哪条链是他们相信的链。\n<img src=\"/asset/eth_fork.png\"   width = \"1000\" height = \"300\" alt=\"\" align=center />\n\n\n为了确定哪个路径才是最有效的以及防止多条链的产生，以太坊使用了一个叫做**“GHOST协议(GHOST protocol)”**的数学机制。\n>  ** GHOST**  = **Greedy Heaviest Observed Subtree**\n\n简单来说，GHOST协议就是让我们必须选择一个在其上完成计算最多的路径。一个方法确定路径就是使用最近一个区块（叶子区块）的区块号，区块号代表着当前路径上总的区块数（不包含创世纪区块）。区块号越大，路径就会越长，就说明越多的挖矿算力被消耗在此路径上以达到叶子区块。使用这种推理就可以允许我们赞同当前状态的权威版本。\n<img src=\"/asset/eth_canonical.png\"   width = \"1000\" height = \"300\" alt=\"\" align=center />\n\n现在你大概对区块链是什么有个理性的认识，让我们在再深入地了解一下以太坊系统主要组成部分：\n- 账户(accounts)\n- 状态(state)\n- 损耗和费用(gas and fees)\n- 交易(transactions)\n- 区块(blocks)\n- 交易执行(transaction execution)\n- 挖矿(mining)\n- 工作量证明(proof of work)\n\n在开始之前需要注意的是：每当我说某某的Hash， 我指的都是[KECCAK-256](https://ethereum.stackexchange.com/questions/550/which-cryptographic-hash-function-does-ethereum-use) hash, 以太坊就是使用这个Hash算法。\n\n## 账户\n以太坊的全局“共享状态”是有很多小对象（账户）来组成的，这些账户可以通过消息传递来与对方进行交互。每个账户都有一个与之关联的**状态(state)**和一个20字节的**地址(address)**。在以太坊中一个地址是160位的标识符，用来识别账户。\n\n两种不同类型的账户：\n- 外部拥有的账户，被私钥控制且没有任何代码与之关联\n- 合约账户，被它们的合约代码控制且有代码与之关联\n<img src=\"/asset/eth_account.png\"   width = \"\" height = \"300\" alt=\"\" align=center />\n\n\n### 外部拥有账户与合约账户的比较\n理解外部拥有账户和合约账户的基本区别是很重要的。一个外部拥有账户可以通过创建和用自己的私钥来对交易进行签名，来发送消息给另一个外部拥有账户或合约账户。在两个外部拥有账户之间传送的消息只是一个简单的价值转移。但是从外部拥有账户到合约账户的消息会激活合约账户的代码，允许它执行各种动作。（比如转移代币，写入内部存储，挖出一个新代币，执行一些运算，创建一个新的合约等等）。\n\n不像外部拥有账户，合约账户不可以自己发起一个交易。相反，合约账户只有在接收到一个交易之后(从一个外部拥有账户或另一个合约账户处)，为了响应此交易而触发一个交易。我们将会在“交易和消息”章节来了解关于合约与合约之间的通信。\n<img src=\"/asset/eth_transationset.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n**因此，在以太坊上任何的动作，总是被外部拥有账户触发的交易所发动的。**\n<img src=\"/asset/eth_blockchain.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n### 账户状态\n账户状态有四个组成部分，不论账户类型是什么，都存在这四个组成部分：\n- nonce：如果账户是一个外部拥有账户，nonce代表从此账户地址发送的交易序号。如果账户是一个合约账户，nonce代表此账户创建的合约序号\n- balance： 此地址拥有Wei的数量。1Ether=10^18Wei\n- storageRoot： Merkle Patricia树的根节点Hash值（我们后面在解释Merkle树）。Merkle树会将此账户存储内容的Hash值进行编码，默认是空值\n- codeHash：此账户EVM（以太坊虚拟机，后面细说）代码的hash值。对于合约账户，就是被Hash的代码并作为codeHash保存。对于外部拥有账户，codeHash域是一个空字符串的Hash值\n<img src=\"/asset/eth_codehash.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n### 世界状态\n好了，我们知道了以太坊的全局状态就是由账户地址和账户状态组成的一个映射。这个映射被保存在一个叫做Merkle Patricia树的数据结构中\n\nMerkle Tree（也被叫做Merkle trie）是一种由一系列节点组成的二叉树，这些节点包括：\n- 在树底的大量叶子节点，这些叶子节点包含了源数据\n- 一系列的中间节点，这些节点是两个子节点的Hash值\n- 一个根节点，同样是两个子节点的Hash值，代表着整棵树\n<img src=\"/asset/eth_merkletree.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\n树底的数据是通过分开我们想要保存到**chunks**的数据产生的，然后将**chunks**分成**buckets**，再然后获取每个**bucket**的hash值并一直重复直到最后只剩下一个Hash：根Hash。\n<img src=\"/asset/eth_roothash.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\n这棵树要求存在里面的值（value）都有一个对应的key。从树的根节点开始，key会告诉你顺着哪个子节点可以获得对应的值，这个值存在叶子节点。在以太坊中，key/value是地址和与地址相关联的账户之间状态的映射，包括每个账户的balance, nonce, codeHash和storageRoot（storageRoot自己就是一颗树）。\n<img src=\"/asset/eth_nonce.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\n同样的树结构也用来存储交易和收据。更具体的说，每个块都有一个**头(header)**，头中保存了三个Merkle树结构的根节点Hash，三个Merkle树分别为：\n- 状态树\n- 交易树\n- 收据树\n<img src=\"/asset/eth_blockheader.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\nMerkle树中存储信息的高效性在以太坊的“轻客户端”和“轻节点”中相当的有用。记住区块链就是一群节点来维持的。广泛的说，有两种节点类型：全节点和轻节点。\n\n全节点通过下载整条链来进行同步，从创世纪块到当前块，执行其中包含的所有交易。通常，矿工会存储全节点，因为他们在挖矿过程中需要全节点。也有可能下载一个全节点而不用执行所有的交易。无论如何，一个全节点包含了整个链。\n\n不过除非一个节点需要执行所有的交易或轻松访问历史数据，不然没必要保存整条链。这就是轻节点概念的来源。**比起下载和存储整个链以及执行其中所有的交易，轻节点仅仅下载链的头，从创世纪块到当前块的头，不执行任何的交易或检索任何相关联的状态**。由于轻节点可以访问区块头，而头中包含了3个Merkle树的根Hash值，所有轻节点依然可以很容易生成和接收关于交易、事件、余额等可验证的答案。\n\n这个可以行的通是因为在Merkle树中Hash值是向上传播的—如果一个恶意用户试图用一个假交易来交换Merkle树底的交易，这个会改变它上面节点的Hash值，而它上面节点的值的改变也会导致上上一个节点Hash值的改变，以此类推，一直到树的根节点。\n<img src=\"/asset/eth_hashchange.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\n任何节点想要验证一些数据都可以通过**Merkle证明**来进行验证，**Merkle 证明**的组成：\n- 一块需要验证的数据\n- 树的根节点Hash值\n- 一个“分支”（从 **chunk**到根这个路径上所有的Hash值）\n<img src=\"/asset/eth_chunk.png\"   width = \"600\" height = \"300\" alt=\"\" align=center />\n\n任何可以读取证明的人都可以验证分支的Hash值是连贯的，因此给出的块在树中实际的位置就是在此处。\n\n**总之，使用Merkle Patricia树的好处就是该结构的根节点加密取决于存储在树中的数据，而且根节点的Hash值还可以作为该数据的安全标识。由于块的头包含了状态树、交易树、收据树的根Hash值，所以任何节点都可以验证以太坊的一小部分状态而不用保存整个状态，这整个状态的的大小可能是非常大的。**\n\n## Gas和费用\n在以太坊中一个比较重要的概念就是**费用(fees)**，**由以太坊网络上的交易而产生的每一次计算，都会产生费用—没有免费的午餐**。这个费用是以\"gas\"来支付。\n\nGas就是用来衡量在一个具体计算中要求的费用单位。gas price就是你愿意在每个gas上花费Ether的数量，以“gwei”进行衡量。“Wei”是Ether的最小单位，1Ether=10^18Wei，1gwei=1,000,000,000 Wei。\n\n对每个交易，发送者设置gas limit和gas price。gas limit和gas price就代表着发送者愿意为执行交易支付的Wei的最大值。\n\n例如，假设发送者设置gas limit为50,000，gas price为20gwei。这就表示发送者愿意最多支付50,000*20gwei = 1,000,000,000,000,000 Wei = 0.001 Ether来执行此交易。\n![](/asset/eth_price.png) \n\n记住gas limit代表用户愿意花费在gas上费用的最大值。如果在他们的账户余额中有足够的Ether来支付这个最大值费用，那么就没问题。在交易结束时任何未使用的gas都会被返回给发送者，以原始费率兑换。\n![](/asset/eth_gas.png) \n\n在发送者没有提供足够的gas来执行交易，那么交易执行就会出现“gas不足”然后被认为是无效的。在这种情况下，交易处理就会被终止以及所有已改变的状态将会被恢复，最后我们就又回到了交易之前的状态—完完全全的之前状态就像这笔交易从来没有发生。因为机器在耗尽gas之前还是为计算做出了努力，\n所以理论上，**将不会有任何的gas被返回给发送者**。\n![](/asset/eth_refunder.png) \n\n这些gas的钱到底去了哪里？**发送者在gas上花费的所有费用都被发送到“受益人”的地址，通常情况下就是矿工的地址**。因为矿工为了计算和验证交易做出了努力，所以矿工接收gas的费用作为奖励。\n<img src=\"/asset/eth_reward.png\"   width = \"800\" height = \"250\" alt=\"\" align=center />\n\n通常，发送者愿意支付更高的gas price，矿工从这笔交易中就能获得更多的价值。因此，矿工也就更加愿意选择这笔交易。这样的话，矿工可以自由的选择自己愿意验证或忽略的交易。为了引导发送者设置合理的gas price，矿工可以选择建议一个最小的gas值，此值代表自己愿意执行交易的最低价格。\n\n### 存储也有费用\nGas不仅仅是用来支付计算这一步的费用，而且也用来支付存储的费用。存储的总费用与所使用的32位字节的最小倍数成比例。\n\n存储费用有一些比较细微的方面。比如，由于增加的存储增加了所有节点上的以太坊状态数据库的大小，所以激励保持数据存储量小。为了这个原因，如果一个交易的执行有一步是清除一个存储实体，那么为执行这个操作的费用就会被放弃，并且由于释放存储空间的退款就会被返回给发送者。\n\n### 费用的作用是什么？\n以太坊可以运作的一个重要方面就是每个网络执行的操作同时也被全节点所影响。然而，计算的操作在以太坊虚拟机上是非常昂贵的。因此，以太坊智能合约最好是用来执行最简单的任务，比如运行一个简单的业务逻辑或者验证签名和其他密码对象，而不是用于复杂的操作，比如文件存储，电子邮件，或机器学习，这些会给网络造成压力。**施加费用防止用户使网络超负荷**。\n\n以太坊是一个图灵完备语言（短而言之，图灵机器就是一个可以模拟任何电脑算法的机器。对于图灵机器不太熟悉的人可以看看[这个](https://en.wikipedia.org/wiki/Turing_machine) 和[这个](http://mathworld.wolfram.com/TuringMachine.html) ）。这就允许有循环，并使以太坊受到[停机问题](https://en.wikipedia.org/wiki/Halting_problem) 的影响，这个问题让你无法确定程序是否无限制的运行。如果没有费用的话，恶意的执行者通过执行一个包含无限循环的交易就可以很容易的让网络瘫痪而不会产生任何反响。因此，费用保护网络不受蓄意攻击。\n\n你也许会想，“为什么我们还需要为存储付费？”其实就像计算一样，以太坊网络上的存储是整个网络都必须要负担的成本。\n\n## 交易和消息\n之前说过以太坊是一个基于交易的状态机。换句话说，在两个不同账户之间发生的交易才让以太坊的全局状态从一个状态转换成另一个状态。\n\n**最基本的概念，一个交易就是指被外部拥有账户生成的加密签名的一段指令，序列化之后提交给区块链。**\n\n有两种类型的交易：**消息通信(message calls)**和**合约创建(contract creations)(也就是交易产生一个新的以太坊合约)**。\n\n不管什么类型的交易，都包含：\n- nonce：发送者发送交易数的计数\n- gasPrice：发送者愿意支付执行交易所需的每个gas的Wei数量\n- gasLimit：发送者愿意为执行交易支付gas数量的最大值。此值设置之后在任何计算完成之前就会被提前扣掉\n- to：接收者的地址。在合约创建交易中，合约账户的地址还没有存在，所以值先空着\n- value：从发送者转移到接收者Wei的数量。在合约创建交易中，value作为新建合约账户的开始余额\n- v,r,s：用于产生标识交易发送者的签名\n- init（只有在合约创建交易中存在）：用来初始化新合约账户的EVM代码片段。**init**值会执行一次，然后就会被丢弃。当**init**第一次执行的时候，它返回一个账户代码体，也就是永久与合约账户关联的一段代码。\n- data（可选域，只有在**消息通信**中存在）：消息通信中的输入数据(也就是参数)。例如，如果智能合约就是一个域名注册服务，那么调用合约可能就会期待输入参数：域名和IP地址\n<img src=\"/asset/eth_transationmessage.png\"   width = \"500\" height = \"300\" alt=\"\" align=center />\n\n在“账户”这个章节中我们学到交易—**消息通信**和合约创建交易两者都总是被外部拥有账户触发并提交到区块链的。换种思维思考就是，交易是外部世界和以太坊内部状态的桥梁。 \n<img src=\"/asset/eth_ bridge.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n但是这也并不代表一个合约与另一个合约无法通信。**在以太坊状态全局范围内的合约可以与在相同范围内的合约进行通信。他们是通过“消息”或者“内部交易”进行通信的**。我们可以认为消息或内部交易类似于交易，不过与交易有着最大的不同点—它们不是由外部拥有账户产生的。相反，他们是被合约产生的。它们是虚拟对象，与交易不同，没有被序列化而且只存在于以太坊执行环境。\n\n**当一个合约发送一个内部交易给另一个合约，存在于接收者合约账户相关联的代码就会被执行。**\n![](/asset/eth_excuted.png) \n\n一个需要注意的重要事情是内部交易或者消息不包含**gasLimit**。因为gas limit是由原始交易的外部创建者决定的（也就是外部拥有账户）。外部拥有账户设置的gas limit必须要高到足够将交易完成，包括由于此交易而产生的任何\"子执行\"，例如合约到合约的消息。如果，在一个交易或者信息链中，其中一个消息执行造成gas不足，那么这个消息的执行会被还原，包括任何被此执行触发的子消息。不过，父执行没必要被还原。\n\n## 区块\n所有的交易都被组成一个\"块\"。一个区块链包含了一系列这样链在一起的区块。\n\n在以太坊中，一个区块包含：\n- **区块头**\n- 关于包含在此区块中**交易集**的信息\n-  与当前块的ommers相关的一系列其他区块头\n\n### Ommers解释\n“ommer”到底是什么？ ommer就是一个区块的父区块与当前区块父区块的父区块是相同的。让我们快速了解一下ommers是用来干嘛的，并且为什么一个区块需要为ommers包含区块头。\n\n由于以太坊的构造，它的区块生产时间（大概15秒左右）比其他的区块链例如Bitcoin（大概10分钟左右）要快很多。这使得交易的处理更快。但是，更短的区块生产时间的一个缺点就是：更多的竞争区块会被矿工发现。这些竞争区块同样也被称为“孤区块”（也就是被挖出来但是不会被添加到主链上的区块）。\n\nOmmers的目的就是为了帮助奖励矿工纳入这些孤区块。矿工包含的ommers必须是有效的，也就是ommers必须是往上数6代之内或更小范围内父区块的子区块。  一个孤区块在第6个子区块之后，这种陈旧的孤区块将不会再被引用（因为包含老旧的交易会使事情变得复杂一点）。\n\nOmmer区块会收到比全区块少一点的奖励。不管怎样，依然存在激励来让矿工们纳入孤区块并能从中获得一些报酬。\n\n### 区块头\n让我们再回到区块的问题上。我们前面提到每个区块都有一个“区块头”，但这究竟是什么？\n\n区块头是区块的一部分，包含了：\n- parentHash：父区块头的Hash值（这也是使得区块变成区块链的原因）\n- ommerHash：当前区块ommers列表的Hash值\n- beneficiary：接收挖此区块费用的账户地址\n- stateRoot：状态树根节点的Hash值（回忆一下我们之前所说的保存在头中的状态树以及它使得轻客户端认证任何关于状态的事情都变得非常简单）\n- transactionsRoot：包含此区块所有交易的Merkle树的根节点Hash值\n- receiptsRoot：包含此区块所有交易收据的Merkle树的根节点Hash值\n- logsBloom：由日志信息组成的一个[Bloom过滤器](https://en.wikipedia.org/wiki/Bloom_filter) (一种数据结构)\n- difficulty： 此区块的难度级别\n- number：当前区块的计数（创世纪块的区块序号为0，对于每个后续区块，区块序号都增加1）\n- gasLimit：每个区块的当前gas limit\n- gasUsed： 此区块中交易所用的总gas量\n- timestamp：此区块成立时的unix的时间戳\n- extraData：与此区块相关的附加数据\n- mixHash：一个Hash值，当与nonce组合时，证明此区块已经执行了足够的计算\n- nonce：一个Hash值，当与mixHash组合时，证明此区块已经执行了足够的计算\n<img src=\"/asset/eth_blockheaders.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n注意每个区块是如何包含三个树结构的，三个树结构分别对应：\n- 状态（stateRoot）\n- 交易（transactionsRoot）\n- 收据（receiptsRoot）\n这三个树结构就是我们前面讨论的Merkle Patricia树。\n\n另外，上面描述的有几个术语值得说明一下，下面来看一下。\n\n### 日志\n以太坊允许日志可以跟踪各种交易和信息。一个合约可以通过定义“事件”来显示的生成日志。\n\n一个日志的实体包含：\n- 记录器的账户地址\n- 代表本次交易执行的各种事件的一系列主题以及与这些事件相关的任何数据\n\n日志被保存在[bloom过滤器](https://en.wikipedia.org/wiki/Bloom_filter) 中，过滤器高效的保存了无尽的日志数据。\n\n### 交易收据\n包含着日志信息的交易收据的根Hash值保存在头中。 就像你在商店买东西时收到的收据一样，以太坊为每笔交易都产生一个收据。像你期望的那样，每个收据包含关于交易的特定信息，这些信息为：\n- 区块序号\n- 区块Hash值\n- 交易Hash值\n- 当前交易使用了的gas\n- 在当前交易执行完之后当前块使用的累计gas\n- 执行当前交易时创建的日志\n- 等等\n\n### 区块难度\n区块的难度是被用来在验证区块时加强一致性。创世纪区块的难度是131,072，有一个特殊的公式用来计算之后的每个块的难度。如果某个区块比前一个区块验证的更快，以太坊协议就会增加区块的难度。\n\n区块的难度影响**nonce**，它是在挖矿时必须要使用工作量证明算法计算出的一个Hash值。\n\n区块**难度**和**nonce**之间的关系用数学形式表达就是：\n![](/asset/eth_math.png) \n**Hd**代表的是难度。\n\n找到符合难度阈值的**nonce**唯一方法就是使用工作量证明算法来列举所有的可能性。找到解决方案预期时间与难度成正比—难度越高，找到**nonce**就越困难，因此验证一个区块也就越难，这又相应地增加了验证新块所需的时间。**所以，通过调整区块难度，协议可以调整验证区块所需的时间**。\n\n另一方面，如果验证时间变的越来越慢，协议就会降低难度。这样的话，验证时间自我调节以保持恒定的速率—平均每15s一个块。\n\n## 交易执行\n我们已经到了以太坊协议最复杂的部分：交易的执行。假设你发送了一笔交易给以太坊网络处理，将以太坊状态转换成包含你的交易这个过程到底发生了什么？\n<img src=\"/asset/eth_transition.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n首先，为了可以被执行所有的交易必须都要符合最基础的一系列要求，包括：\n- 交易必须是正确格式化的RLP。\"RLP\"代表Recursive Length Prefix，它是一种数据格式，用来编码二进制数据嵌套数组。以太坊就是使用RLP格式序列化对象。\n- 有效的交易签名。\n- 有效的交易序号。回忆一下账户中的nonce就是从此账户发送出去交易的计数。如果有效，那么交易序号一定等于发送账户中的nonce。\n- 交易的gas limit 一定要等于或者大于交易使用的**intrinsic gas**，**intrinsic gas**包括：\n&nbsp;&nbsp;&nbsp;1.执行交易预订费用为21,000gas\n&nbsp;&nbsp;&nbsp;2.随交易发送的数据的gas费用（每字节数据或代码为0的费用为4gas，每个非零字节的数据或代码费用为68gas）\n&nbsp;&nbsp;&nbsp;3.如果是合约创建交易，还需要额外的32,000gas\n![](/asset/eth_ intrinsicgas.png) \n- 发送账户余额必须有足够的Ether来支付\"前期\"gas费用。前期gas费用的计算比较简单：首先，交易的gas limit乘以交易的gas价格得到最大的gas费用。然后，这个最大的gas费用加上从发送方传送给接收方的总值。\n![](/asset/eth_upfront.png) \n\n如果交易符合上面的所有要求，那么我们进行下面的步骤。\n\n第一步，我们从发送者的余额中扣除执行的前期费用，并为当前交易将发送者账户中的nonce增加1。此时，我们可以计算剩余的gas，将交易的总gas减去使用的**intrinsic gas**。\n![](/asset/eth_gasremaining.png) \n\n第二步，开始执行交易。在交易执行的整个过程中，以太坊保持跟踪“子状态”。子状态是记录在交易中生成的信息的一种方式，当交易完成时会立即需要这些信息。具体来说，它包含：\n- 自毁集：在交易完成之后会被丢弃的账户集（如果存在的话）\n- 日志系列：虚拟机的代码执行的归档和可检索的检查点\n- 退款余额：交易完成之后需要退还给发送账户的总额。回忆一下我们之前提到的以太坊中的存储需要付费，发送者要是清理了内存就会有退款。以太坊使用退款计数进行跟踪退款余额。退款计数从0开始并且每当合约删除了一些存储中的东西都会进行增加。\n\n第三步，交易所需的各种计算开始被处理。\n\n当交易所需的步骤全部处理完成，并假设没有无效状态，通过确定退还给发送者的未使用的gas量，最终的状态也被确定。除了未使用的gas，发送者还会得到上面所说的“退款余额”中退还的一些津贴。\n\n一旦发送者得到退款之后：\n- gas的Ether就会给矿工\n- 交易使用的gas会被添加到区块的gas计数中（计数一直记录当前区块中所有交易使用的gas总量，这对于验证区块时是非常有用的）\n- 所有在**自毁集**中的账户（如果存在的话）都会被删除\n\n最后，我们就有了一个新的状态以及交易创建的一系列日志。\n\n现在我们已经介绍了交易执行的基本知识，让我们再看看合约创建交易和消息通信的一些区别。\n\n### 合约创建(Contract creation)\n回忆一下在以太坊中，有两种账户类型：合约账户和外部拥有账户。当我们说一个交易是“合约创建”，是指交易的目的是创建一个新的合约账户。\n\n为了创建一个新的合约账户，我们使用一个特殊的公式来声明新账户的地址。然后我们使用下面的方法来初始化一个账户：\n- 设置nonce为0\n- 如果发送者通过交易发送了一定量的Ether作为**value**，那么设置账户的余额为**value**\n- 将存储设置为0\n- 设置合约的**codeHash**为一个空字符串的Hash值\n\n一旦我们完成了账户的初始化，使用交易发送过来的**init code**（查看\"交易和消息\"章节来复习一下**init code**），实际上就创造了一个账户。**init code**的执行过程是各种各样的。取决于合约的构造器，可能是更新账户的存储，也可能是创建另一个合约账户，或者发起另一个消息通信等等。\n\n\n当初始化合约的代码被执行之后，会使用gas。**交易不允许使用的gas超过剩余gas。如果它使用的gas超过剩余gas，那么就会发生gas不足异常(OOG)并退出。如果一个交易由于gas不足异常而退出，那么状态会立刻恢复到交易前的一个点。发送者也不会获得在gas用完之前所花费的gas**。\n\n不过，如果发送者随着交易发送了Ether，即使合约创建失败Ether也会被退回来。\n\n如果初始化代码成功的执行完成，最后合约创建的花费会被支付。这些是存储成本，与创建的合约代码大小成正比（再一次，没有免费的午餐）。如果没有足够的剩余gas来支付最后的花费，那么交易就会再次宣布gas不足异常并中断退出。\n\n如果所有的都正常进行没有任何异常出现，那么任何剩余的未使用gas都会被退回给原始的交易发送者，现在改变的状态才被允许永久保存。\n\n### 消息通信(Message calls)\n消息通信的执行与合约创建比较类似，只不过有一点点区别。\n\n由于没有新账户被创建，所以消息通信的执行不包含任何的**init code**。不过，它可以包含输入数据，如果交易发送者提供了此数据的话。一旦执行，消息通信同样会有一个额外的组件来包含输出数据，如果后续执行需要此数据的话组件就会被使用。\n\n就像合约创建一样，如果消息通信执行退出是因为gas不足或交易无效（例如栈溢出，无效跳转目的地或无效指令），那么已使用的gas是不会被退回给原始触发者的。相反，所有剩余的未使用gas也会被消耗掉，并且状态会被立刻重置为余额转移之前的那个点。\n\n没有任何方法停止或恢复交易的执行而不让系统消耗你提供的所有gas，直到最新的以太坊更新。例如，假设你编写了一个合约，当调用者没有授权来执行这些交易的时候抛出一个错误。在以太坊的前一个版本中，剩余的gas也会被消耗掉，并且没有任何gas退回给发送者。**但是拜占庭更新包括了一个新的“恢复”代码，允许合约停止执行并且恢复改变的状态而不消耗剩余的gas，此代码还拥有返回交易失败原因的能力**。如果一个交易是由于恢复而退出，那么未使用的gas就会被退回给发送者。\n\n## 执行模式\n到目前为止，我们了解了从开始到结束交易的执行必须经历的一系列步骤。现在，我们来看看交易究竟是如何在虚拟机(VM)中执行的。\n\n**协议实际操作交易处理的部分是以太坊自己的虚拟机，称之为以太坊虚拟机(EVM)**。\n\n像之前定义的那样，EVM是图灵完备虚拟机器。EVM存在而典型图灵完备机器不存在的唯一限制就是EVM本质上是被gas束缚。因此，可以完成的计算总量本质上是被提供的gas总量限制的。\n![](/asset/eth_evm.png) \n\n此外，EVM具有基于堆栈的架构。[堆栈机器](https://en.wikipedia.org/wiki/Stack_machine) 就是使用后进先出来保存临时值的计算机。\n\nEVM中每个堆栈项的大小为256位，堆栈有一个最大的大小，为1024位。\n\nEVM有内存，各项按照可寻址字节数组来存储。内存是易失性的，也就是数据是不持久的。\n\nEVM也有一个存储器。不像内存，存储器是非易失性的，并作为系统状态的一部分进行维护。EVM分开保存程序代码，在虚拟[ROM](https://en.wikipedia.org/wiki/Read-only_memory) 中只能通过特殊指令来访问。这样的话，EVM就与典型的[冯·诺依曼架构](https://en.wikipedia.org/wiki/Von_Neumann_architecture) 不同，此架构将程序的代码存储在内存或存储器中。\n<img src=\"/asset/eth_evmstorage.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\nEVM同样有属于它自己的语言：“EVM字节码”，当一个程序员比如你或我写一个在以太坊上运行的智能合约时，我们通常都是用高级语言例如Solidity来编写代码。然后我们可以将它编译成EVM可以理解的EVM字节码。\n\n好了，现在来说执行。\n\n在执行特定的计算之前，处理器会确定下面所说的信息是否有效和是否可获取：\n- 系统状态\n- 用于计算的剩余gas\n- 拥有执行代码的账户地址\n- 原始触发此次执行的交易发送者的地址\n- 触发代码执行的账户地址（可能与原始发送者不同）\n- 触发此次执行的交易gas price\n- 此次执行的输入数据\n- **Value**(单位为Wei)作为当前执行的一部分传递给该账户\n- 待执行的机器码\n- 当前区块的区块头\n- 当前消息通信或合约创建堆栈的深度\n\n执行刚开始时，内存和堆栈都是空的，程序计数器为0。\n```\nPC: 0 STACK: [] MEM: [], STORAGE: {}\n```\n然后EVM开始递归的执行交易，为每个循环计算**系统状态**和**机器状态**。系统状态也就是以太坊的全局状态(global state)。机器状态包含：\n- 可获取的gas\n- 程序计数器\n- 内存的内容\n- 内存中字的活跃数\n- 堆栈的内容\n\n堆栈中的项从系列的最左边被删除或者添加。\n\n每个循环，剩余的gas都会被减少相应的量，程序计数器也会增加。\n在每个循环的结束，都有三种可能性：\n- 机器到达异常状态（例如 gas不足，无效指令，堆栈项不足，堆栈项会溢出1024，无效的JUMP/JUMPI目的地等等）因此停止，并丢弃所有更改\n- 进入后续处理下一个循环\n- 机器到达了受控停止（到达执行过程的终点）\n\n假设执行没有遇到异常状态，达到一个“可控的”或正常的停止，机器就会产生一个合成状态，执行之后的剩余gas、产生的子状态、以及组合输出。\n\n呼。我们终于过了一遍以太坊最难的部分了。如果你不能完全理解这个部分，也没关系。除非你在研究非常深层次的东西，否则你真的没有必要去理解交易执行的每个细节。\n\n### 一个块是如何完成的？\n最后，让我们看看一个包含许多交易的块是如何完成的。\n\n当我们说“完成”，取决于此块是新的还是已存在的，可以指两个不同的事情。如果是个新块，就是指挖这个块所需的处理。如果是已存在的块，就是指验证此块的处理。不论哪种情况，一个块的“完成”都有4个要求：\n1）验证（或者，如果是挖矿的话，就是确定）ommers\n在区块头中的每个ommer都必须是有效的并且必须在当前块往上6代之内\n\n2）验证（或者，如果是挖矿的话，就是确定）交易\n区块中的**gasUsed**数量必须与区块中所列交易使用的累积gas量相等。（回忆一下，当执行一个交易的时候，我们会跟踪区块的gas计数器，也就跟踪了区块中所有交易使用的gas总数量）\n\n3）申请奖励（只有挖矿时）\n受益人的地址会因为挖矿而获得5Ether（在以太坊[EIP-649](https://github.com/ethereum/EIPs/pull/669) 提案中，5ETH很快将会被减少为3ETH）。另外，对于每个ommer，当前块的受益人会获得额外的1/32当前块奖励金的奖励。最近，每个ommer区块的受益人能够得到一定量的奖励（有个特殊公式可以进行计算）。\n\n4）校验（或者，如果是挖矿的话，就是计算一个有效的）状态和nonce\n确保所有的交易和改变的结果状态都被应用了，然后在区块奖励被应用于最终交易结果状态之后定义一个新块为状态。通过检查最终状态与存储在头中的状态树来进行验证。\n\n## 工作量证明挖矿\n在“区块”这个章节简短的说明了一下区块难度这个概念。给予区块难度意义的算法叫做工作量证明（PoW）。\n\n以太坊的工作量证明算法称之为[“Ethash”](https://github.com/ethereum/wiki/wiki/Ethash) （之前叫做Dagger-Hashimoto）。\n算法正式定义为：\n![](/asset/eth_algorithm.png) \n**m**代表的是**mixHash**，**n**代表的是**nonce**，**Hn**代表的是新区块的头（不包含需要计算的**nonce**和**mixHash**），**Hn**是区块头的nonce，**d**是[DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) ，就是一个大数据集。\n\n在\"区块\"章节，我们讨论了存在于区块头中的多项。其中两项叫做**mixHash**和**nonce**。也许你会回忆起：\n- mixHash：一个Hash值，当与nonce组合时，证明此区块已经执行了足够的计算\n- nonce：一个Hash值，当与mixHash组合时，证明此区块已经执行了足够的计算\n\nPoW函数就是用来估算这两项的。\n**mixHash**和**nonce**到底是如何使用PoW函数来计算出来的有点复杂，如果深入了解的话，我们可以另写一篇文章来讲解了。但是在一个高层面上，它大致就是这样计算的：\n会为每个区块计算一个\"种子\"。每个“时期”的种子都不一样，每个时期是30,000个区块长度。对于第一时期，种子就是32位0的Hash值。对于后续的每个时期，种子就是前一个种子Hash值的Hash值。使用这个种子，节点可以计算出一个伪随机“缓存”。\n\n这个缓存是非常有用的，因为它可以使“轻节点”的概念变成现实，轻节点概念在这篇文章的前面讨论过。轻节点的目的就是让某个节点有能力高效的校验交易而用不着存储整个区块链的数据集。一个轻节点可以仅基于缓存来校验一个交易的有效性，因为缓存可以重新生成需要校验的特定块。\n\n使用这个缓存，节点可以生成DAG“数据集”，数据集中的每项取决于缓存中少量伪随机选择项。为了成为矿工，你需要要生成全数据集，所有全客户端和矿工都保存这个数据集，并且这个数据集随着时间线性增长。\n\n然后矿工可以随机抽取数据集中的部分并将它们放入一个数学函数中Hash出一个\"mixHash\"。矿工会重复生成**mixHash**直到输出的值小于想要的目标值**nonce**。当输出的值符合这个条件的时候，nonce就被认为是有效的，然后区块就被添加到链中。\n\n### 挖矿作为安全机制\n总的来说，PoW的目的就是以加密安全的方式证明生成的一些输出（也就是**nonce**）是经过了一定量的计算的。**因为除了列举所有的可能性，没有更好的其他方法来找到一个低于要求阈值的nonce**。重复应用Hash函数的输出均匀分布，所以我们可以确保，在平均值上，**找到满足要求的nonce所需时间取决于难度阈值**。难度系数越大，所需时间越长。这样的话，**PoW算法就给予难度这个概念意义了：用来加强区块链的安全**。\n\n我们所说的区块链的安全又是什么意思？这非常简单：我们想要创造一个每个人都信任的区块链。像我们之前在这篇文章中讨论的那样，如果存在超过1条以上的链，用户的信任就会消失，因为他们没有能力合理的确认哪条链才是“有效的”。为了让一群用户接受存储在区块链中的潜在状态，我们需要有一群人信任的一个权威区块链。\n\n**这完完全全就是Pow算法所做的事情：它确保特定的区块链直到未来都一直保持着权威性，让攻击者创造一个新区块来重写某个历史部分（例如清除一个交易或者创建一个假的交易）或者保持一个分叉变得非常困难**。为了首先让他们的区块被验证，攻击者需要总是比网络上的其他人更快的解决掉**nonce**问题，这样网络就会相信他们的链是最重的链（基于我们之前提到的GHOST协议原则）。除非攻击者拥有超过一半的网络挖矿能力（这种场景也被称为[大多数51%攻击](https://en.bitcoin.it/wiki/Majority_attack) ），要不然这基本上是不可能的。\n<img src=\"/asset/eth_attack.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n\n### 挖矿作为财富分配机制\n除了提供一个安全的区块链，PoW同样也是分配财富给那些为提供这个安全而花费自己计算力的人的一种方法。回忆一下，一个矿工挖出一个区块的时候会获得奖励，包括：\n- 为“获胜”区块提供的5 ether静态区块奖励（马上就会[变成3 ether](https://github.com/ethereum/EIPs/pull/669) ）\n- 区块中的交易在区块内所消耗的gas\n- 纳入ommers作为区块的一部分的额外奖励\n\n为了保证PoW共识算法机制对安全和财富分配的使用是长期可持续的，以太坊努力灌输这两个特性：\n- 尽可能的让更多的人可访问。换句话说，人们不需要特殊的或者与众不同的硬件来运行这个算法。这样做的目的是为了让财富分配模式变的尽可能的开放，以便任何人都可以提供一些算力而获得Ether作为回报。\n- 降低任何单个节点（或小组）能够创造与其不成比例的利润可能性。任何可以创造不成比例的利润的节点拥有比较大的影响力来决定权威区块链。这是件麻烦的事情，因为这降低了网络的安全性。\n\n在区块链网络中，与上面两个特性有关的一个问题是PoW算法是SHA256哈希函数。这种函数的缺点就是它使用特殊的硬件（也被称之为ASCIs）可以更加快速高效的解决**nonce**问题。\n\n为了减轻这个问题，以太坊选择让PoW算法[(Ethhash)](https://github.com/ethereum/wiki/wiki/Ethash) 提高内存级别难度。意思是此算法被设计为计算出要求的**nonce**需要大量的内存和带宽。大量内存的需求让电脑平行的使用内存同时计算多个**nonce**变得极其困难，高带宽的需求让即使是超级电脑同时计算多个**nonce**也变得十分艰难。这种方式降低了中心化的风险，并为正在进行验证的节点提供了更加公平的竞争环境。\n\n有一件值得注意的事情是以太坊正在从PoW共识机制渐渐转换为一个叫做“权益证明(PoS)”的共识算法。这就是一个比较野心的话题了，我们希望可以在未来的文章中探索这个话题。\n\n## 总结\n呼！ 你终于坚持到最后了。我希望如此？\n\n这篇文章中有很多的地方需要消化。如果需要你阅读好几遍才能理解怎么回事，这完全正常。我个人重复阅读了好几次以太坊黄皮书，白皮书，以及代码的不同部分才渐渐明白是怎么回事。\n\n无论如何，我希望你觉得这篇文章对你有帮助。如果你发现了任何的错误或失误，我很乐意你给我写个私人消息或者直接在评论区评论（我保证我会查看所有评论）。\n\n记住，我是个人类（对，这是真的），我会犯错误。为了社区的利益，我花时间免费写了这篇文章。所以请你在反馈时不要带着没必要的攻击性，尽量是建设性的反馈。\n\n[以太坊的黄皮书](https://github.com/ethereum/yellowpaper) ","tags":["ethereum"],"categories":["translation"]},{"title":"简易支付验证能支持数十亿的比特币用户吗？","url":"/SPV.html","content":"** **  <Excerpt in index | Homepage Digest>\n原文作者是Jameson Lopp，他是BitGo的工程师，也是statoshi.info的创造者以及bitcoinsig.com的建立者。Lopp对于“移除比特币区块大小的限制是安全的，取而代之可以依靠现有的SPV方式”的声明做了一个深入的思考。\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n\n翻译作者：[许莉](https://lilymoana.github.io/)\n原文地址：[Could SPV Support a Billion Bitcoin Users?](https://www.coindesk.com/spv-support-billion-bitcoin-users-sizing-scaling-claim/) \n\n一个新的声明被永载在比特币扩展讨论中。\n\n我们听到取消比特币块大小的限制是安全的，因为比特币可以很容易就扩展到巨大的块（指块的大小），然后通过现已存在的简化支付认证（ SPV）的方式可以支持数十亿的比特币用户。假设，SPV由于只要求SPV客户存储，发送，以及接收很少的数据而具有非常好的可扩展性。\n\n让我们深入的从多个不同角度来考察一下这个问题。\n\n## SPV是如何工作的？\n即使是直到两年后 Mike Hearn创造了[BitcoinJ](https://bitcoinj.github.io/) 时才开始实施SPV，但[Satoshi](https://www.coindesk.com/information/who-is-satoshi-nakamoto/)在[比特币白皮书](https://bitcoin.org/bitcoin.pdf) 中早就描述了SPV的高层设计。\n\n以下引用于比特币白皮书中:\n> 8.简易支付认证（Simplified Payment Verification）\n> 认证支付有可能是不需要遍历整个网络全部节点的。用户只需要保存一份最长的工作量证明链的区块头内容就可以了（通过不停的向网络节点查询直到自己认为已经获取到了最长的链），以及获取带有时间戳的区块的交易相关的Merkle树分支。用户无法自己检测交易，但是通过链接到链中的某个位置，用户可以看到网络节点已经接受了这笔交易，并在进一步确认网络已经接受后块就会被加入进去。\n> <img src=\"/asset/spv_verification.png\"   width = \"800\" height = \"300\" alt=\"\" align=center />\n> 因此，只要诚实节点掌控网络，那么这个认证就是可靠的，但是如果网络被攻击者所制服，认证就会变得非常的脆弱。当网络节点可以自己认证交易时，只要攻击者能够持续掌控网络，则简易方法可能会被攻击者捏造的交易所欺骗。有一个策略可以保护不被攻击者欺骗，那就是当检测到一个无效区块时接受网络节点的改变，提示用户的软件下载完整区块和改变交易以确认一致性。经常接收到付款的业务可能还是希望能有一个自己的节点，来保证更加独立的安全性和更加快速的认证。\n\n初期SPV的实现是非常简单的—下载整个的区块链，在宽带方面下载整个的区块链并没有比下载完整块（交易已满的块）更高效。\n\n通过丢弃与SPV客户钱包无关的交易，才能够节省大量的磁盘空间。[BIP 37](https://github.com/bitcoin/bips/blob/master/bip-0037.mediawiki) 花了18个月的时间才发布，为交易提供了Bloom过滤规范，因此依靠区块头的Merkle根可以显示区块中的交易内容，就如Satoshi描述的那样。提供Bloom过滤规范大大的降低了贷款的使用。\n\n当SPV客户与比特币网络同步时，他会连接一个或多个全面认证的比特币节点，确定链顶端的最新一个区块，然后使用‘getheaders’命令请求所有的区块头，从最后一个他同步到链顶端的区块开始。\n\n如果SPV客户只对与钱包相应的特定交易感兴趣，那么它会基于钱包拥有私钥的所有地址构建一个Bloom过滤器，然后发送‘filterload’命令给全节点（一个或多个全节点），全节点就会按照过滤要求发送给客户所需的交易。\n\n在同步区块头和可能加载Bloom过滤器之后，SPV客户会发送一个‘getdata’命令来请求从他们上次在线时所遗漏的每个区块（可能是过滤之后的），按照顺序来获取遗漏的每个区块。\n\n当客户同步完之后，如果他还保持着连接全节点对端的状态，那么它只会接收到符合Bloom过滤器交易的‘inv’清单信息。\n\n## SPV客户端扩展\n从客户的视角来看，当使用最小的CPU资源，带宽，和磁盘空间时，Bloom过滤是在区块链中获取相关交易最高效的方法。\n\n每个比特币的区块头只有80个字节，所以在区块链整个8年多的历史中只有38兆的数据被写入。每年（粗略有52,560个区块），不管区块链中区块的大小，仅仅只添加了4.2兆的数据。\n\n用来显示区块中交易内容的Merkle树也扩展的非常好。因为新添加到树中的每‘层’都可以让树能表示‘叶子’的总数翻一番。即使是在一个含有数百万交易的区块中，你也不需要一个很深的树来紧凑的显示交易内容。\n <img src=\"/asset/spv_scaling.png\"   width = \"700\" height = \"300\" alt=\"\" align=center />\n\nMerkle树的数据结构是非常高效的，深度为24的树就能表示出1600万的交易——这足以代表一个8GB的区块。然而，这种交易的Merkle树证明大小仍然保持在1KB以下。\n![](/asset/spv_table.png)\n\n从SPV客户角度来看，这是非常清晰的，比特币网络可以扩展到千兆大小的区块而SPV客户端处理所需要的那些少量数据也是没有任何问题的——即使是一个3G网络的移动手机。\n\n但是啊，扩展比特币网络不是那么简单的事情！\n\n## SPV服务端扩展\n当SPV对客户端非常高效的时候，对于服务端却没这么好了——也就是，对于SPV客户发送请求的全节点，由于几种原因，这种方法表现出非常差的可扩展性。\n\n网络中的节点必须要处理非常庞大的数据才能返回一个对端想要的数据，而且需要为每个区块中的每个发送请求的对端进行着这重复的过程。磁盘I/O很快就变成了一个瓶颈。\n\n每个SPV客户都必须从上次与网络联系之后开始同步整个区块链，或者它认为自己遗漏了某些交易，它必须要从建立钱包日期起开始重新扫描整个区块链。最坏的情况下，在写入数据时，能达到大约150GB。全节点必须要从磁盘加载每个区块，根据客户要求来过滤并返回结果。\n\n由于区块链是个追加模式的账簿，数量就会不停的增加。没有一个广泛协议的改变，区块链裁剪与BIP 37就无法兼容——它期待所有的区块对于广发NODE_BLOOM消息的全节点都是可获取的。\n\n通过遗漏的方式就可以欺骗BIP 37 SPV客户端。为了预防这个，SPV客户端连接多个节点（[通常是4个](https://en.bitcoin.it/wiki/Clearing_Up_Misconceptions_About_Full_Nodes) ），不过这并不能作为担保——Sybil攻击可以将SPV客户端从主网络分离。这将全节点的网络负载增加 4倍。\n\n对于每个已同步到区块链顶端的SPV客户端，每个传入块和交易都必须被单独过滤。这就涉及到无法忽略的CPU时间量，而且必须给每个连接的SPV客户单独完成。\n\n## 推测一下数量\n在写入的时候大约有8,300个接收传入连接的全节点在运行，其中8,000个全节点广播NODE_BLOOM消息，因此有能力对于SPV客户的请求做出响应。但是，当前数量下的监听全节点能够合理支持多少SPV客户端呢？\n\n让网络由能够支撑日用户量达到数万亿以及区块大到能够容纳数万亿用户交易的全节点组成，需要什么？\n![](/asset/spv_numbers.png)\n\n比特币内核默认传入连接最大值为117，这在网络上可以创建上线为936,000个可使用的套接字。然而，这些大多数套接字在今天都已经被消耗完了。\n\n每个全节点默认连接8个其他的全节点。比特币内核开发者Luke-Jr的[节点计数](http://luke.dashjr.org/programs/bitcoin/files/charts/software.html) （非常粗略的）估计在写入的时候有 100,000个总节点数。其中92,000个节点不为SPV客户端提供有效套接字。这让全节点就消耗了800,000个有效套接字，为SPV客户端仅仅留下了136,000个有效套接字。\n\n这让我总结出大概有85%的有效套接字都是被网络中的全节点网格给消耗掉了。（值得注意的是，Luke-Jr的估计方法无法计算出非监听节点在线的时间，当然，其中一些节点肯定是周期性的断开连接然后又重新建立连接）。\n\n从[statoshi.info](https://statoshi.info/) 中获取的平均值为100个全节点（8传出连接，92个传入连接）对端和25个SPV客户。这也就是80%的有效套接字被全节点给消耗掉了。\n![](/asset/spv_peers.png)\n\n如果我们想要甚至10亿的SPV客户都可以使用这个系统，那就必须要有足够的全节点资源可以服务这些客户——网络套接字，CUP周期，磁盘I/O等等。我们能实现这个目标吗？\n\n为了相信SPV扩展能够做到，我们就比较保守的假设10亿的SPV的每个用户：\n- 每天接受和发送一条交易\n- 每天将钱包同步到区块链顶端一次\n- 同步的时候查询四个节点以降低因遗漏而被欺骗\n\n每天10亿的交易，如果平均分配（当然不会被平均分配）每个区块会有7百万的交易。由于Merkle树非常好的可扩展性，只需要23个哈希值就能证明此种区块中的交易内容：736个字节的数据外加每个交易的平均500个字节。\n\n每天加上另外的12KB的区块头数据，SPV客户会依然每天还是使用大概20KB的数据。\n\n然而，每天10亿的交易会产生大概500GB的区块链数据让全节点去存储以及处理。SPV客户连接上之后要查询自己钱包前一天的交易时，四个节点各自都需要读取和过滤这500GB的数据。\n\n记住在 8,000个SPV服务全节点的网络中当前大约有 136,000个有效套接字是为了SPV客户端准备的。如果每个SPV客户端使用4个套接字，那么在任何时刻只有34,000个客户端可以与网络进行同步。如果一次性在线的人数大于34,000，当其他的用户打开钱包试图与区块链顶端进行同步的时候就会接受到连接错误。\n\n因此，在当前只能支撑34,000个用户在任意时刻能进行同步的网络上，要支撑10亿的SPV用户每天同步一次，也就是一天有29,400个组的用户必须要连接、同步、断开连接：每个用户必须要能够在3秒钟之内完成前一天数据的同步。\n\n这就会造成一点难题，因为它要求每个全节点要有能力连续的每秒为每个SPV客户读取以及过滤167GB的数据。在一个全节点对应20个SPV客户端时，也就意味着每秒需要处理3,333GB的数据。我还不知道有任何的设备能拥有这样的吞吐量。不过应该可以创建一个巨大的RAID 0阵列的[高端固态磁盘](https://www.amazon.com/960Gb-Ssdnow-Dc400-Ssd-Sata/dp/B01LFOIK2Y/ref=sr_1_2?s=electronics&ie=UTF8&qid=1500821192&sr=1-2&keywords=SEDC400S37%2F1600G) ，每个磁盘可以实现大约每秒600MB的吞吐量。\n\n你大概需要 5,555个这样的设备来达到目标吞吐量。这种磁盘写入时会花费400美元，它拥有大约1TB的容量——足够保这种存理论网络上2天的区块数据。因此，每两天你就需要一个新的磁盘阵列，也就是每两天大概需要花费超过220万美元——这意味着保存1年的区块数据并达到所要求的吞吐量需要花费超过1亿美元。\n\n当然，我们可以利用假设来稍稍调整这些数字，我们是否可以假设出一个节点的花费能够合理一点的场景？\n\n让我们来尝试一下：\n如果我们有 100,000个全节点都运行在更加便宜，大容量的旋转磁盘上，然后我们能以某种方式让这些全节点全部都接收SPV客户，而且设法更改全节点的软件让它能支持1,000个连接的SPV客户。\n\n这样我们就拥有1亿个套接字可供SPV客户使用，能够支持2500万的SPV客户同时在线（每个客户需要4个套接字）。因此每个SPV客户每天拥有2,160秒来与网络同步数据。如果让一个全节点能满足要求，那么需要它能够保持着每个SPV客户读取速度达到231MB/s，也就意味着 1,000 个连接的SPV客户速度就要达到 231GB/s。\n\n一个 7,200 RPM的硬盘读取速度大概是220MB/s，所以大概 1,000多个RAID 0阵列设备就能达到目标读取速度。\n\n在写入的时候你可以购买一个[价值$400的10TB容量设备](https://www.amazon.com/Seagate-BarraCuda-3-5-Inch-Internal-ST10000DM0004/dp/B01IA9H22Q) ，因此一个400,000美元的这些设备RAID阵列就能够保存20天的区块数据——也就是需要720万美元来保存1年的数据并达到要求的读取吞吐量，这个价格相对就比较容易让人接受了。\n<img src=\"/asset/spv_device.jpg\"   width = \"700\" height = \"300\" alt=\"\" align=center />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;差不多每天就要至少添加两个这样的设备！\n\n值得注意的是，没人会在头脑清醒的时候用那么多设备来运行RAID 0阵列，因为如果其中一个设备有问题那么整个磁盘都会崩溃。因此具有容错功能的RAID阵列将更加昂贵并且性能更差一些。而且这看起来也是令人难以置信的乐观——100,000个组织愿意每年花费数百万的美元来运行全节点。\n\n另外一个需要注意的是，这些保守的估计中，都是假设SPV客户能够通过某种方式来协调，以便在每一天内均匀分配其同步时间。而现实中，会有每天和每周的周期性峰值和活跃性低谷——网络会需要一个比估计值合理的高点的容量来满足峰值时要求。\n\n否则的话，在使用高峰时SPV客户同步会失败。\n\n有趣的是，原来改变每个节点的套接字数不会影响任何给定的全节点总负载量——它还是需要处理相同数量的数据。在这个等式中真正重要的是全节点与SPV客户的比例，当然还有全节点需要处理的链中区块的大小。\n\n最终结果似乎是不可避免的：运行能够支持每天10亿链上交易者的SPV的全节点的花费是非常庞大的。\n\n## 寻找一个中间点\n通过这一点，可以清楚的看到，每天10亿的交易量让运行全认证节点的花费除了最有钱的人之外没人能负担的起。\n\n但是，如果我们略过这些计算，取而代之尝试寻找一个公式，可以通过增加链上交易的吞吐量来确定增加网络负载的费用呢？\n\n为了让比特币网络能够每秒支持目标交易量（增加了86,400个新日常用户的容量），我们可以计算每个节点磁盘吞吐量要求如下：\n![](/asset/spv_math.png)\n\n这提供了全节点服务SPV客户需求的每秒最小磁盘读取吞吐量。根据现在已存在的网络特性和可用的技术，我们可以通过将磁盘吞吐量作为假设的瓶颈来推算节点运行花销的估计值。当然这里肯定也会存在其他资源限制因素，来增加全节点运行的花销。\n\n[接下来的运算](https://docs.google.com/spreadsheets/d/1vJE0Qmfvg654J49rDOtofGWI7hqd-hJLJYQ9I2WlJvc/edit?usp=sharing) 中，我使用了这些假设：\n- 根据[statoshi.info](https://statoshi.info/dashboard/db/transactions?panelId=2&fullscreen) 交易平均大小字节数 = 500 bytes\n- SPV用户的总数 = 每天每笔交易1个\n- 被SPV客户端消耗的套接字 =标准为5\n- 全节点对SPV客户可获取的套接字的数量 = 之前计算的数字是136,000\n- 硬盘吞吐量和空间的花销 = $400 10TB, 7,200 PRM的RAID 0配置硬盘\n![](/asset/spv_chart1.png)\n\n我们可以看见在正常情况下磁盘的吞吐量还是比较合理的，但是当每秒超过100个交易的时候就不合理了。在这个点的时候你就需要购买多个磁盘，并且将其分段在RAID阵列中以达到要求的性能。\n\n不幸的是，磁盘吞吐量的需求以及因此全节点的运行成本相对于每秒交易数量的二次增加。花销很快就变得大多数人无法承担。\n\n作为参考，请记住Visa每秒大约处理2,000笔交易。在比特币中这大概需要将近$200,000价值的磁盘来跟上SPV的需求。值得注意一点是，这些图表保持着全节点的数量在一个8,000的常量—在现实中，他们很有可能随着花销的增加而减少，因此增加了吞吐量的需求以及运行剩下的节点花销会增加的更快。\n\n这似乎是中心化节点的复合限制。\n![](/asset/spv_chart2.png)\n\n就像我在[如何从中心化中拯救比特币的节点网络](https://www.coindesk.com/how-to-save-bitcoins-node-network-from-centralization/) 中总结的，其中一个关于增加区块大小的根本争论问题是节点的运行成本。上面的计算让我们对于计算节点运行成本的复杂有了基本的认识，计算复杂是因为涉及了太多的变量—上面的计算是基本上让变量都保持一个常量而且只关注磁盘I/O的花销。\n\n一年前我做的民意调查（不是非常科学）显示98%的节点运营商每月不会支付超过$100来运行一个节点，即使他们对比特币的投资非常高昂。我愿意打赌，如果增加比特币链上交易一个数量级将会导致失去大多数的全节点，如果增加两个数量级会导致失去90%的节点甚至更多。\n\n我相信，假设只有少数人会愿意为了运行一个全节点而不怕麻烦的去建立一个RAID陈列会安全一点。如果在这种情况下，声称这样的增加对于普通用户而言没关系是站不住脚的，因为这将会导致甚至没有足够的全节点磁盘吞吐量或套接字来为SPV提供服务。\n\n\n## SPV其他的缺点\nSPV对于安全性或全认证节点隐私性没有要求的终端用户而言是非常好的。然而，有很多原因可以被认为是多数SPV网络节点的阻碍者，不论它的可扩展性如何。\n\nSPV做出主要的假设，导致其具有比全认证节点的安全性和隐私性更加的薄弱。\n1. SPV用户相信矿工会正确认证和加强比特币规则，他们认为具有最大累积工作量证明的块链也是一个有效的链。你可以从[这篇文章](http://www.coindesk.com/bitcoins-security-model-deep-dive/) 中了解SPV和全节点安全模型的不同。\n2. SPV用户认为全节点不会因为遗漏对他们撒谎。全节点不会撒谎说一个其实不存在在区块上的交易是存在的，但是可以撒谎说存在在区块上的交易没有发生。\n3.  因为SPV客户力求效率，所以他们只发送请求来获取属于他们自己交易的数据。这导致失去大量的隐私。\n\n有趣的是，BIP 37的合著者 Matt Corallo, [后悔创建了它](https://www.youtube.com/watch?v=8BLWUUPfh2Q&feature=youtu.be&t=1569) \n> *”现在在系统中用户隐私的最大问题就是 BIP37 SPV bloom过滤器。我很抱歉，我写了这个。\"*\n\nBIP 37 Bloom过滤的SPV客户[基本上是没有隐私的](https://eprint.iacr.org/2014/763.pdf) ，即使使用不合理地高 **false-positive rates**。Jonas Nick(Blockstream的安全工程师)发现给出一个公钥，他可以确定给出钱包70%的其他地址。\n\n<iframe width=\"780\" height=\"515\" src=\"https://www.youtube.com/embed/HScK4pkDNds\" frameborder=\"0\" allowfullscreen></iframe>\n\n你可以通过在多个对端中分开Bloom过滤器来解决SPV的恶劣隐私，虽然这会让SPV的扩展性比在全节点上放更多的负载还要差。\n\nBIP 37 对于微不足道的拒绝服务攻击也同样脆弱。展示的代码可以在[这里获取](https://github.com/petertodd/bloom-io-attack) ，它通过发送很多快速库存请求经过特殊构造的过滤器，导致磁盘不停的查找以及CPU的高使用率来让全节点瘫痪。\n\n攻击的概念证明作者和主要开发者的Peter Todd解释：\n> *”根本问题是你可以用很少的网络带宽来消耗不成比例的磁盘I/O带宽。“*\n\n甚至直到今天，Satoshi在白皮书中描述的欺诈警告还是没有实现。实际上，这方面的努力调查显示它甚至不可能实现一个轻量级的欺诈警告。\n\n例如，欺诈警告只有当你真的获得了被要求证明是欺诈的数据才有效—如果矿工不提供那个数据，欺诈警告就不会被创建。再比如，SPV客户没有Satoshi设想的安全级别。\n\n从一个高层次的角度来看，一个由大多数SPV节点组成的世界可以让共识改变比如coin cap的总数或甚至让编辑分类账本更加的容易。更少的全认证节点意味着更多的中心化共识规则实施，因此更少的阻力改变共识规则。有人些人认为这是一个特征，但是更多的人认为这是个缺陷。\n\n## 潜在的改进\nSPV安全性和可扩展性有可能会通过好几种方法被潜在的改进，比如通过欺诈证明，欺诈提示，输入证明，花费证明等等方式。但是就我所知，这些都还只存在与概念阶段，还没有准备好开始开发产品。\n\n[Bloom过滤器承诺](https://bitcoin.stackexchange.com/questions/37124/is-there-a-way-to-index-transactions-so-that-filterload-commands-can-be-answered?rq=1) 可以提高隐私性，但是在过滤器的大小和它的 **false positive rate** 存在着一个效能的权衡： 太粗略意味着对端会下载太多的 **false-positive** 区块，而太精细又意味着过滤器对于任何使用SPV客户来下载的人来说太巨大又不切实际。\n\n它会减少全节点磁盘吞吐量的负载，但是权衡就变成了SPV客户和全节点之间增加的带宽，因为整个区块会在网络上进行传送。\n\n[最近提出的紧凑客户端过滤](https://github.com/Roasbeef/bips/blob/master/gcs_light_client.mediawiki) 消除了隐私的问题，但是它要求如果匹配过滤器全节点就需要下载整个区块（虽然不一定非要通过p2p网络）。\n\n[UTXO承诺](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html) 可以让SPV客户同步他们当前的UTXO集，因此钱包余额就不需要去请求全节点来扫描整个区块链。相反，它可以提供现有UTXOs的证明。\n\n也许可以通过要求SPV客户要么提交工作量证明（站不住脚的电池供电设备比如手机），要么基于通道的微型支付（如果客户还没接收到钱那么就不可能会自举）来防范Bloom过滤器的Dos攻击，但是这两者都没有提出直接的解决方案。\n\n全节点的磁盘读取需求可能会通过改进数据索引和批量处理SPV客户的请求等多种方式进行减少。\n\nRyan X Charles在下面的评论中指出，使用BIP70的支付协议来直接告诉别人你发送给他们的UTXO支付ID，可以移除他们对Bloom过滤器使用的需要，因为他们可以直接从全节点来请求数据。如果你愿意接受隐私权衡的话，这是非常高效的。\n\n照我说，这还有很多的改进空间—为了改进链上的扩展性还有很多的困难需要克服。\n\n##  合适的扩展解决方案\n如果我们忽略扩展区块大小的其他众多杂项问题，比如块传播延迟，UTXO集扩展，初始化区块同步时间和安全性以及隐私等权衡问题，只要有人愿意投资巨大的资源来开发改进软件和运行需求的基本设备，那么技术上是有可能将比特币扩展到每天亿万的链上用户。\n\n不过比特币似乎不太可能以这种方式有机的演变，因为有其他很多有校的方式来扩展系统。最高效的扩展形式已经被使用了：联合中心化API提供者。当使用这个方法的时候，倾向于存在巨大的信任和隐私权衡，但是很多交互涉及到合同协议，这也降低了一些危险性。\n\n用不可靠的方式进行扩展，诸如闪电之类的2层协议提供了更高效的扩展，因为大量的数据传输，仅仅只需要在直接涉及到给定链下交易的少数方之间进行。你可以把它想成广播到所有以太网通信层与路由IP层之间的区别—互联网在没有路由的情况下无法扩展，货币网络也如此。\n\n虽然这种扩展方法比传统中心化扩展在技术上要复杂很多而且还需要[克服很多独特的挑战](https://www.coindesk.com/lightning-technical-challenges-bitcoin-scalability/)， 为调研和这些路由协议开发的前期投资在长期来看会带来巨大的收益，因为他们在数量级上减少了整个网络需要承载的负载。\n\n两者之间还有很多可以探索：\n- 使用诸如[HashCash](http://hashcash.com/) Chaum代币的具有完善隐私的中心化监管方案\n- 诸如[TumbleBit](http://cs-people.bu.edu/heilman/tumblebit/) 的中心化非监管领信息证明系统\n- 联合的（半信任的多重签名）[侧链](https://elementsproject.org/sidechains/) \n- 矿工安全（半信任）[驱动链](http://www.drivechain.info/) \n\n我[仍然相信](https://medium.com/@lopp/de-centralized-block-chain-scaling-268dc5c3a7d0) 长期来看， 比特币还是需要大一点的区块。\n\n让我们耐心一点，策略性的在保持安全性和隐私的同时尝试将系统扩展到尽可能的高效。\n\n一个可审计的，轻去中心化的PayPal如果站在普通用户的立场上运作那么肯定能起作用，但是它就不会提供比特币现在所喜爱的财务主权。\n\n感谢 Matt Corallo, Mark Erhardt and Peter Todd为本文提供的审查和反馈。\n\n**信息披露：**CoinDesk是Digital Currency Group的子公司，拥有Blockstream所有权。\n","tags":["bitcoin"],"categories":["translation"]},{"title":"C Language Implemented Tendermint ABCI","url":"/Eng_C-ABCI.html","content":"**  **  <Excerpt in index | Homepage Digest>\nThis article is about a C-ABCI program I implemented.\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\nOriginal Author: [XU LI](https://lilymoana.github.io/)\nChinese Version: [C-ABCI](https://lilymoana.github.io/Chi_C-ABCI.html)\n\n## Brief Introduction\nThis article will focus on the implementation of **C-ABCI** which means use **C language** to implement **Tendermint ABCI** ! First of all,let's brief introduce **Tendermint** and **ABCI**:\n\n**Temdermint's** core is consensus engine, it would be responsible for:\n- Sharing blocks and transactions between nodes\n- Establishing a canonical/immutable order of transactions (the blockchain)\n \n**ABCI(Application BlockChain Interfac)** is interface between **Tendermint** and **Application**, which means **Application** will use **ABCI** to communicate with **Tendermint**. It can be implemented with any language, so far it's  been implemented with [C++](https://github.com/mdyring/cpp-tmsp) and [JavaScript](https://github.com/tendermint/js-abci), [Java](https://github.com/jTendermint/jabci), [Erlang](https://github.com/KrzysiekJ/abci_server). But not include **C language**, so I took the chance, use **C language** implemented  **C-ABCI**.\n\nLearn more about **Tendermint**: [Tendermint Intro](https://tendermint.com/intro)\nLearn more about **ABCI** : [ABCI Overview](https://tendermint.com/intro/abci-overview)\nSource code of **C-ABCI** : [chainx-org/c-abci](https://github.com/chainx-org/c-abci)\n\n## How to run C-ABCI demo?\nThis is pretty easy part, there's only five step to run a **C-ABCI** demo, do as the following:\n\n### Step 1:  Install Tendermint\nInstall **Tendermint** into your computer, here is the guide of [Installation of Tendermint](https://tendermint.com/docs/guides/install-from-source)\n\n### Step 2: Clone code\nClone the **C-ABCI** source code to your computer:\n```\ngit clone https://github.com/chainx-org/c-abci.git   ~/work/c/c-abci\n```\nThis is where I keep **C-ABCI** source code, you can chose your own path to keep it.\n\n### Step 3: Compile code \n Enter into **c-abci**  directory and compile  the **C-ABCI**:\n```\ncd ~/work/c/c-abci\nmake\n```\nwhen you successfully compile the **C-ABCI**, you will see the terminal output like this:\n![](/asset/cabci_make.png)\n\nAnd in the **c-abci/bin** directory you will see the **c-dummy** binary file, it can be executed !\n\n### Step 4: Run test program\nEnter  into **c-abci/bin** directory and run **c-dummy** program:\n```\ncd  bin/\n./c-dummy\n```\n\n### Step 5: Run Tendermint\nRun **Tendermint** program:\n\nIf it is your first time run **Tendermint** in your computer,  execute command:\n```\ntendermint init\ntendermint node\n```\nIf you have already run **Tendermint** in your computer , then execute command:\n```\ntendermint unsafe_reset_all\ntendermint node\n```\n\nThis is whole procedure of **How to run C-ABCI demo**. Here is the video of runing C-ABCI:\n<iframe width=\"1000\" height=\"500\" src=\"https://www.youtube.com/embed/p8CSvTyvOOI\" frameborder=\"0\" allowfullscreen></iframe>\n\n\n## C-ABCI code framework\n**Tendermint** provides two methods  to communicate with,  that's  **GRPC** and **TSP** ! **C-ABCI** chose the latter, it use **TCP** protocol to implement communication module.  Tendermint keep three connections: Mempool Connection, Consensus Connection, Query Connection. [Connections Introduction](https://tendermint.com/docs/guides/app-development). In **C-ABCI's** implementation each connection has it's own process to dispose the connection's request,  maybe latter on I will implement another version which use separated threads to dispose each connection.\n\nAs we said before, ABCI is a interface, in **C language** term it means that  **C-ABCI** is a library which  provides three interfaces.  **Application** can use **C-ABCI** library to communicate with **Tendermint**. **C-ABCI** doesn't interested in the data which **Application** and **Tendermint** communicate with, it's just a transmitter. Data transmission between **Tendermint** and **C-ABCI** is relay on **TCP Socket**, but **C-ABCI** and **Application** data transmission use callback function to achieve!\n\nProcessing flow among **Tendermint**, **Application**, **C-ABCI**:\n 1. **Tendermint** send a request to **C-ABCI**\n 2. **C-ABCI** receive the request and parse request data, then pass the data to the callback function which is **Application** implemented\n 3. The callback function according to request type to act different with the data, and pass the result to **C-ABCI** via callback function return value\n 4. **C-ABCI** pack the returned value and send it to **Tendermint**\n\nIn **C-ABCI** source code, there have been seven directories , each directory represent a individual modular except **include** directory. The sheet below describes each directory:\n\n| directory| description|\n|------------|--------------|\n|include | Include all modular head files|\n| socket| Communication modular which implemented communication of network based on TCP Socket\n|encoding| Character conversion modular which implemented conversion between **unsigned char** and **unsigned integer** of big endian and little endian \n|dlist| Data storage modular which use **Circular Doubly Linked List** to store data\n| type| Data type modular which dispose **Tendermint** data type, produce from **Tendermint** type.proto file with **protobuf-c** software\n| core| **C-ABCI** core modular which provides three interface to **Application**\n|demo|**C-ABCI** demo which is very simple **Application** for show you how to use **C-ABCI** library\n\n## How to build a Application on top of C-ABCI?\nEven though **C-ABCI** have seven directories,  there only have two directories you have to study:\n- core : use this modular to code **Application's** framework\n- type : use this modular to **malloc data struct** and **free data struct**\n \nI have already implemented a very simple application called **c-dummy** in **c-abci/demo** directory, you can draw lessons from it.\n\n**C-ABCI** is very easy to start on, it provides only three interfaces which is all you need to code a **Application** framework! \n\nThe three interfaces is:\n###  Initialize **C-ABCI** serve\nBind and listen the provided IP address and port.\n```\nint server_init(const char *ipaddr, const char *port);\n```\n\n### Start **C-ABCI** serve\nIt will not return until some error occurred. **app** is callback function which need **Application** to implemented.\n```\nint server_start(Application app)\n```\n### Stop **C-ABCI** server\nClose listened socket.\n```\n void server_stop();\n```\n\nYou just need write this three functions in your **Application's main function** then the code framework of your **Application** is completed (see **main function** in `main.c` file of **c-abci/demo/** directory) !\n\nRest of the work is to implement callback function which you provide to **server_start** function. It should look like this:\n```\nvoid *ABCIApplication(Types__Request *request)\n{\n    switch( request->value_case )\n    {\n        case TYPES__REQUEST__VALUE_INFO:\n            return Info();\n        case TYPES__REQUEST__VALUE_SET_OPTION:\n            return SetOption(request->set_option);\n        case TYPES__REQUEST__VALUE_DELIVER_TX:\n            return DeliverTx(request->deliver_tx);\n        case TYPES__REQUEST__VALUE_CHECK_TX:\n            return CheckTx(request->check_tx);\n        case TYPES__REQUEST__VALUE_COMMIT:\n            return  Commit();\n        case TYPES__REQUEST__VALUE_QUERY:\n            return Query(request->query);\n        case TYPES__REQUEST__VALUE_INIT_CHAIN:\n            return InitChain(request->init_chain);\n        case TYPES__REQUEST__VALUE_BEGIN_BLOCK:\n            return BeginBlock(request->begin_block);\n        case TYPES__REQUEST__VALUE_END_BLOCK:\n            return EndBlock(request->end_block);\n    }\n}\n```\nYou can find this code in `c-abci/demo/dummy.c` file. The  parameter of **request** passed by **C-ABCI**, which is received from **Tendermint**.\n\nYou can see in this callback function each **request type** has it's own function to dispose **request**. This is most important part of your **Application code**, you need  implement functions of each **request type**, these functions are your **Application's business logic** . And when you finished these functions, your **Application's code** is completed! \nIn **c-abci/demo/** directory just implemented a few  functions of some **request type**, and it's very simple **business logic** which just store data or query them.  It use **dlist modular** to store data. You can choose your own method to store data, such as **tree**, **database**.\n\nProblem's Solution:[C-ABCI's problems during compiling](https://github.com/chainx-org/c-abci/wiki/%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98)\n","tags":["c"],"categories":["original"]},{"title":"C语言实现的ABCI","url":"/Chi_C-ABCI.html","content":"** **  <Excerpt in index | Homepage Digest>\n本文主要介绍用 C 语言实现的 Tendermint ABCI，以及如何在此之上构建一个属于自己的应用\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n\n原文作者：[许莉](https://lilymoana.github.io/)\n英文版本：[C-ABCI](https://lilymoana.github.io/Eng-C-ABCI-md.html) \n\n## 简介\n首先简单介绍一下 Tendermint 和 ABCI。\n\nTendermint 的核心就是共识引擎，它主要负责两点：\n* 节点之间共享交易和区块\n* 建立一个规范且不可改变的交易顺序（也就是区块链）\n\nABCI（Application BlockChain Interface）是 Tendermint 与应用程序之间的一个接口，它可以使用各种语言来实现。目前已经实现的语言有 [C++](https://github.com/mdyring/cpp-tmsp)，[JavaScript](https://github.com/tendermint/js-abci)，[Java](https://github.com/jTendermint/jabci) 和 [Erlang](https://github.com/KrzysiekJ/abci_server)，尚无 C 语言实现，故而本文实现了 C 版本的 ABCI。\n\n如果对于 Tendermint 和 ABCI 尚不熟悉，或者想要了解更多有关内容，可自行参阅以下资料：\n- [Tendermint Intro](https://tendermint.com/intro)\n- [ABCI Overview](https://tendermint.com/intro/abci-overview)\n- [Tendermint Intro 中文翻译](http://chainx.org/news/index/detail/id/18.html)\n\nC-ABCI 的GitHub源码：[chainx-org/c-abci](https://github.com/chainx-org/c-abci)。\n\n## 运行示例\n\n### 安装 Tendermint\n在编译启动 C-ABCI 之前，首先需要安装 Tendermint，[这里是官方的安装指南](https://tendermint.com/docs/guides/install-from-source)。\n\n### 编译执行 c-dummy\nTendermint 安装完成之后，从 GitHub 下载 C-ABCI 源码到本地：\n```bash\ngit clone https://github.com/chainx-org/c-abci.git ~/c-abci\n```\n进入到目录 c-abci ，执行 `make` 对源码进行编译：\n```bash\ncd ~/c-abci\nmake\n```\n编译成功, 可以看到如下信息：\n![Makfile执行成功结果](/asset/cabci_make.png)\n编译完成后，会在 bin 目录下生成一个叫做 c-dummy 的可执行程序，执行该程序：\n```bash\ncd bin\n./c-dummy\n```\n### 启动 Tendermint\nc-dummy 启动后，开始启动 Tendermint。如果是首次执行Tendermint，需要先进行初始化再启动节点\n```bash\ntendermint init\ntendermint node\n```\n如果之前有启动过 Tendermint，先对 Tendermint 进行重置再启动节点：\n```bash\ntendermint unsafe_reset_all\ntendermint node\n```\n这就是整个启动过程了，下面有个C-ABCI启动过程的视频：\n<iframe width=\"1000\" height=\"500\" src=\"https://www.youtube.com/embed/p8CSvTyvOOI\" frameborder=\"0\" allowfullscreen></iframe>\n\n## 代码架构\nTendermint 提供了 GRPC 和 TSP 两种通信方式，C-ABCI 使用了后者，用基于 TCP 协议的 Socket 来完成通信模块。Tendermint 会保持3个连接：内存池连接（Mempool Connection）、共识连接（Consensus Connection）、查询连接（Query Connection），[三个连接简介](https://tendermint.com/docs/guides/app-development)。在 C-ABCI 的实现中，每个连接都拥有一个独立的进程来专门处理此连接的所有请求，后期可能会增加用独立线程来处理的版本。\n\n前面提到 ABCI 是一个接口，对 C 语言来说，它其实就是一个库。C-ABCI 就是一个用 C 语言实现的库，应用程序调用这个库来与 Tendermint 进行数据交互。C-ABCI 对于 Tendermint 与应用程序之间通信的具体数据并不感兴趣，它只是作为一个传递者而已！C-ABCI 与 Tendermint 之间数据的传输是通过 TCP Socket 来实现的，与应用程序之间数据的传输则是通过回调函数来实现的。\n\n应用程序、C-ABCI、Tendermint 三者之间处理流程：\n1. Tendermint 向 C-ABCI 发送请求\n2. C-ABCI 接收请求，并解析数据，然后调用应用程序实现的回调函数，并将解析的数据通过回调函数的参数传递给应用程序\n3. 应用程序所实现的回调函数会根据不同的请求类型对数据进行不同的处理，并将处理的结果通过回调函数的返回值返回给 C-ABCI\n4. C-ABCI 将返回的结果按照 Tendermint 要求的数据格式进行处理，并将处理的最后数据响应给 Tendermint\n\nC-ABCI 源码中，一共有 7 个目录，除了 `include` 目录之外每个目录都代表着一个模块，对于 `socket`，`encoding`，`dlist` 三个目录，是完全独立的，可以移出来放在任何项目中使用，后期有时间会把这三个独立的模块抽取出来继续完善！\n\n下面具体说明一下每个目录的作用：\n\n 目录        | 功能\n --------    | --------------------------\n include   | 头文件目录，包含所有模块的头文件\n socket    | 通信模块，主要功能是实现TCP协议的通信，提供了绑定监听端口，连接端口，关闭端口，以及接收，发送数据的接口\n encoding | 字符转换模块，主要功能是实现大小端整型数据与字符串之间的转换，分别提供了大端和小端不同位数的无符号整型与无符号字符串之间互相转换的接口\n dlist    | 数据存储模块，主要功能是使用循环双向链表来实现数据的存储，提供了链表的创建，销毁，增加，删除，查找接口\n type   | 数据类型处理模块，主要功能是实现数据结构体的的相关操作，提供结构体的创建，销毁等接口。Tendermint使用的数据类型保存在一个types.proto文件中，使用第三方软件protobuf-c软件将此文件生成C文件格式\n core      | C-ABCI的核心模块，主要功能就是实现一个服务端，给应用程序提供了初始化服务，开始服务以及停止服务的接口\n demo      | 实现了一个简单的应用程序，关于数据存储使用了dlist模块。\n\n## 应用程序示例\n在 C-ABCI 的源码中，`demo` 目录中实现了一个简单的应用程序，可以参考这个应用程序来实现自己的应用程序。\nC-ABCI中有多个目录，但是编写一个应用程序不用每个目录都需要去了解，只需要了解：\n- `core`：核心模块\n- `type`：数据类型处理模块\n\n下面结合 `demo` 讲述一下如何使用上面所说的两个模块在 C-ABCI 上编写一个属于自己的应用程序。\n\n应用程序的 `main` 函数中只需要调用 `core` 提供的三个接口，就完成了整个框架的编写（对照 `demo` 中 `main.c`理解）\n\n\n### 初始化C-ABCI服务\n此接口是绑定和监听传入的IP地址和端口\n```c\nint server_init(const char *ipaddr, const char *port);\n```\n### 启动C-ABCI服务\n只要没有出错，此接口不会返回，会一直等待新的连接，传入的app参数就是由应用程序实现的回调函数\n```c\nint server_start(Application app)\n```\n### 停止C-ABCI服务\n此接口主要是关闭监听的端口\n```c\nvoid server_stop();\n```\n这样，应用程序的框架代码就已经完成了。剩下所需要做的事情就是实现回调函数了，回调函数的实现:（**demo**中的**dummy.c**）：\n```c\nvoid *ABCIApplication(Types__Request *request)\n{\n    switch( request->value_case )\n    {\n        case TYPES__REQUEST__VALUE_INFO:\n            return Info();\n        case TYPES__REQUEST__VALUE_SET_OPTION:\n            return SetOption(request->set_option);\n        case TYPES__REQUEST__VALUE_DELIVER_TX:\n            return DeliverTx(request->deliver_tx);\n        case TYPES__REQUEST__VALUE_CHECK_TX:\n            return CheckTx(request->check_tx);\n        case TYPES__REQUEST__VALUE_COMMIT:\n            return  Commit();\n        case TYPES__REQUEST__VALUE_QUERY:\n            return Query(request->query);\n        case TYPES__REQUEST__VALUE_INIT_CHAIN:\n            return InitChain(request->init_chain);\n        case TYPES__REQUEST__VALUE_BEGIN_BLOCK:\n            return BeginBlock(request->begin_block);\n        case TYPES__REQUEST__VALUE_END_BLOCK:\n            return EndBlock(request->end_block);\n    }\n}\n```\n每个应用程序回调函数的实现都是如此。回调函数的参数是由 C-ABCI 提供，根据不同的请求会有不同的具体实现函数，这些具体实现函数就是应用程序代码编写的重点了，也就是应用程序的业务处理的逻辑代码。业务逻辑代码写完，那么一个应用程序就完成了，剩下的就是编译运行了！\n\n在 `demo` 中只实现了个别请求的具体实现，逻辑代码也非常的简单的，只是将请求的数据保存起来而已！demo 中对于数据存储这一块使用的是循环双向链表（ `dlist` 模块），应用程序可以不用使用C-ABCI提供的数据存储模块（`dlist`），可以选择其他的数据存储技术，比如树，数据库等等！\n\nGitHub Wiki:[C-ABCI编译运行出现的问题](https://github.com/chainx-org/c-abci/wiki/%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98) \n","tags":["c"],"categories":["original"]},{"title":"DPOS共识算法—缺失的白皮书","url":"/DPOS.html","content":"** **  <Excerpt in index | Homepage Digest>\n这是一份缺失的白皮书以及对委托权益共识算法（DPOS）的分析！这篇文章的目的就是提供一个分析，为什么DPOS可以行的通以及是什么使得它很强大！一篇早期对于DPOS介绍的文章可以在[bitshares.org](https://bitshares.org/technology/delegated-proof-of-stake-consensus/)看到，不过这篇介绍中也包含了很多不属于真正共识处理的其他方面。\n\n<!-- more -->\n<The rest of contents | Rest of all>\n\n翻译作者：[许莉](https://lilymoana.github.io/)\n原文地址：[DPOS Consensus Algorithm](https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper)\n\n\n所有的区块链基本上都是一个确定性的状态机，根据交易来行动。共识就是对交易顺序的确定性达成一致以及过滤无效交易的过程。也有很多不同的共识算法能够产生相同的交易顺序，但是通过多年来在多个区块链上的可靠运行，DPOS被证明了是很强大、安全和高效的。\n\n## DPOS共识算法摘要\nDPOS共识算法分为两个部分：选举一群区块生产者和调度生产。选举过程是为了保证利益相关者最终掌握控制权，因为当网络没有正常运行时利益相关者损失的最多。区块生产者是如何选举出来对于共识是如何达成的几乎没有影响。因此，本文主要讲解当一个区块生产者被选举出来之后共识是如何达成的。\n\n为了解释这个算法，我假设有3个区块生产者：A、B、C。因为共识的达成需要2/3+1多数来解决所有情况，这个简单的模型假设区块生产者C是决胜者。在现实世界中会有21个区块生产者或者更多。就像工作量证明，一般规则就是最长的链胜出。任何时候一个诚实的对端看见一个有效的长链都会将自己从当前的分支切换到最长链上。\n\n## 正常流程\n在正常流程下区块生产者会轮流每3秒钟来生产一个区块。假设每次轮流到的人都产生了自己该产生的区块，那么将会产生最长链。区块生产者在不属于自己产生区块之外的其他任何时间间隙产生的区块都是无效的。\n![](/asset/dpos_normal.png) \n\n## 少数者分支\n最多允许1/3的节点可以是恶意的或者存在故障，创造了一个少数者分支。这种情况下少数者分支只会每9秒钟产生一个区块，而多数者分支则会每9秒钟生产2个区块。再一次，诚实的2/3多数者将永远会比少数者分支的链要长。\n![](/asset/dpos_minority.png) \n\n## 未连接的少数者双重生产\n这个少数者可以尝试产生无数的分支，但是所有的分支上的链都会比多数者的链要短，因为少数者被限制区块的生产要比多数者慢。\n![](/asset/dpos_disconnect.png)\n\n## 网络分片\n网络完全有可能碎片化，在网络碎片化时没有任何分支拥有多数区块生产者。在这种情况下，最长的链将会在最大的少数者上产生。当网络的连通性恢复之后小一些的少数者会自动的切换到最长链上，明确的共识也随之恢复。\n![](/asset/dpos_fragmentation.png)\n\n有可能会出现3个分支中2个链长一点的分支，链的长度是一样的。这种情况下当第三个（链短一点的分支）分支上的区块生产者重新加入到网络时就会打破这种平衡。区块生产者的数量是奇数所以这种情况不会维持太长时间。后面我们也会对区块生产者重新洗牌，让生产区块的顺序随机化，来保证即使两个分支拥有相同数量的区块生产者，分支也将会在不同的长度爆发生长，导致一个分支接管另一个分支。\n\n## 连接的少数者双重生产\n在这种场景下少数者B在属于他的时间间隙生产2个或者更多其他的区块。下一个预订的区块生产者(C)，也许会选择在任何一个由B生产的区块上生产链。当C生产出一个区块之后，它将会变成一个最长链，所有选择B1的节点都会切换到最长链的分支上。不论少数恶意区块生产者尝试传播多少其他的区块都没有关系，这些区块在最长链中存在的时间永远不会超过一个回合的时间。\n![](/asset/dpos_connected.png)\n\n## 最后不可逆区块\n在网络分片事件中是有可能存在多个分支继续生长了一段延长时间。在长期来看，最长的链将会胜出，但是观测者要求有个方法可以确定的知道一个区块绝对是增长最快的链中的一部分。这个可以根据看到区块生产者们的超过2/3的确认消息就能确定。\n\n在下图中，区块B被C和代表着多数2/3+1确认的A确认过，因此我们可以推测只要2/3的区块生产者都是诚实的那么就没有其他的链会比这个链更长。\n![](/asset/dpos_irreversible.png)\n\n注意这个“规则”与比特币的6个块确认是相似的。一些聪明的人可以设计出一系列的事件让两个不同的节点在出现在不同的最后不可逆区块上。这种边缘案例要求攻击者能够完全掌控通信延时，并且需要在几分钟之内，不是一次，而是两次使用这个控制力。如果这种事情发生了，那么长期来看，最长链的规则依然有效。我们估计这种攻击事件发生的概率基本为0，而且就算发生了，对于资金基本上造成的影响小到你都不用去担心。\n\n## 缺少区块生产者法定数\n虽然可能性比较小，但是也可能存在区块生产者的法定数不明确，这种情况对于少数者还是有可能继续生产块的，在这些块中利益相关者可以包含更改投票的交易。然后这些投票可以选择一群新的区块生产者，让区块生产的参与率恢复到100%。一旦这种情况发生，少数者链将会最终超过其他参与率低于100%的链。\n\n在这个过程中所有的观察者都将会知道网络状态一直在变化指导区块生产参与率达到了67%。那些选择在这种情况下进行交易的人冒的风险大概跟没有得到6个块确认的交易差不多。他们是在知道有很小的可能性存在共识可能最终选择了一条不同的分叉进行操作的。在现实中这种情况比接收一个少于3个确认的比特币区块要安全的多。\n\n## 多数区块生产者腐败\n如果多数的区块生产者都变得腐败，那么他们就可以产生无数的分叉，每个都将以2/3多数确认进行着。在这种情况下，最后不可逆区块算法就会恢复成最长链算法。那么被最大的多数者所认可的链将会成为最长链， 谁是最大的多数者由剩下少数诚实的节点来决定。这种行为不会维持较长的时间，因为利益相关者最终会选择投票替换这些区块生产者。\n![](/asset/dpos_corruption.png)\n\n## 交易作为权益证明（TaPoS）\n当用户签名一个交易的时候，他们是在对区块链的状态有个确定猜想下进行签名的。这个猜想建立在他们对近期区块的看法。如果最长链的共识发生了改变，那么可能会使签名者在他们认可交易时产生的猜想无效化。\n\n由于TaPoS, 当一个区块在链的历史中不存在，所有的交易包括最近一个区块的hash值都被认为是无效的。任何在孤儿分支对交易签名的人将会发现交易是无效的，而且是无法迁移到主分支上的。\n\n这个处理的一个附带作用就是安全性，可以抵御试图产生替代链的长期攻击。各利益相关方每次在交易的时候都会直接确认区块链。随着时间的流逝，所有的区块都被所有的利益相关者确认，而这一点是无法在伪造的链中被复制的。\n\n##  确定的区块生产者洗牌\n在所有的列子中我们展示了区块生产者的循环调度。在现实中一群区块生产者会在N个块（N代表的区块生产者的数量）之后会被洗牌一次。这种随机性保证区块生产者B不会总是忽略区块生产者A，也确保每当有多个相同数量的区块生产者的分叉出现时，僵局都能被打破。\n\n## 总结\nDPOS在任何能够想得到的自然网络中断情况下还是稳健的，即使面对大多数的区块生产者舞弊也是安全的。不像一些竞争算法，DPOS在多数区块生产者出现故障的时候也可以正常工作。在这个期间，社区可以投票来选择新的区块生产者来代替这些出现故障的区块生产者直到区块生产者的参与率达到100%。我知道没有其他的共识算法可以在如此高频率且多变的失败环境下还能如此稳健。\n\nDPOS从选择一个选举区块生产者的共识算法而最终获得重要的安全性，并认证节点的高质量和唯一性。使用投票同意的处理机制确保了即使是拥有50%投票权的人，也无法依靠自己的权利选择哪怕一个区块生产者。DPOS旨在优化具有强大网络连接，且名义上诚实节点参与率为100%条件下的性能。这让DPOS有能力在平均1.5s内拥有99.9%的确定性来确认一笔交易，同时以优雅的方式，能在降级服务中恢复。\n\n其它的共识算法设计来支持较差网络的，和面对非诚实的节点。这将导致最终的可选设计只能是更慢的网络性能，更高的延迟，高通信开销，并且在33%的节点故障时将导致整个网络挂掉。\n\n在BitShares3年，Steem一年的成功运营中，我们经历了各种网络条件和软件bug。 DPOS已经成功地经历了这种环境，并展示了保持共识时，比任何其他链处理更多的交易时的能力\n","tags":["consensus"],"categories":["translation"]}]